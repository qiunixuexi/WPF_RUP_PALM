{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58223092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error,r2_score, mean_squared_error\n",
    "import random\n",
    "import os\n",
    "\n",
    "def set_deterministic(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_deterministic(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484365a",
   "metadata": {},
   "source": [
    "## 0. Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "name='CAISO_zone_1_.csv'\n",
    "surrogate_model_path = 'transformer_wind_power_model2_CAISO_zone_1_.pth'\n",
    "with open('weather_scaler.pkl', 'rb') as f:\n",
    "    weather_scaler = pickle.load(f)\n",
    "\n",
    "class WindPowerDataset(Dataset):\n",
    "    def __init__(self, csv_file, wind_power_scaler=None, weather_scaler=None, save_scalers=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.data = self.data.iloc[::5, :].reset_index(drop=True)\n",
    "\n",
    "        self.original_wind_power_std = self.data.iloc[:, 2].std()\n",
    "        self.original_weather_std = self.data.iloc[:, 4:12].std()\n",
    "\n",
    "        if wind_power_scaler is None or weather_scaler is None:\n",
    "            self.wind_power_scaler = MinMaxScaler()\n",
    "            self.weather_scaler = MinMaxScaler()\n",
    "\n",
    "            self.data.iloc[:, 2] = self.wind_power_scaler.fit_transform(self.data.iloc[:, 2].values.reshape(-1, 1)).squeeze()\n",
    "\n",
    "            self.data.iloc[:, 4:12] = self.weather_scaler.fit_transform(self.data.iloc[:, 4:12])\n",
    "            \n",
    "            if save_scalers:\n",
    "                with open('wind_power_scaler.pkl', 'wb') as f:\n",
    "                    pickle.dump(self.wind_power_scaler, f)\n",
    "                with open('weather_scaler.pkl', 'wb') as f:\n",
    "                    pickle.dump(self.weather_scaler, f)\n",
    "        else:\n",
    "            self.wind_power_scaler = wind_power_scaler\n",
    "            self.weather_scaler = weather_scaler\n",
    "            self.data.iloc[:, 2] = self.wind_power_scaler.transform(self.data.iloc[:, 2].values.reshape(-1, 1)).squeeze()\n",
    "            self.data.iloc[:, 4:12] = self.weather_scaler.transform(self.data.iloc[:, 4:12])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - 312  # 288 (1440/5) + 24 (120/5)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        wind_power_history = self.data.iloc[idx:idx + 288, 2].values.astype(float)\n",
    "        future_weather = self.data.iloc[idx + 288:idx + 312, 4:12].values.astype(float)\n",
    "        future_wind_power = self.data.iloc[idx + 312, 2]\n",
    "        return torch.tensor(wind_power_history, dtype=torch.float32), \\\n",
    "               torch.tensor(future_weather, dtype=torch.float32), \\\n",
    "               torch.tensor(future_wind_power, dtype=torch.float32)\n",
    "    \n",
    "    def get_original_stds(self):\n",
    "        return {\n",
    "            'original_wind_power_std': self.original_wind_power_std,\n",
    "            'original_weather_std': self.original_weather_std.to_dict()\n",
    "        }\n",
    "\n",
    "dataset = WindPowerDataset(name, save_scalers=True)\n",
    "weather_stds = dataset.get_original_stds()\n",
    "weather_stds_array = np.array(list(weather_stds['original_weather_std'].values()))  \n",
    "weather_data = pd.read_csv(name)\n",
    "weather_data = weather_data.iloc[::5, :].reset_index(drop=True)\n",
    "weather_mean = weather_data.iloc[:, 4:12].mean()\n",
    "wind_power_scaler=dataset.wind_power_scaler\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size=32\n",
    "test_split=0.2\n",
    "test_size = int(len(dataset) * test_split)\n",
    "train_size = len(dataset) - test_size\n",
    "train_dataset = Subset(dataset, list(range(train_size)))\n",
    "test_dataset = Subset(dataset, list(range(train_size, len(dataset))))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867dbba",
   "metadata": {},
   "source": [
    "## 1. Load surrogate model and target model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5708d336",
   "metadata": {},
   "source": [
    "### traget model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad65881",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.lstm_wind = nn.LSTM(input_size=1, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm_weather = nn.LSTM(input_size=8, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(256, 1)\n",
    "        self.relu=nn.ReLU()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = wind_history.unsqueeze(-1)\n",
    "        _, (hn_wind, _) = self.lstm_wind(wind_history)\n",
    "        _, (hn_weather, _) = self.lstm_weather(weather_future)\n",
    "        hn_wind = hn_wind[-1, :, :]\n",
    "        hn_weather = hn_weather[-1, :, :]\n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.relu(output)\n",
    "        return output\n",
    "    \n",
    "def load_model(model_path, device='cpu'):\n",
    "    model = WindPowerPredictor().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tar_model_path1 = 'wind_caiso_lstm_sigmoid_version2.pth'\n",
    "tar_model1 = load_model(tar_model_path1, device)\n",
    "\n",
    "class WindPowerPredictor(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(WindPowerPredictor, self).__init__()  \n",
    "        self.gru_wind = nn.GRU(input_size=1, hidden_size=128, num_layers=1, batch_first=True)  \n",
    "        self.gru_weather = nn.GRU(input_size=8, hidden_size=128, num_layers=1, batch_first=True)  \n",
    "        self.fc = nn.Linear(256, 1)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "      \n",
    "    def forward(self, wind_history, weather_future):  \n",
    "        wind_history = wind_history.unsqueeze(-1)  \n",
    "        _, hn_wind = self.gru_wind(wind_history)  \n",
    "        _, hn_weather = self.gru_weather(weather_future)  \n",
    "        hn_wind = hn_wind[-1, :, :]  \n",
    "        hn_weather = hn_weather[-1, :, :]  \n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)  \n",
    "        output = self.fc(combined)  \n",
    "        output = self.sigmoid(output)\n",
    "        return output  \n",
    "\n",
    "tar_model_path2 = 'wind_gru_caiso_sigmoid_version2.pth'\n",
    "tar_model2 = load_model(tar_model_path2, device)\n",
    "\n",
    "class WindPowerPredictorV2(nn.Module):\n",
    "    def __init__(self, d_model=64, nhead=4, num_layers=3, dim_feedforward=128, dropout=0.1, max_seq_len=300):\n",
    "        super(WindPowerPredictorV2, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.embedding_wind = nn.Linear(1, d_model)\n",
    "        self.embedding_weather = nn.Linear(8, d_model)\n",
    "\n",
    "        self.pos_encoder_wind = nn.Parameter(torch.zeros(max_seq_len, 1, d_model))\n",
    "        self.pos_encoder_weather = nn.Parameter(torch.zeros(max_seq_len, 1, d_model))\n",
    "\n",
    "\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=False\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "\n",
    "        self.fc_combine = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, wind_history, weather_future):\n",
    "        # wind_history: (batch_size, T1)        e.g., (32, 288)\n",
    "        # weather_future: (batch_size, T2, 8)    e.g., (32, 24, 8)\n",
    "\n",
    "        batch_size, seq_len_wind = wind_history.shape\n",
    "        _, seq_len_weather, _ = weather_future.shape\n",
    "\n",
    "        if seq_len_wind > self.pos_encoder_wind.size(0):\n",
    "            raise ValueError(f\"Wind sequence length {seq_len_wind} exceeds max supported length {self.pos_encoder_wind.size(0)}\")\n",
    "        if seq_len_weather > self.pos_encoder_weather.size(0):\n",
    "            raise ValueError(f\"Weather sequence length {seq_len_weather} exceeds max supported length {self.pos_encoder_weather.size(0)}\")\n",
    "\n",
    "        wind_emb = self.embedding_wind(wind_history.unsqueeze(-1))           # (B, T1, D)\n",
    "        weather_emb = self.embedding_weather(weather_future)                 # (B, T2, D)\n",
    "\n",
    "        wind_emb = wind_emb.permute(1, 0, 2)  # (T1, B, D)\n",
    "        weather_emb = weather_emb.permute(1, 0, 2)  # (T2, B, D)\n",
    "\n",
    "        wind_emb = wind_emb + self.pos_encoder_wind[:seq_len_wind]      # (T1, B, D)\n",
    "        weather_emb = weather_emb + self.pos_encoder_weather[:seq_len_weather]  # (T2, B, D)\n",
    "\n",
    "        wind_features = self.transformer_encoder(wind_emb)              # (T1, B, D)\n",
    "        weather_features = self.transformer_encoder(weather_emb)        # (T2, B, D)\n",
    "\n",
    "        wind_last = wind_features[-1, :, :]        \n",
    "        weather_last = weather_features[-1, :, :]  \n",
    "\n",
    "        combined = torch.cat((wind_last, weather_last), dim=1)  # (B, 2D)\n",
    "\n",
    "        output = self.fc_combine(combined)  # (B, 1)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "    \n",
    "tar_model_path3 = 'wind_caiso_transformer_sigmoid_version2.pth'\n",
    "tar_model3 = WindPowerPredictorV2().to(device)\n",
    "state_dict = torch.load(tar_model_path3, map_location=device)\n",
    "tar_model3.load_state_dict(state_dict)\n",
    "tar_model3.to(device)\n",
    "\n",
    "class TemporalConvNet_V2(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=3, dropout=0.2):\n",
    "        super(TemporalConvNet_V2, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "\n",
    "            padding = (kernel_size - 1) * dilation_size\n",
    "\n",
    "            conv = nn.Conv1d(\n",
    "                in_channels, out_channels, kernel_size,\n",
    "                stride=1, padding=padding, dilation=dilation_size  \n",
    "            )\n",
    "            relu = nn.ReLU()\n",
    "            drop = nn.Dropout(dropout)\n",
    "\n",
    "            if in_channels != out_channels:\n",
    "                res_conv = nn.Conv1d(in_channels, out_channels, 1)\n",
    "            else:\n",
    "                res_conv = None\n",
    "\n",
    "            layers.append(nn.ModuleDict({\n",
    "                'conv': conv,\n",
    "                'relu': relu,\n",
    "                'dropout': drop,\n",
    "                'res_conv': res_conv\n",
    "            }))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, in_channels, seq_len)\n",
    "        for layer in self.layers:\n",
    "            residual = x  \n",
    "\n",
    "            x = layer['conv'](x)  \n",
    "            x = layer['relu'](x)\n",
    "            x = layer['dropout'](x)\n",
    "            x = x[:, :, :residual.size(2)]  \n",
    "\n",
    "            # 残差连接\n",
    "            if layer['res_conv'] is not None:\n",
    "                residual = layer['res_conv'](residual)\n",
    "            x = x + residual\n",
    "            x = layer['relu'](x)  \n",
    "        return x\n",
    "\n",
    "\n",
    "class WindPowerPredictorTCN_V2(nn.Module):\n",
    "    def __init__(self, d_model=64, dropout=0.2, fusion_mode='concat'):\n",
    "        super(WindPowerPredictorTCN_V2, self).__init__()\n",
    "        self.fusion_mode = fusion_mode  # 'concat' or 'add'\n",
    "        self.tcn_wind = TemporalConvNet_V2(\n",
    "            num_inputs=1,\n",
    "            num_channels=[d_model, d_model*2, d_model, d_model],  \n",
    "            kernel_size=3,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.tcn_weather = TemporalConvNet_V2(\n",
    "            num_inputs=8,\n",
    "            num_channels=[d_model, d_model*2, d_model, d_model],\n",
    "            kernel_size=3,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        if fusion_mode == 'concat':\n",
    "            fc_input_dim = d_model * 2\n",
    "        elif fusion_mode == 'add':\n",
    "            fc_input_dim = d_model\n",
    "        else:\n",
    "            raise ValueError(\"fusion_mode must be 'concat' or 'add'\")\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(fc_input_dim, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, wind_history, weather_future):\n",
    "        # wind_history: (batch_size, 288)\n",
    "        # weather_future: (batch_size, 24, 8)\n",
    "\n",
    "        x_wind = wind_history.unsqueeze(1)  # (B, 1, 288)\n",
    "        x_wind = self.tcn_wind(x_wind)     # (B, D, 288)\n",
    "        x_wind = x_wind[:, :, -1]          \n",
    "\n",
    "        x_weather = weather_future.transpose(1, 2)  # (B, 8, 24)\n",
    "        x_weather = self.tcn_weather(x_weather)     # (B, D, 24)\n",
    "        x_weather = x_weather[:, :, -1]             # -> (B, D)\n",
    "\n",
    "        if self.fusion_mode == 'concat':\n",
    "            combined = torch.cat((x_wind, x_weather), dim=1)  # (B, 2D)\n",
    "        elif self.fusion_mode == 'add':\n",
    "            combined = x_wind + x_weather  \n",
    "\n",
    "        output = self.fc(combined)         # (B, 1)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "    \n",
    "tar_model_path4 = 'wind_tcn_caiso_sigmoid_v2.pth'\n",
    "tar_model4 = WindPowerPredictorTCN_V2()\n",
    "state_dict = torch.load(tar_model_path4, map_location=device)\n",
    "tar_model4.load_state_dict(state_dict)\n",
    "tar_model4.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_model_list = [tar_model1, tar_model2, tar_model3, tar_model4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bcf972",
   "metadata": {},
   "source": [
    "### surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5881a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(WindPowerPredictor, self).__init__()  \n",
    "        self.gru_wind = nn.GRU(input_size=1, hidden_size=50, num_layers=2, batch_first=True)  \n",
    "        self.gru_weather = nn.GRU(input_size=8, hidden_size=50, num_layers=2, batch_first=True)  \n",
    "        self.fc = nn.Linear(100, 1)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "      \n",
    "    def forward(self, wind_history, weather_future):  \n",
    "        wind_history = wind_history.unsqueeze(-1)  \n",
    "        _, hn_wind = self.gru_wind(wind_history)  \n",
    "        _, hn_weather = self.gru_weather(weather_future)  \n",
    "        hn_wind = hn_wind[-1, :, :]  \n",
    "        hn_weather = hn_weather[-1, :, :]  \n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)  \n",
    "        output = self.fc(combined)  \n",
    "        output = self.sigmoid(output)\n",
    "        return output  \n",
    "    \n",
    "sur_model_path1 = 'wind_gru_caiso_sigmoid.pth'\n",
    "sur_model1 = load_model(sur_model_path1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75e8ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self, d_model=50):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding_wind = nn.Linear(1, d_model)\n",
    "        self.embedding_weather = nn.Linear(8, d_model)\n",
    "        self.transformer_wind = nn.Transformer(\n",
    "            d_model=d_model, nhead=2, num_encoder_layers=2, num_decoder_layers=2, dim_feedforward=200, dropout=0.1\n",
    "        )\n",
    "        self.transformer_weather = nn.Transformer(\n",
    "            d_model=d_model, nhead=2, num_encoder_layers=2, num_decoder_layers=2, dim_feedforward=200, dropout=0.1\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = self.embedding_wind(wind_history.unsqueeze(-1))  # (batch_size, seq_len, d_model)\n",
    "        wind_history = wind_history.permute(1, 0, 2)  # (seq_len, batch_size, d_model)\n",
    "        weather_future = self.embedding_weather(weather_future)  # (batch_size, seq_len, d_model)\n",
    "        weather_future = weather_future.permute(1, 0, 2)  # (seq_len, batch_size, d_model)\n",
    "\n",
    "        transformer_output_wind = self.transformer_wind(wind_history, wind_history)\n",
    "        transformer_output_weather = self.transformer_weather(weather_future, weather_future)\n",
    "        \n",
    "        combined = torch.cat((transformer_output_wind[-1, :, :], transformer_output_weather[-1, :, :]), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.sigmoid(output)  \n",
    "        return output\n",
    "    \n",
    "sur_model_path2 = 'wind_caiso_transformer_sigmoid.pth'\n",
    "sur_model2 = load_model(sur_model_path2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0158db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=(kernel_size-1) * dilation_size, dilation=dilation_size),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Dropout(dropout)]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class WindPowerPredictorTCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WindPowerPredictorTCN, self).__init__()\n",
    "        self.tcn_wind = TemporalConvNet(num_inputs=1, num_channels=[50]*3, kernel_size=3, dropout=0.2)\n",
    "        self.tcn_weather = TemporalConvNet(num_inputs=8, num_channels=[50]*3, kernel_size=3, dropout=0.2)\n",
    "        self.fc = nn.Linear(50 * 2, 1)  # Combined output size of TCNs\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = wind_history.unsqueeze(1)  # (batch_size, 1, seq_len)\n",
    "        tcn_output_wind = self.tcn_wind(wind_history).transpose(1, 2)[:, -1, :]\n",
    "        \n",
    "        weather_future = weather_future.transpose(1, 2)  # (batch_size, 8, seq_len)\n",
    "        tcn_output_weather = self.tcn_weather(weather_future).transpose(1, 2)[:, -1, :]\n",
    "        \n",
    "        combined = torch.cat((tcn_output_wind, tcn_output_weather), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "    \n",
    "sur_model3 = WindPowerPredictorTCN()\n",
    "sur_model_path3 = 'wind_tcn_caiso_sigmoid.pth'\n",
    "sur_model3.load_state_dict(torch.load(sur_model_path3))\n",
    "sur_model3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86442103",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.lstm_wind = nn.LSTM(input_size=1, hidden_size=50, num_layers=2, batch_first=True)\n",
    "        self.lstm_weather = nn.LSTM(input_size=8, hidden_size=50, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(100, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = wind_history.unsqueeze(-1)\n",
    "        _, (hn_wind, _) = self.lstm_wind(wind_history)\n",
    "        _, (hn_weather, _) = self.lstm_weather(weather_future)\n",
    "        hn_wind = hn_wind[-1, :, :]\n",
    "        hn_weather = hn_weather[-1, :, :]\n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.sigmoid(output)  \n",
    "        return output\n",
    "    \n",
    "sur_model_path4 = 'wind_caiso_lstm_sigmoid.pth'\n",
    "sur_model4 = WindPowerPredictor()\n",
    "sur_model4.load_state_dict(torch.load(sur_model_path4))\n",
    "sur_model4.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sur_model_list = [sur_model1, sur_model2, sur_model3, sur_model4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c5597",
   "metadata": {},
   "source": [
    "## Attack peroformance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e64218",
   "metadata": {},
   "source": [
    "### RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b28648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_attack_RA(model, data_loader, epsilon=0.01, device='cpu'):\n",
    "    model.eval()  \n",
    "    all_preds = []\n",
    "    all_adversarial_preds = []\n",
    "    all_targets = []\n",
    "    all_original_weather = []\n",
    "    all_adversarial_weather = []\n",
    "    \n",
    "    for parameters in model.parameters():\n",
    "        parameters.requires_grad = False\n",
    "    \n",
    "    for wind_history, weather_future, future_wind_power in data_loader:\n",
    "        wind_history = wind_history.to(device)\n",
    "        weather_future = weather_future.to(device)\n",
    "        future_wind_power = future_wind_power.to(device)\n",
    "        original_output = model(wind_history, weather_future)\n",
    "        uap=torch.empty_like(weather_future).uniform_(-epsilon, epsilon)\n",
    "        adversarial_weather = weather_future +uap\n",
    "        adversarial_weather = torch.clamp(adversarial_weather, 0, 1)  \n",
    "        adversarial_output = model(wind_history, adversarial_weather.detach())  \n",
    "        all_preds.append(original_output.detach().cpu().numpy())\n",
    "        all_adversarial_preds.append(adversarial_output.detach().cpu().numpy())\n",
    "        all_targets.append(future_wind_power.cpu().numpy())\n",
    "        all_original_weather.append(weather_future.detach().cpu().numpy())\n",
    "        all_adversarial_weather.append(adversarial_weather.detach().cpu().numpy())\n",
    "\n",
    "    model.eval()  \n",
    "\n",
    "    return all_preds, all_adversarial_preds, all_targets, all_original_weather, all_adversarial_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c167e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_list=[0.03,0.05,0.1]\n",
    "for epsilon in epsilon_list:\n",
    "    for tar_model in tar_model_list:\n",
    "        original_preds, adversarial_preds, targets, original_weathers, adversarial_weathers = adversarial_attack_RA(tar_model, test_loader, epsilon=epsilon, device=device)\n",
    "        all_targets = np.concatenate(targets).flatten()\n",
    "        all_adversarial_preds=np.concatenate(adversarial_preds).flatten()\n",
    "        all_targets_inv=wind_power_scaler.inverse_transform(np.array(all_targets).reshape(-1, 1)).squeeze()\n",
    "        all_preds_inv=wind_power_scaler.inverse_transform(np.array(all_adversarial_preds).reshape(-1, 1)).squeeze()\n",
    "        rmse = mean_squared_error(all_targets_inv, all_preds_inv, squared=False)\n",
    "        mse = mean_squared_error(all_targets_inv, all_preds_inv)\n",
    "        print(f'RMSE_inv: {rmse:.10f}')\n",
    "        print(f'MSE_inv: {mse:.10f}')\n",
    "        mae = mean_absolute_error(all_targets_inv, all_preds_inv)\n",
    "        print(f'MAE_inv: {mae:.10f}')\n",
    "        print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd453a",
   "metadata": {},
   "source": [
    "### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_attack_FGSM(sur_model, model, data_loader, epsilon=0.01, device='cpu'):\n",
    "    sur_model.train()  \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_adversarial_preds = []\n",
    "    all_targets = []\n",
    "    all_original_weather = []\n",
    "    all_adversarial_weather = []\n",
    "\n",
    "    for parameters in sur_model.parameters():\n",
    "        parameters.requires_grad = False\n",
    "    \n",
    "    for wind_history, weather_future, future_wind_power in data_loader:\n",
    "        wind_history = wind_history.to(device)\n",
    "        weather_future = weather_future.to(device)\n",
    "        future_wind_power = future_wind_power.to(device)\n",
    "        weather_future.requires_grad = True\n",
    "        original_output = model(wind_history, weather_future)\n",
    "        sur_original_output = sur_model(wind_history, weather_future)\n",
    "        original_loss = torch.sum(sur_original_output.squeeze()- future_wind_power)\n",
    "        sur_model.zero_grad()\n",
    "        original_loss.backward()  \n",
    "\n",
    "        # adversarial perturbation\n",
    "        weather_future_grad = weather_future.grad.data\n",
    "        adversarial_weather = weather_future + epsilon * weather_future_grad.sign()\n",
    "        adversarial_weather = torch.clamp(adversarial_weather, 0, 1)  # ensure the data is within a reasonable range\n",
    "        adversarial_output = model(wind_history, adversarial_weather.detach())  \n",
    "\n",
    "        all_preds.append(original_output.detach().cpu().numpy())\n",
    "        all_adversarial_preds.append(adversarial_output.detach().cpu().numpy())\n",
    "        all_targets.append(future_wind_power.cpu().numpy())\n",
    "        all_original_weather.append(weather_future.detach().cpu().numpy())\n",
    "        all_adversarial_weather.append(adversarial_weather.detach().cpu().numpy())\n",
    "\n",
    "    model.eval()  \n",
    "\n",
    "    return all_preds, all_adversarial_preds, all_targets, all_original_weather, all_adversarial_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c07383",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_list=[0.03,0.05,0.1]\n",
    "for epsilon in epsilon_list:\n",
    "    for sur_model in sur_model_list:\n",
    "        for model in tar_model_list:\n",
    "            original_preds, adversarial_preds, targets, original_weathers, adversarial_weathers = adversarial_attack_FGSM(sur_model, model, test_loader, epsilon=epsilon, device=device)\n",
    "            all_targets = np.concatenate(targets).flatten()\n",
    "            all_adversarial_preds=np.concatenate(adversarial_preds).flatten()\n",
    "            all_targets_inv=wind_power_scaler.inverse_transform(np.array(all_targets).reshape(-1, 1)).squeeze()\n",
    "            all_preds_inv=wind_power_scaler.inverse_transform(np.array(all_adversarial_preds).reshape(-1, 1)).squeeze()\n",
    "            rmse = mean_squared_error(all_targets_inv, all_preds_inv, squared=False)\n",
    "            mse = mean_squared_error(all_targets_inv, all_preds_inv)\n",
    "            print(f'RMSE_inv: {rmse:.10f}')\n",
    "            print(f'MSE_inv: {mse:.10f}')\n",
    "            mae = mean_absolute_error(all_targets_inv, all_preds_inv)\n",
    "            print(f'MAE_inv: {mae:.10f}')\n",
    "            print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf7456",
   "metadata": {},
   "source": [
    "### PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb8ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_attack_PGD(sur_model, model, data_loader, epsilon=0.01, alpha=0.003, num_iterations=80, device='cpu'):\n",
    "    sur_model.train()  \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_adversarial_preds = []\n",
    "    all_targets = []\n",
    "    all_original_weather = []\n",
    "    all_adversarial_weather = []\n",
    "\n",
    "    for parameters in sur_model.parameters():\n",
    "        parameters.requires_grad = False\n",
    "\n",
    "    for wind_history, weather_future, future_wind_power in data_loader:\n",
    "        wind_history = wind_history.to(device)\n",
    "        weather_future = weather_future.to(device)\n",
    "        future_wind_power = future_wind_power.to(device)\n",
    "        adversarial_weather = weather_future.clone().detach()\n",
    "        adversarial_weather.requires_grad = True\n",
    "        original_output = model(wind_history, weather_future)\n",
    "\n",
    "        sur_original_output = sur_model(wind_history, weather_future)\n",
    "        for i in range(num_iterations):\n",
    "            original_output = model(wind_history, adversarial_weather)\n",
    "            \n",
    "            sur_original_output = sur_model(wind_history, adversarial_weather)\n",
    "            original_loss = torch.sum(sur_original_output.squeeze()- future_wind_power)\n",
    "            sur_model.zero_grad()\n",
    "            original_loss.backward()  \n",
    "            with torch.no_grad():\n",
    "                weather_future_grad = adversarial_weather.grad.data\n",
    "                adversarial_weather += alpha * weather_future_grad.sign()\n",
    "                adversarial_weather = torch.max(torch.min(adversarial_weather, weather_future + epsilon),\n",
    "                                                weather_future - epsilon)\n",
    "                adversarial_weather = torch.clamp(adversarial_weather, 0,1)\n",
    "                adversarial_weather = adversarial_weather.detach().requires_grad_(True)\n",
    "     \n",
    "        adversarial_output = model(wind_history, adversarial_weather)\n",
    "        original_output = model(wind_history, weather_future)\n",
    "\n",
    "        all_preds.append(original_output.detach().cpu().numpy())\n",
    "        all_adversarial_preds.append(adversarial_output.detach().cpu().numpy())\n",
    "        all_targets.append(future_wind_power.cpu().numpy())\n",
    "        all_original_weather.append(weather_future.detach().cpu().numpy())\n",
    "        all_adversarial_weather.append(adversarial_weather.detach().cpu().numpy())\n",
    "    sur_model.eval()  \n",
    "    \n",
    "    return all_preds, all_adversarial_preds, all_targets, all_original_weather, all_adversarial_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_list=[0.03,0.05,0.1]\n",
    "for epsilon in epsilon_list:\n",
    "    for sur_model in sur_model_list:\n",
    "        for model in tar_model_list:\n",
    "            original_preds, adversarial_preds, targets, original_weathers, adversarial_weathers = adversarial_attack_PGD(sur_model, model, test_loader, epsilon=epsilon, device=device)\n",
    "            all_targets = np.concatenate(targets).flatten()\n",
    "            all_adversarial_preds=np.concatenate(adversarial_preds).flatten()\n",
    "            all_targets_inv=wind_power_scaler.inverse_transform(np.array(all_targets).reshape(-1, 1)).squeeze()\n",
    "            all_preds_inv=wind_power_scaler.inverse_transform(np.array(all_adversarial_preds).reshape(-1, 1)).squeeze()\n",
    "            rmse = mean_squared_error(all_targets_inv, all_preds_inv, squared=False)\n",
    "            mse = mean_squared_error(all_targets_inv, all_preds_inv)\n",
    "            print(f'RMSE_inv: {rmse:.10f}')\n",
    "            print(f'MSE_inv: {mse:.10f}')\n",
    "            mae = mean_absolute_error(all_targets_inv, all_preds_inv)\n",
    "            print(f'MAE_inv: {mae:.10f}')\n",
    "            print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2497766c",
   "metadata": {},
   "source": [
    "### AoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b263800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "import torch.optim as optim\n",
    "\n",
    "def compute_attention(model, wind_history, weather_input, baseline_type='zero'):\n",
    "    was_training = model.training\n",
    "    try:\n",
    "        model.train()\n",
    "        if not weather_input.requires_grad:\n",
    "            weather_input.requires_grad_(True)\n",
    "\n",
    "        with torch.backends.cudnn.flags(enabled=False):\n",
    "            output = model(wind_history, weather_input)\n",
    "\n",
    "        grad_outputs = torch.ones_like(output)\n",
    "        \n",
    "        grads = torch.autograd.grad(\n",
    "            outputs=output,\n",
    "            inputs=weather_input,\n",
    "            grad_outputs=grad_outputs,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        attention = torch.abs(grads * weather_input)\n",
    "        return attention.contiguous()\n",
    "\n",
    "    finally:\n",
    "        if not was_training:\n",
    "            model.eval()\n",
    "\n",
    "def generate_universal_adversarial_samples(\n",
    "    surrogate_models,\n",
    "    test_loader,\n",
    "    device,\n",
    "    lambda_aoa=1.0,\n",
    "    lambda_reg=10.0,\n",
    "    epsilon=0.1,  \n",
    "    num_steps=10,\n",
    "    learning_rate=0.01,\n",
    "    target_bias=0.1, \n",
    "    save_path=\"universal_adversarial_samples.pkl\"\n",
    "):\n",
    "   \n",
    "    for model in surrogate_models:\n",
    "        model.train() \n",
    "\n",
    "    adversarial_samples = []\n",
    "\n",
    "    for batch_idx, (wind_history, future_weather, true_power) in enumerate(test_loader):\n",
    "        wind_history = wind_history.to(device)\n",
    "        future_weather = future_weather.to(device)\n",
    "        true_power = true_power.to(device)\n",
    "\n",
    "        A_ori_list = []\n",
    "        for model in surrogate_models:\n",
    "            A_ori = compute_attention(model, wind_history, future_weather, baseline_type='original')\n",
    "            A_ori_list.append(A_ori.detach())\n",
    "\n",
    "        future_weather_adv = future_weather.detach().clone().requires_grad_(True)\n",
    "        optimizer = optim.Adam([future_weather_adv], lr=learning_rate)\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            optimizer.zero_grad()\n",
    "            total_loss = 0.0\n",
    "\n",
    "            for i, model in enumerate(surrogate_models):\n",
    "                A_adv = compute_attention(model, wind_history, future_weather_adv, baseline_type='original')\n",
    "                A_ori_flat = A_ori_list[i].reshape(A_ori_list[i].size(0), -1)  \n",
    "                A_adv_flat = A_adv.reshape(A_adv.size(0), -1)\n",
    "                cos_sim = nn.functional.cosine_similarity(A_ori_flat, A_adv_flat, dim=1)\n",
    "                L_aoa = -cos_sim.mean()\n",
    "\n",
    "                pred_adv = model(wind_history, future_weather_adv).squeeze()\n",
    "                pred_ori = model(wind_history, future_weather).squeeze().detach()\n",
    "                L_reg = -pred_adv.mean()\n",
    "\n",
    "                loss = lambda_aoa * L_aoa + lambda_reg * L_reg\n",
    "                total_loss += loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                future_weather_adv.data = torch.clamp(\n",
    "                    future_weather_adv,\n",
    "                    min=future_weather - epsilon,\n",
    "                    max=future_weather + epsilon\n",
    "                )\n",
    "\n",
    "        adversarial_samples.append({\n",
    "            'index': batch_idx,\n",
    "            'wind_history': wind_history.cpu().detach().numpy(),\n",
    "            'future_weather_original': future_weather.cpu().detach().numpy(),\n",
    "            'future_weather_adversarial': future_weather_adv.cpu().detach().numpy(),\n",
    "            'true_power': true_power.cpu().detach().numpy()\n",
    "        })\n",
    "\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Batch {batch_idx}, Loss: {total_loss.item():.4f}\")\n",
    "    return adversarial_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4077fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack_with_mae(surrogate_models, adversarial_samples, device, wind_power_scaler=None):\n",
    "    results = []\n",
    "    for model_idx, model in enumerate(surrogate_models):\n",
    "        model.eval()\n",
    "        total_bias = 0.0\n",
    "        total_mae_ori = 0.0\n",
    "        total_mae_adv = 0.0\n",
    "        count = 0\n",
    "        \n",
    "        for sample in adversarial_samples:\n",
    "            wind_history = torch.tensor(sample['wind_history'], dtype=torch.float32).to(device)\n",
    "            future_weather_ori = torch.tensor(sample['future_weather_original'], dtype=torch.float32).to(device)\n",
    "            future_weather_adv = torch.tensor(sample['future_weather_adversarial'], dtype=torch.float32).to(device)\n",
    "            true_power = torch.tensor(sample['true_power'], dtype=torch.float32).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred_ori = model(wind_history, future_weather_ori).squeeze()\n",
    "                pred_adv = model(wind_history, future_weather_adv).squeeze()\n",
    "                \n",
    "                bias = (pred_adv - pred_ori).mean().item()\n",
    "                total_bias += bias\n",
    "                \n",
    "                mae_ori = torch.abs(pred_ori - true_power).mean().item()\n",
    "                mae_adv = torch.abs(pred_adv - true_power).mean().item()\n",
    "                total_mae_ori += mae_ori\n",
    "                total_mae_adv += mae_adv\n",
    "                \n",
    "                count += 1\n",
    "        \n",
    "        avg_bias = total_bias / count\n",
    "        avg_mae_ori = total_mae_ori / count\n",
    "        avg_mae_adv = total_mae_adv / count\n",
    "        mae_increase = avg_mae_adv - avg_mae_ori\n",
    "        \n",
    "        result = {\n",
    "            'model_idx': model_idx,\n",
    "            'avg_prediction_bias': avg_bias,\n",
    "            'avg_mae_original': avg_mae_ori,\n",
    "            'avg_mae_adversarial': avg_mae_adv,\n",
    "            'mae_increase': mae_increase\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"Model {model_idx}:\")\n",
    "        print(f\"adversarial MAE = {avg_mae_adv:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f7390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_aoa_adversarial_samples(\n",
    "    surrogate_models,\n",
    "    test_loader,\n",
    "    device,\n",
    "    epsilon=0.1,\n",
    "    num_steps=80,\n",
    "    learning_rate=0.003,\n",
    "    lambda_aoa=1.0,\n",
    "    lambda_reg=10.0,\n",
    "):\n",
    "    for model in surrogate_models:\n",
    "        model.train()  \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad_(False)\n",
    "\n",
    "    adversarial_samples = []\n",
    "\n",
    "    for batch_idx, (wind_history, future_weather, true_power) in enumerate(test_loader):\n",
    "        wind_history = wind_history.to(device)\n",
    "        future_weather = future_weather.to(device)\n",
    "        true_power = true_power.to(device)\n",
    "\n",
    "        # Compute original attention from all surrogate models\n",
    "        A_ori_list = []\n",
    "        for model in surrogate_models:\n",
    "            A_ori = compute_attention(model, wind_history, future_weather, baseline_type='original')\n",
    "            A_ori_list.append(A_ori.detach())\n",
    "\n",
    "        # Initialize adversarial input\n",
    "        future_weather_adv = future_weather.clone().detach().requires_grad_(True)\n",
    "        optimizer = torch.optim.Adam([future_weather_adv], lr=learning_rate)\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            optimizer.zero_grad()\n",
    "            total_loss = 0.0\n",
    "\n",
    "            for i, model in enumerate(surrogate_models):\n",
    "                A_adv = compute_attention(model, wind_history, future_weather_adv, baseline_type='original')\n",
    "                A_ori_flat = A_ori_list[i].reshape(A_ori_list[i].size(0), -1)\n",
    "                A_adv_flat = A_adv.reshape(A_adv.size(0), -1)\n",
    "                cos_sim = torch.nn.functional.cosine_similarity(A_ori_flat, A_adv_flat, dim=1)\n",
    "                L_aoa = -cos_sim.mean()\n",
    "\n",
    "                pred_adv = model(wind_history, future_weather_adv).squeeze()\n",
    "                L_reg = -pred_adv.mean()  # maximize prediction\n",
    "\n",
    "                loss = lambda_aoa * L_aoa + lambda_reg * L_reg\n",
    "                total_loss += loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                future_weather_adv.clamp_(min=future_weather - epsilon, max=future_weather + epsilon)\n",
    "                future_weather_adv.clamp_(0.0, 1.0)\n",
    "\n",
    "        adversarial_samples.append({\n",
    "            'wind_history': wind_history.detach().cpu().numpy(),\n",
    "            'future_weather_original': future_weather.detach().cpu().numpy(),\n",
    "            'future_weather_adversarial': future_weather_adv.detach().cpu().numpy(),\n",
    "            'true_power': true_power.detach().cpu().numpy()\n",
    "        })\n",
    "\n",
    "    return adversarial_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416464f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_aoa_on_target_model(\n",
    "    target_model,\n",
    "    adversarial_samples,\n",
    "    device,\n",
    "    wind_power_scaler\n",
    "):\n",
    "    target_model.eval()\n",
    "    all_targets = []\n",
    "    all_preds_original = []\n",
    "    all_preds_adversarial = []\n",
    "\n",
    "    for sample in adversarial_samples:\n",
    "        wind_history = torch.tensor(sample['wind_history'], dtype=torch.float32).to(device)\n",
    "        weather_orig = torch.tensor(sample['future_weather_original'], dtype=torch.float32).to(device)\n",
    "        weather_adv = torch.tensor(sample['future_weather_adversarial'], dtype=torch.float32).to(device)\n",
    "        true_power = torch.tensor(sample['true_power'], dtype=torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_orig = target_model(wind_history, weather_orig).squeeze()\n",
    "            pred_adv = target_model(wind_history, weather_adv).squeeze()\n",
    "\n",
    "        all_targets.append(true_power.cpu().numpy())\n",
    "        all_preds_original.append(pred_orig.cpu().numpy())\n",
    "        all_preds_adversarial.append(pred_adv.cpu().numpy())\n",
    "\n",
    "    all_targets = np.concatenate(all_targets).flatten()\n",
    "    all_preds_orig = np.concatenate(all_preds_original).flatten()\n",
    "    all_preds_adv = np.concatenate(all_preds_adversarial).flatten()\n",
    "\n",
    "    # Inverse transform to original scale\n",
    "    all_targets_inv = wind_power_scaler.inverse_transform(all_targets.reshape(-1, 1)).squeeze()\n",
    "    all_preds_orig_inv = wind_power_scaler.inverse_transform(all_preds_orig.reshape(-1, 1)).squeeze()\n",
    "    all_preds_adv_inv = wind_power_scaler.inverse_transform(all_preds_adv.reshape(-1, 1)).squeeze()\n",
    "\n",
    "    mae_orig = mean_absolute_error(all_targets_inv, all_preds_orig_inv)\n",
    "    mae_adv = mean_absolute_error(all_targets_inv, all_preds_adv_inv)\n",
    "    rmse_adv = mean_squared_error(all_targets_inv, all_preds_adv_inv, squared=False)\n",
    "\n",
    "    return {\n",
    "        'mae_original': mae_orig,\n",
    "        'mae_adversarial': mae_adv,\n",
    "        'rmse_adversarial': rmse_adv,\n",
    "        'mae_increase': mae_adv - mae_orig\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97538526",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_list = [0.03, 0.05, 0.10]\n",
    "\n",
    "surrogate_models_for_aoa = sur_model_list  \n",
    "\n",
    "for epsilon in epsilon_list:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" AoA Attack (Multi-Surrogate) | ε = {epsilon}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    aoa_samples = generate_aoa_adversarial_samples(\n",
    "        surrogate_models=surrogate_models_for_aoa,  \n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        epsilon=epsilon,\n",
    "        num_steps=80,\n",
    "        learning_rate=0.003,\n",
    "        lambda_aoa=1.0,\n",
    "        lambda_reg=10.0\n",
    "    )\n",
    "\n",
    "    for tar_model in tar_model_list:\n",
    "        metrics = evaluate_aoa_on_target_model(\n",
    "            tar_model, aoa_samples, device, wind_power_scaler\n",
    "        )\n",
    "        print(f\"MAE_adv: {metrics['mae_adversarial']:.6f}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355603e5",
   "metadata": {},
   "source": [
    "## UP/RUP/RUPW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e92fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_attack_inde(uap_loaded, model, data_loader, device='cpu'):\n",
    "    model.eval()  \n",
    "    all_preds = []\n",
    "    all_adversarial_preds = []\n",
    "    all_targets = []\n",
    "    all_original_weather = []\n",
    "    all_adversarial_weather = []\n",
    "    for wind_history, weather_future, future_wind_power in data_loader:\n",
    "        wind_history = wind_history.to(device)\n",
    "        weather_future = weather_future.to(device)\n",
    "        future_wind_power = future_wind_power.to(device)\n",
    "        original_output = model(wind_history, weather_future)\n",
    "        adversarial_weather = weather_future + uap_loaded\n",
    "        adversarial_weather = torch.clamp(adversarial_weather, 0, 1)  \n",
    "        adversarial_output = model(wind_history, adversarial_weather.detach())  \n",
    "        all_preds.append(original_output.detach().cpu().numpy())\n",
    "        all_adversarial_preds.append(adversarial_output.detach().cpu().numpy())\n",
    "        all_targets.append(future_wind_power.cpu().numpy())\n",
    "        all_original_weather.append(weather_future.detach().cpu().numpy())\n",
    "        all_adversarial_weather.append(adversarial_weather.detach().cpu().numpy())\n",
    "    model.eval()  \n",
    "    return all_preds, all_adversarial_preds, all_targets, all_original_weather, all_adversarial_weather\n",
    "\n",
    "\n",
    "def evaluate_uap_on_target(uap_tensor, target_model, data_loader, scaler, device):\n",
    "    _, adv_preds, targets, _, _ = adversarial_attack_inde(\n",
    "        uap_tensor, target_model, data_loader, device=device\n",
    "    )\n",
    "    \n",
    "    adv_flat = np.concatenate(adv_preds).flatten()\n",
    "    tgt_flat = np.concatenate(targets).flatten()\n",
    "\n",
    "    tgt_inv = scaler.inverse_transform(tgt_flat.reshape(-1, 1)).squeeze()\n",
    "    pred_inv = scaler.inverse_transform(adv_flat.reshape(-1, 1)).squeeze()\n",
    "    \n",
    "    mae = mean_absolute_error(tgt_inv, pred_inv)\n",
    "    rmse = mean_squared_error(tgt_inv, pred_inv, squared=False)\n",
    "    r2 = r2_score(tgt_inv, pred_inv)\n",
    "    \n",
    "    return {'mae': mae, 'rmse': rmse, 'r2': r2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d73bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [('003', 0.03), ('005', 0.05), ('010', 0.10)]\n",
    "model_names = ['tcn', 'lstm', 'gru', 'transformer']\n",
    "\n",
    "for suffix, epsilon_val in epsilons:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Universal Attacks | ε = {epsilon_val}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # === Load all UAPs (flattened across models) ===\n",
    "    all_uaps = []\n",
    "    for name in model_names:\n",
    "        pkl_path = f'uap_results_{name}_epsilon_{suffix}.pkl'\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            uap_list = data['uap_list']\n",
    "            for uap_np in uap_list:\n",
    "                if isinstance(uap_np, torch.Tensor):\n",
    "                    uap_np = uap_np.cpu().numpy()\n",
    "                uap_tensor = torch.tensor(uap_np, dtype=torch.float32).to(device)\n",
    "                all_uaps.append(uap_tensor)\n",
    "\n",
    "    # === Load RUP ===\n",
    "    with open(f'rup_ensemble_{suffix}_caiso.pkl', 'rb') as f:\n",
    "        rup_np = pickle.load(f)\n",
    "    if isinstance(rup_np, torch.Tensor):\n",
    "        rup_np = rup_np.cpu().numpy()\n",
    "    rup_tensor = torch.tensor(rup_np, dtype=torch.float32).to(device)\n",
    "\n",
    "    # === Load RUPW ===\n",
    "    with open(f'RUPW{suffix}_caiso.pkl', 'rb') as f:\n",
    "        rupw_np = pickle.load(f)\n",
    "    if isinstance(rupw_np, torch.Tensor):\n",
    "        rupw_np = rupw_np.cpu().numpy()\n",
    "    rupw_tensor = torch.tensor(rupw_np, dtype=torch.float32).to(device)\n",
    "\n",
    "    # === Evaluate on each target model ===\n",
    "    for tar_model in tar_model_list:\n",
    "        # --- Print each UAP individually ---\n",
    "        for idx, uap_tensor in enumerate(all_uaps):\n",
    "            metrics = evaluate_uap_on_target(uap_tensor, tar_model, test_loader, wind_power_scaler, device)\n",
    "            print(f\"  UAP #{idx:02d}             | MAE: {metrics['mae']:.6f}, RMSE: {metrics['rmse']:.6f}\")\n",
    "\n",
    "        # --- RUP ---\n",
    "        rup_metrics = evaluate_uap_on_target(rup_tensor, tar_model, test_loader, wind_power_scaler, device)\n",
    "        print(f\"  RUP (weighted)         | MAE: {rup_metrics['mae']:.6f}, RMSE: {rup_metrics['rmse']:.6f}\")\n",
    "\n",
    "        # --- RUPW ---\n",
    "        rupw_metrics = evaluate_uap_on_target(rupw_tensor, tar_model, test_loader, wind_power_scaler, device)\n",
    "        print(f\"  RUPW (average)         | MAE: {rupw_metrics['mae']:.6f}, RMSE: {rupw_metrics['rmse']:.6f}\")\n",
    "        \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166fe43f",
   "metadata": {},
   "source": [
    "### execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951adac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# UP/RUP/RUPW\n",
    "name='lstm'\n",
    "suffix='010'\n",
    "pkl_path = f'uap_results_{name}_epsilon_{suffix}.pkl'\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    uap_list = data['uap_list']\n",
    "uap_loaded = uap_list[0].to(device)\n",
    "\n",
    "times = []\n",
    "count = 0\n",
    "\n",
    "total_start = time.perf_counter()\n",
    "\n",
    "for wind_history, weather_future, future_wind_power in test_loader:\n",
    "    count += 1\n",
    "    iter_start = time.perf_counter()\n",
    "    wind_history = wind_history.to(device)\n",
    "    weather_future = weather_future.to(device)\n",
    "    future_wind_power = future_wind_power.to(device)\n",
    "\n",
    "    adversarial_weather = weather_future + uap_loaded\n",
    "    adversarial_weather = torch.clamp(adversarial_weather, 0.0, 1.0)\n",
    "\n",
    "    iter_end = time.perf_counter()\n",
    "    times.append(iter_end - iter_start)\n",
    "\n",
    "total_end = time.perf_counter()\n",
    "\n",
    "times_ms = np.array(times) * 1000\n",
    "mean_ms = times_ms.mean()\n",
    "std_ms = times_ms.std(ddof=1)  \n",
    "\n",
    "print(f\"   UAP : {mean_ms:.2f} ms ± {std_ms:.2f} ms\")\n",
    "print(f\"   count: {count}\")\n",
    "print(f\"   total time: {total_end - total_start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e67a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM\n",
    "\n",
    "epsilon = 0.1  \n",
    "\n",
    "surrogate_model = sur_model4\n",
    "surrogate_model.train() \n",
    "\n",
    "for p in surrogate_model.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "times = []\n",
    "count = 0\n",
    "\n",
    "total_start = time.perf_counter()\n",
    "\n",
    "for wind_history, weather_future, future_wind_power in test_loader:\n",
    "    count += 1\n",
    "    iter_start = time.perf_counter()\n",
    "    wind_history = wind_history.to(device)\n",
    "    weather_future = weather_future.to(device)\n",
    "    adv_input = weather_future.clone().detach().requires_grad_(True)\n",
    "\n",
    "    output = surrogate_model(wind_history, adv_input)\n",
    "    loss = -output.sum()  \n",
    "\n",
    "    surrogate_model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        perturbation = epsilon * adv_input.grad.sign()\n",
    "        adversarial_weather = weather_future + perturbation\n",
    "        adversarial_weather = torch.clamp(adversarial_weather, 0.0, 1.0)\n",
    "\n",
    "    iter_end = time.perf_counter()\n",
    "    times.append(iter_end - iter_start)\n",
    "\n",
    "total_end = time.perf_counter()\n",
    "\n",
    "times_ms = np.array(times) * 1000\n",
    "mean_ms = times_ms.mean()\n",
    "std_ms = times_ms.std(ddof=1)\n",
    "\n",
    "print(f\" FGSM: {mean_ms:.3f} ms ± {std_ms:.3f} ms\")\n",
    "print(f\" count: {count}\")\n",
    "print(f\" total time: {total_end - total_start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD attack\n",
    "\n",
    "alpha = 0.005\n",
    "epsilon = 0.1\n",
    "num_iterations = 80\n",
    "\n",
    "surrogate_model = sur_model4\n",
    "surrogate_model.train() \n",
    "\n",
    "for p in surrogate_model.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "times = []\n",
    "count = 0\n",
    "\n",
    "total_start = time.perf_counter()\n",
    "\n",
    "for wind_history, weather_future, future_wind_power in test_loader:\n",
    "    count += 1\n",
    "    iter_start = time.perf_counter()\n",
    "    wind_history = wind_history.to(device)\n",
    "    weather_future = weather_future.to(device)\n",
    "    future_wind_power = future_wind_power.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        original_output = surrogate_model(wind_history, weather_future)\n",
    "    original_output = original_output.detach()\n",
    "\n",
    "    adversarial_weather = weather_future.clone().detach().requires_grad_(True)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        adversarial_output = surrogate_model(wind_history, adversarial_weather)\n",
    "\n",
    "        loss = torch.sum(adversarial_output.squeeze() - original_output.squeeze())\n",
    "\n",
    "        surrogate_model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            adversarial_weather += alpha * adversarial_weather.grad.sign()\n",
    "            adversarial_weather = torch.clamp(\n",
    "                adversarial_weather,\n",
    "                min=weather_future - epsilon,\n",
    "                max=weather_future + epsilon\n",
    "            )\n",
    "            adversarial_weather = torch.clamp(adversarial_weather, 0.0, 1.0)\n",
    "            adversarial_weather = adversarial_weather.detach().requires_grad_(True)\n",
    "\n",
    "    iter_end = time.perf_counter()\n",
    "    times.append(iter_end - iter_start)\n",
    "\n",
    "total_end = time.perf_counter()\n",
    "\n",
    "times_ms = np.array(times) * 1000\n",
    "mean_ms = times_ms.mean()\n",
    "std_ms = times_ms.std(ddof=1)\n",
    "\n",
    "print(f\"   PGD ({num_iterations} iters): {mean_ms:.2f} ms ± {std_ms:.2f} ms\")\n",
    "print(f\"   count: {count}\")\n",
    "print(f\"   total time: {total_end - total_start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144646dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RA\n",
    "\n",
    "times = []\n",
    "count = 0\n",
    "\n",
    "total_start = time.perf_counter()\n",
    "\n",
    "for wind_history, weather_future, future_wind_power in test_loader:\n",
    "    count += 1\n",
    "    iter_start = time.perf_counter()\n",
    "    wind_history = wind_history.to(device)\n",
    "    weather_future = weather_future.to(device)\n",
    "    future_wind_power = future_wind_power.to(device)\n",
    "    noise = torch.randn_like(weather_future)  \n",
    "    adversarial_weather = weather_future + noise\n",
    "    adversarial_weather = torch.clamp(adversarial_weather, 0.0, 1.0)\n",
    "\n",
    "    iter_end = time.perf_counter()\n",
    "    times.append(iter_end - iter_start)\n",
    "\n",
    "total_end = time.perf_counter()\n",
    "\n",
    "times_ms = np.array(times) * 1000\n",
    "mean_ms = times_ms.mean()\n",
    "std_ms = times_ms.std(ddof=1)  \n",
    "\n",
    "print(f\"   RA: {mean_ms:.3f} ms ± {std_ms:.3f} ms\")\n",
    "print(f\"   count: {count}\")\n",
    "print(f\"   total time: {total_end - total_start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AOA attack\n",
    "epsilon = 0.10         \n",
    "num_steps = 80\n",
    "learning_rate = 0.003\n",
    "lambda_aoa = 1.0\n",
    "lambda_reg = 10.0\n",
    "\n",
    "surrogate_models = sur_model_list\n",
    "for model in surrogate_models:\n",
    "    model.train()\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad_(False)\n",
    "\n",
    "times = []\n",
    "count = 0\n",
    "total_start = time.perf_counter()\n",
    "\n",
    "for wind_history, future_weather, true_power in test_loader:\n",
    "    count += 1\n",
    "    iter_start = time.perf_counter()\n",
    "    \n",
    "    wind_history = wind_history.to(device)\n",
    "    future_weather = future_weather.to(device)\n",
    "    true_power = true_power.to(device)\n",
    "\n",
    "    # Step 1: Compute original attention (once per batch)\n",
    "    A_ori_list = []\n",
    "    for model in surrogate_models:\n",
    "        A_ori = compute_attention(model, wind_history, future_weather, baseline_type='original')\n",
    "        A_ori_list.append(A_ori.detach())\n",
    "\n",
    "    # Step 2: Initialize adversarial input\n",
    "    future_weather_adv = future_weather.clone().detach().requires_grad_(True)\n",
    "    optimizer = torch.optim.Adam([future_weather_adv], lr=learning_rate)\n",
    "\n",
    "    # Step 3: Optimization loop\n",
    "    for step in range(num_steps):\n",
    "        optimizer.zero_grad()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for i, model in enumerate(surrogate_models):\n",
    "            A_adv = compute_attention(model, wind_history, future_weather_adv, baseline_type='original')\n",
    "            A_ori_flat = A_ori_list[i].reshape(A_ori_list[i].size(0), -1)\n",
    "            A_adv_flat = A_adv.reshape(A_adv.size(0), -1)\n",
    "            cos_sim = torch.nn.functional.cosine_similarity(A_ori_flat, A_adv_flat, dim=1)\n",
    "            L_aoa = -cos_sim.mean()\n",
    "\n",
    "            pred_adv = model(wind_history, future_weather_adv).squeeze()\n",
    "            L_reg = -pred_adv.mean()\n",
    "\n",
    "            loss = lambda_aoa * L_aoa + lambda_reg * L_reg\n",
    "            total_loss += loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            future_weather_adv.clamp_(min=future_weather - epsilon, max=future_weather + epsilon)\n",
    "            future_weather_adv.clamp_(0.0, 1.0)\n",
    "\n",
    "    iter_end = time.perf_counter()\n",
    "    times.append(iter_end - iter_start)\n",
    "\n",
    "total_end = time.perf_counter()\n",
    "\n",
    "# ====== Output ======\n",
    "times_ms = np.array(times) * 1000\n",
    "mean_ms = times_ms.mean()\n",
    "std_ms = times_ms.std(ddof=1)\n",
    "\n",
    "print(f\"   AoA: {mean_ms:.3f} ms ± {std_ms:.3f} ms\")\n",
    "print(f\"   count: {count}\")\n",
    "print(f\"   total time: {total_end - total_start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846d554a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
