{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3641e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import random\n",
    "import os\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(42)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09873507",
   "metadata": {},
   "source": [
    "## 0. Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b676daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerDataset(Dataset):\n",
    "    def __init__(self, csv_file, wind_power_scaler=None, weather_scaler=None, save_scalers=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.data = self.data.iloc[::5, :].reset_index(drop=True)\n",
    "\n",
    "        self.original_wind_power_std = self.data.iloc[:, 2].std()\n",
    "        self.original_weather_std = self.data.iloc[:, 4:12].std()\n",
    "\n",
    "        if wind_power_scaler is None or weather_scaler is None:\n",
    "            self.wind_power_scaler = MinMaxScaler()\n",
    "            self.weather_scaler = MinMaxScaler()\n",
    "\n",
    "            self.data.iloc[:, 2] = self.wind_power_scaler.fit_transform(self.data.iloc[:, 2].values.reshape(-1, 1)).squeeze()\n",
    "\n",
    "            self.data.iloc[:, 4:12] = self.weather_scaler.fit_transform(self.data.iloc[:, 4:12])\n",
    "            \n",
    "            if save_scalers:\n",
    "                with open('wind_power_scaler.pkl', 'wb') as f:\n",
    "                    pickle.dump(self.wind_power_scaler, f)\n",
    "                with open('weather_scaler.pkl', 'wb') as f:\n",
    "                    pickle.dump(self.weather_scaler, f)\n",
    "        else:\n",
    "            self.wind_power_scaler = wind_power_scaler\n",
    "            self.weather_scaler = weather_scaler\n",
    "            self.data.iloc[:, 2] = self.wind_power_scaler.transform(self.data.iloc[:, 2].values.reshape(-1, 1)).squeeze()\n",
    "            self.data.iloc[:, 4:12] = self.weather_scaler.transform(self.data.iloc[:, 4:12])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - 312  # 288 (1440/5) + 24 (120/5)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        history_weather = self.data.iloc[idx:idx + 288, 4:12].values.astype(float)  # [288, 8]\n",
    "        wind_power_history = self.data.iloc[idx:idx + 288, 2].values.astype(float)   # [288]\n",
    "        future_weather = self.data.iloc[idx + 288:idx + 312, 4:12].values.astype(float)  # [24, 8]\n",
    "        future_wind_power = self.data.iloc[idx + 312, 2]  # float\n",
    "\n",
    "        return (\n",
    "            #torch.tensor(history_weather, dtype=torch.float32),\n",
    "            torch.tensor(wind_power_history, dtype=torch.float32),\n",
    "            torch.tensor(future_weather, dtype=torch.float32),\n",
    "            torch.tensor(future_wind_power, dtype=torch.float32)\n",
    "        )\n",
    "    \n",
    "    def get_original_stds(self):\n",
    "        return {\n",
    "            'original_wind_power_std': self.original_wind_power_std,\n",
    "            'original_weather_std': self.original_weather_std.to_dict()\n",
    "        }\n",
    "    \n",
    "name='CAISO_zone_1_.csv'\n",
    "with open('weather_scaler.pkl', 'rb') as f:\n",
    "    weather_scaler = pickle.load(f)\n",
    "dataset = WindPowerDataset(name, save_scalers=True)\n",
    "wind_power_scaler=dataset.wind_power_scaler\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size=32\n",
    "test_split=0.2\n",
    "test_size = int(len(dataset) * test_split)\n",
    "train_size = len(dataset) - test_size\n",
    "train_dataset = Subset(dataset, list(range(train_size)))\n",
    "test_dataset = Subset(dataset, list(range(train_size, len(dataset))))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4cd865",
   "metadata": {},
   "source": [
    "## 1. preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.lstm_wind = nn.LSTM(input_size=1, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm_weather = nn.LSTM(input_size=8, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(256, 1)\n",
    "        self.relu=nn.ReLU()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = wind_history.unsqueeze(-1)\n",
    "        _, (hn_wind, _) = self.lstm_wind(wind_history)\n",
    "        _, (hn_weather, _) = self.lstm_weather(weather_future)\n",
    "        hn_wind = hn_wind[-1, :, :]\n",
    "        hn_weather = hn_weather[-1, :, :]\n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.relu(output)\n",
    "        return output\n",
    "    \n",
    "def load_model(model_path, device='cpu'):\n",
    "    model = WindPowerPredictor().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tar_model_path1 = 'wind_caiso_lstm_sigmoid_version2.pth'\n",
    "tar_model1 = load_model(tar_model_path1, device)\n",
    "\n",
    "class WindPowerPredictor(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(WindPowerPredictor, self).__init__()  \n",
    "        self.gru_wind = nn.GRU(input_size=1, hidden_size=128, num_layers=1, batch_first=True)  \n",
    "        self.gru_weather = nn.GRU(input_size=8, hidden_size=128, num_layers=1, batch_first=True)  \n",
    "        self.fc = nn.Linear(256, 1)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "      \n",
    "    def forward(self, wind_history, weather_future):  \n",
    "        wind_history = wind_history.unsqueeze(-1)  \n",
    "        _, hn_wind = self.gru_wind(wind_history)  \n",
    "        _, hn_weather = self.gru_weather(weather_future)  \n",
    "        hn_wind = hn_wind[-1, :, :]  \n",
    "        hn_weather = hn_weather[-1, :, :]  \n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)  \n",
    "        output = self.fc(combined)  \n",
    "        output = self.sigmoid(output)\n",
    "        return output  \n",
    "\n",
    "tar_model_path2 = 'wind_gru_caiso_sigmoid_version2.pth'\n",
    "tar_model2 = load_model(tar_model_path2, device)\n",
    "\n",
    "class WindPowerPredictorV2(nn.Module):\n",
    "    def __init__(self, d_model=64, nhead=4, num_layers=3, dim_feedforward=128, dropout=0.1, max_seq_len=300):\n",
    "        super(WindPowerPredictorV2, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.embedding_wind = nn.Linear(1, d_model)\n",
    "        self.embedding_weather = nn.Linear(8, d_model)\n",
    "\n",
    "        self.pos_encoder_wind = nn.Parameter(torch.zeros(max_seq_len, 1, d_model))\n",
    "        self.pos_encoder_weather = nn.Parameter(torch.zeros(max_seq_len, 1, d_model))\n",
    "\n",
    "\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=False\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "\n",
    "        self.fc_combine = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, wind_history, weather_future):\n",
    "        # wind_history: (batch_size, T1)        e.g., (32, 288)\n",
    "        # weather_future: (batch_size, T2, 8)    e.g., (32, 24, 8)\n",
    "\n",
    "        batch_size, seq_len_wind = wind_history.shape\n",
    "        _, seq_len_weather, _ = weather_future.shape\n",
    "\n",
    "        if seq_len_wind > self.pos_encoder_wind.size(0):\n",
    "            raise ValueError(f\"Wind sequence length {seq_len_wind} exceeds max supported length {self.pos_encoder_wind.size(0)}\")\n",
    "        if seq_len_weather > self.pos_encoder_weather.size(0):\n",
    "            raise ValueError(f\"Weather sequence length {seq_len_weather} exceeds max supported length {self.pos_encoder_weather.size(0)}\")\n",
    "\n",
    "        wind_emb = self.embedding_wind(wind_history.unsqueeze(-1))           # (B, T1, D)\n",
    "        weather_emb = self.embedding_weather(weather_future)                 # (B, T2, D)\n",
    "\n",
    "        wind_emb = wind_emb.permute(1, 0, 2)  # (T1, B, D)\n",
    "        weather_emb = weather_emb.permute(1, 0, 2)  # (T2, B, D)\n",
    "\n",
    "        wind_emb = wind_emb + self.pos_encoder_wind[:seq_len_wind]      # (T1, B, D)\n",
    "        weather_emb = weather_emb + self.pos_encoder_weather[:seq_len_weather]  # (T2, B, D)\n",
    "\n",
    "        wind_features = self.transformer_encoder(wind_emb)              # (T1, B, D)\n",
    "        weather_features = self.transformer_encoder(weather_emb)        # (T2, B, D)\n",
    "\n",
    "        wind_last = wind_features[-1, :, :]        \n",
    "        weather_last = weather_features[-1, :, :]  \n",
    "\n",
    "        combined = torch.cat((wind_last, weather_last), dim=1)  # (B, 2D)\n",
    "\n",
    "        output = self.fc_combine(combined)  # (B, 1)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "    \n",
    "tar_model_path3 = 'wind_caiso_transformer_sigmoid_version2.pth'\n",
    "tar_model3 = WindPowerPredictorV2().to(device)\n",
    "state_dict = torch.load(tar_model_path3, map_location=device)\n",
    "tar_model3.load_state_dict(state_dict)\n",
    "tar_model3.to(device)\n",
    "\n",
    "class TemporalConvNet_V2(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=3, dropout=0.2):\n",
    "        super(TemporalConvNet_V2, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "\n",
    "            padding = (kernel_size - 1) * dilation_size\n",
    "\n",
    "            conv = nn.Conv1d(\n",
    "                in_channels, out_channels, kernel_size,\n",
    "                stride=1, padding=padding, dilation=dilation_size  \n",
    "            )\n",
    "            relu = nn.ReLU()\n",
    "            drop = nn.Dropout(dropout)\n",
    "\n",
    "            if in_channels != out_channels:\n",
    "                res_conv = nn.Conv1d(in_channels, out_channels, 1)\n",
    "            else:\n",
    "                res_conv = None\n",
    "\n",
    "            layers.append(nn.ModuleDict({\n",
    "                'conv': conv,\n",
    "                'relu': relu,\n",
    "                'dropout': drop,\n",
    "                'res_conv': res_conv\n",
    "            }))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, in_channels, seq_len)\n",
    "        for layer in self.layers:\n",
    "            residual = x  \n",
    "\n",
    "            x = layer['conv'](x)  \n",
    "            x = layer['relu'](x)\n",
    "            x = layer['dropout'](x)\n",
    "            x = x[:, :, :residual.size(2)]  \n",
    "\n",
    "            # 残差连接\n",
    "            if layer['res_conv'] is not None:\n",
    "                residual = layer['res_conv'](residual)\n",
    "            x = x + residual\n",
    "            x = layer['relu'](x)  \n",
    "        return x\n",
    "\n",
    "\n",
    "class WindPowerPredictorTCN_V2(nn.Module):\n",
    "    def __init__(self, d_model=64, dropout=0.2, fusion_mode='concat'):\n",
    "        super(WindPowerPredictorTCN_V2, self).__init__()\n",
    "        self.fusion_mode = fusion_mode  # 'concat' or 'add'\n",
    "        self.tcn_wind = TemporalConvNet_V2(\n",
    "            num_inputs=1,\n",
    "            num_channels=[d_model, d_model*2, d_model, d_model],  \n",
    "            kernel_size=3,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.tcn_weather = TemporalConvNet_V2(\n",
    "            num_inputs=8,\n",
    "            num_channels=[d_model, d_model*2, d_model, d_model],\n",
    "            kernel_size=3,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        if fusion_mode == 'concat':\n",
    "            fc_input_dim = d_model * 2\n",
    "        elif fusion_mode == 'add':\n",
    "            fc_input_dim = d_model\n",
    "        else:\n",
    "            raise ValueError(\"fusion_mode must be 'concat' or 'add'\")\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(fc_input_dim, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, wind_history, weather_future):\n",
    "        # wind_history: (batch_size, 288)\n",
    "        # weather_future: (batch_size, 24, 8)\n",
    "\n",
    "        x_wind = wind_history.unsqueeze(1)  # (B, 1, 288)\n",
    "        x_wind = self.tcn_wind(x_wind)     # (B, D, 288)\n",
    "        x_wind = x_wind[:, :, -1]          \n",
    "\n",
    "        x_weather = weather_future.transpose(1, 2)  # (B, 8, 24)\n",
    "        x_weather = self.tcn_weather(x_weather)     # (B, D, 24)\n",
    "        x_weather = x_weather[:, :, -1]             # -> (B, D)\n",
    "\n",
    "        if self.fusion_mode == 'concat':\n",
    "            combined = torch.cat((x_wind, x_weather), dim=1)  # (B, 2D)\n",
    "        elif self.fusion_mode == 'add':\n",
    "            combined = x_wind + x_weather  \n",
    "\n",
    "        output = self.fc(combined)         # (B, 1)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "    \n",
    "tar_model_path4 = 'wind_tcn_caiso_sigmoid_v2.pth'\n",
    "tar_model4 = WindPowerPredictorTCN_V2()\n",
    "state_dict = torch.load(tar_model_path4, map_location=device)\n",
    "tar_model4.load_state_dict(state_dict)\n",
    "tar_model4.to(device)\n",
    "\n",
    "tar_model_list = [tar_model1, tar_model2, tar_model3, tar_model4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bfe0e8",
   "metadata": {},
   "source": [
    "## 2. PALM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "# ----------------------------\n",
    "# 物理约束计算函数\n",
    "# ----------------------------\n",
    "import torch\n",
    "\n",
    "def compute_constraints(weather_future, weather_scaler):\n",
    "    # 获取张量的形状\n",
    "    batch_size, seq_len, feature_dim = weather_future.shape\n",
    "\n",
    "    # 反归一化数据\n",
    "    weather_future_reshaped = weather_future.view(-1, feature_dim)\n",
    "    weather_future_unscaled = weather_scaler.inverse_transform(weather_future_reshaped.detach().numpy())\n",
    "    weather_future_unscaled = torch.tensor(weather_future_unscaled).view(batch_size, seq_len, feature_dim)\n",
    "\n",
    "    # 提取物理参数\n",
    "    DNI = weather_future_unscaled[:, :, 1]\n",
    "    Solar_Zenith_Angle = weather_future_unscaled[:, :, 4]\n",
    "    DHI = weather_future_unscaled[:, :, 0]\n",
    "    GHI = weather_future_unscaled[:, :, 2]\n",
    "    Dew_Point = weather_future_unscaled[:, :, 3]\n",
    "    Temperature = weather_future_unscaled[:, :, 7]\n",
    "    Relative_Humidity = weather_future_unscaled[:, :, 6]\n",
    "\n",
    "    # 计算物理约束\n",
    "    constraint_1 = torch.abs((DNI * torch.cos(Solar_Zenith_Angle * np.pi / 180) + DHI) - GHI)\n",
    "    constraint_2 = torch.abs(torch.relu(Dew_Point - Temperature))\n",
    "    constraint_3 = torch.abs(\n",
    "        100 * torch.exp((17.625 * Dew_Point) / (243.04 + Dew_Point)) /\n",
    "        torch.exp((17.625 * Temperature) / (243.04 + Temperature)) - Relative_Humidity\n",
    "    )\n",
    "\n",
    "    constraints = torch.stack([constraint_1, constraint_2, constraint_3], dim=-1)\n",
    "    return constraints\n",
    "\n",
    "\n",
    "class ConstraintClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=72): # 72 = 24 steps * 3 constraints\n",
    "        super().__init__()\n",
    "        # 使用较小的隐藏层，因为经过 Max Pooling 后特征已经非常鲜明\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, 32), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1) # 输出 Logits\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x 形状: [Batch, 72]\n",
    "        # 1. 重塑为 [Batch, 24, 3] -> 24个时间步，每个步长3个物理约束\n",
    "        x = x.view(x.size(0), 24, 3)\n",
    "        \n",
    "        # 2. 时间维度最大池化：提取 24 小时中每一个约束的最极端违背值\n",
    "        # 结果形状: [Batch, 3]\n",
    "        x, _ = torch.max(x, dim=1)\n",
    "        \n",
    "        # 3. 对数缩放：增强数值稳定性\n",
    "        x = torch.log1p(x)\n",
    "        \n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss_fn(logits, labels, margin=10.0):\n",
    "    loss_norm = torch.relu(logits[labels == 0] + margin).mean()\n",
    "    loss_adv = torch.relu(margin - logits[labels == 1]).mean()\n",
    "    return (loss_norm if not torch.isnan(loss_norm) else 0.0) + \\\n",
    "           (loss_adv if not torch.isnan(loss_adv) else 0.0)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. 诊断型训练函数\n",
    "# ---------------------------------------------------------\n",
    "def train_classifier(train_loader, uap_loaded_list, classifier_model, weather_scaler, device='cuda', epochs=15, learning_rate=0.0005):\n",
    "    optimizer = optim.Adam(classifier_model.parameters(), lr=learning_rate)\n",
    "    classifier_model.to(device)\n",
    "\n",
    "    best_gap = -float('inf')\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Starting UAP-focused training on {device}...\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        classifier_model.train()\n",
    "        all_norm_logits = []\n",
    "        all_adv_logits = []\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for _, weather_future, _ in train_loader: # 不需要 history 和 power\n",
    "            batch_size = weather_future.size(0)\n",
    "            weather_future = weather_future.to(device)\n",
    "\n",
    "            x_list, y_list = [], []\n",
    "            \n",
    "            # (1) 正常样本\n",
    "            with torch.no_grad():\n",
    "                n_cons = compute_constraints(weather_future.cpu(), weather_scaler).to(device).view(batch_size, -1)\n",
    "                x_list.append(n_cons)\n",
    "                y_list.append(torch.zeros(batch_size, 1).to(device))\n",
    "\n",
    "            # (2) UAP 对抗样本\n",
    "            with torch.no_grad():\n",
    "                for uap in uap_loaded_list:\n",
    "                    u_adv = torch.clamp(weather_future + uap.to(device), 0, 1)\n",
    "                    u_cons = compute_constraints(u_adv.cpu(), weather_scaler).to(device).view(batch_size, -1)\n",
    "                    x_list.append(u_cons)\n",
    "                    y_list.append(torch.ones(batch_size, 1).to(device))\n",
    "\n",
    "            X = torch.cat(x_list, dim=0)\n",
    "            Y = torch.cat(y_list, dim=0)\n",
    "\n",
    "            # --- 优化 ---\n",
    "            optimizer.zero_grad()\n",
    "            logits = classifier_model(X)\n",
    "            loss = margin_loss_fn(logits, Y, margin=15.0) # 调大 Margin\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            with torch.no_grad():\n",
    "                all_norm_logits.append(logits[Y == 0].cpu())\n",
    "                all_adv_logits.append(logits[Y == 1].cpu())\n",
    "\n",
    "        # --- 统计 ---\n",
    "        all_norm_logits = torch.cat(all_norm_logits)\n",
    "        all_adv_logits = torch.cat(all_adv_logits)\n",
    "        \n",
    "        n_max = all_norm_logits.max().item()\n",
    "        a_min = all_adv_logits.min().item()\n",
    "        current_gap = a_min - n_max\n",
    "        acc = ((all_norm_logits < 0).sum() + (all_adv_logits > 0).sum()).item() / (len(all_norm_logits) + len(all_adv_logits))\n",
    "\n",
    "        print(f\"Epoch [{epoch+1:02d}] Loss: {epoch_loss/len(train_loader):.4f} | Acc: {acc:.2%} | Gap: {current_gap:.4f}\")\n",
    "\n",
    "        if current_gap > best_gap:\n",
    "            best_gap = current_gap\n",
    "            best_model = copy.deepcopy(classifier_model)\n",
    "            print(f\"   --> Success! Best Gap improved to {best_gap:.4f}\")\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5348f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models = ['tcn', 'lstm']\n",
    "epsilons = [('003', 0.03), ('005', 0.05), ('010', 0.10)]\n",
    "uap_loaded_list = []\n",
    "for suffix, epsilon_val in epsilons:\n",
    "    for name in selected_models:\n",
    "        pkl_path = f'uap_results_{name}_epsilon_{suffix}.pkl'\n",
    "        try:\n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                uap_np = data['uap_list'][0]\n",
    "                uap_tensor = torch.tensor(uap_np).float() if not isinstance(uap_np, torch.Tensor) else uap_np.float()\n",
    "                uap_loaded_list.append(uap_tensor)\n",
    "        except: pass\n",
    "\n",
    "# 实例化模型\n",
    "classifier_model = ConstraintClassifier(input_dim=72)\n",
    "\n",
    "# 开始训练\n",
    "PALM = train_classifier(\n",
    "    train_loader=train_loader, \n",
    "    uap_loaded_list=uap_loaded_list, \n",
    "    classifier_model=classifier_model, \n",
    "    weather_scaler=weather_scaler, \n",
    "    device='cuda', \n",
    "    epochs=10, \n",
    "    learning_rate=0.0005\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae6eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(PALM.state_dict(), 'PALM_model.pth')\n",
    "PALM=ConstraintClassifier(input_dim=72)\n",
    "PALM.load_state_dict(torch.load('PALM_model.pth'))\n",
    "PALM.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def test_constraint_classifier_uap_only(test_loader, uap_loaded_list, classifier_model, weather_scaler, device='cuda'):\n",
    "    classifier_model.eval()\n",
    "    classifier_model.to(device)\n",
    "    \n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for _, weather_future, _ in test_loader:\n",
    "            batch_size = weather_future.size(0)\n",
    "            weather_future = weather_future.to(device)\n",
    "\n",
    "            n_cons = compute_constraints(weather_future.cpu(), weather_scaler).to(device)\n",
    "            n_cons = n_cons.view(batch_size, -1) \n",
    "\n",
    "            n_logits = classifier_model(n_cons)\n",
    "            n_pred = (n_logits.squeeze() > 0).float() \n",
    "            \n",
    "            correct_predictions += (n_pred == 0).sum().item()\n",
    "            total_samples += batch_size\n",
    "\n",
    "            for uap in uap_loaded_list:\n",
    "                uap_tensor = uap.to(device)\n",
    "                attacked_weather = torch.clamp(weather_future + uap_tensor, 0, 1)\n",
    " \n",
    "                a_cons = compute_constraints(attacked_weather.cpu(), weather_scaler).to(device)\n",
    "                a_cons = a_cons.view(batch_size, -1)\n",
    "\n",
    "                a_logits = classifier_model(a_cons)\n",
    "                a_pred = (a_logits.squeeze() > 0).float()\n",
    "                \n",
    "                correct_predictions += (a_pred == 1).sum().item()\n",
    "                total_samples += batch_size\n",
    "\n",
    "    overall_acc = 100 * correct_predictions / total_samples\n",
    "    print(f\"\\n\" + \"=\"*40)\n",
    "    print(f\"total_samples: {total_samples}\")\n",
    "    print(f\"Accuracy: {overall_acc:.2f}%\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    return overall_acc\n",
    "\n",
    "palm_acc = test_constraint_classifier_uap_only(\n",
    "    test_loader=test_loader, \n",
    "    uap_loaded_list=uap_loaded_list, \n",
    "    classifier_model=PALM, \n",
    "    weather_scaler=weather_scaler, \n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d6949f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3adfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
