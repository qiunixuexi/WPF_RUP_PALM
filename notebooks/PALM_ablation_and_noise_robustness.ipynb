{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66968ea8",
   "metadata": {},
   "source": [
    "## 0. Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86af3d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "class WindPowerDataset(Dataset):\n",
    "    def __init__(self, csv_file, wind_power_scaler=None, weather_scaler=None, save_scalers=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.data = self.data.iloc[::5, :].reset_index(drop=True)\n",
    "\n",
    "        self.original_wind_power_std = self.data.iloc[:, 2].std()\n",
    "        self.original_weather_std = self.data.iloc[:, 4:12].std()\n",
    "\n",
    "        if wind_power_scaler is None or weather_scaler is None:\n",
    "            self.wind_power_scaler = MinMaxScaler()\n",
    "            self.weather_scaler = MinMaxScaler()\n",
    "\n",
    "            self.data.iloc[:, 2] = self.wind_power_scaler.fit_transform(self.data.iloc[:, 2].values.reshape(-1, 1)).squeeze()\n",
    "\n",
    "            self.data.iloc[:, 4:12] = self.weather_scaler.fit_transform(self.data.iloc[:, 4:12])\n",
    "            \n",
    "            if save_scalers:\n",
    "                with open('wind_power_scaler.pkl', 'wb') as f:\n",
    "                    pickle.dump(self.wind_power_scaler, f)\n",
    "                with open('weather_scaler.pkl', 'wb') as f:\n",
    "                    pickle.dump(self.weather_scaler, f)\n",
    "        else:\n",
    "            self.wind_power_scaler = wind_power_scaler\n",
    "            self.weather_scaler = weather_scaler\n",
    "            self.data.iloc[:, 2] = self.wind_power_scaler.transform(self.data.iloc[:, 2].values.reshape(-1, 1)).squeeze()\n",
    "            self.data.iloc[:, 4:12] = self.weather_scaler.transform(self.data.iloc[:, 4:12])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - 312  # 288 (1440/5) + 24 (120/5)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        history_weather = self.data.iloc[idx:idx + 288, 4:12].values.astype(float)  # [288, 8]\n",
    "        wind_power_history = self.data.iloc[idx:idx + 288, 2].values.astype(float)   # [288]\n",
    "        future_weather = self.data.iloc[idx + 288:idx + 312, 4:12].values.astype(float)  # [24, 8]\n",
    "        future_wind_power = self.data.iloc[idx + 312, 2]  # float\n",
    "\n",
    "        return (\n",
    "            torch.tensor(history_weather, dtype=torch.float32),\n",
    "            torch.tensor(wind_power_history, dtype=torch.float32),\n",
    "            torch.tensor(future_weather, dtype=torch.float32),\n",
    "            torch.tensor(future_wind_power, dtype=torch.float32)\n",
    "        )\n",
    "    \n",
    "    def get_original_stds(self):\n",
    "        return {\n",
    "            'original_wind_power_std': self.original_wind_power_std,\n",
    "            'original_weather_std': self.original_weather_std.to_dict()\n",
    "        }\n",
    "    \n",
    "name='CAISO_zone_1_.csv'\n",
    "with open('weather_scaler.pkl', 'rb') as f:\n",
    "    weather_scaler = pickle.load(f)\n",
    "dataset = WindPowerDataset(name, save_scalers=True)\n",
    "wind_power_scaler=dataset.wind_power_scaler\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size=32\n",
    "test_split=0.2\n",
    "test_size = int(len(dataset) * test_split)\n",
    "train_size = len(dataset) - test_size\n",
    "train_dataset = Subset(dataset, list(range(train_size)))\n",
    "test_dataset = Subset(dataset, list(range(train_size, len(dataset))))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8598f9",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rup_ensemble_003_caiso.pkl', 'rb') as f:\n",
    "    rup_ensemble_003 = pickle.load(f)\n",
    "\n",
    "with open('rup_ensemble_005_caiso.pkl', 'rb') as f:\n",
    "    rup_ensemble_005 = pickle.load(f)\n",
    "\n",
    "with open('rup_ensemble_010_caiso.pkl', 'rb') as f:\n",
    "    rup_ensemble_010 = pickle.load(f)\n",
    "\n",
    "with open('RUPW010_caiso.pkl', 'rb') as f:\n",
    "    rupw_010 = pickle.load(f)\n",
    "\n",
    "with open('RUPW005_caiso.pkl', 'rb') as f:\n",
    "    rupw_005 = pickle.load(f)\n",
    "\n",
    "with open('RUPW003_caiso.pkl', 'rb') as f:\n",
    "    rupw_003 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0386cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "uap_loaded_list = []\n",
    "\n",
    "uap_loaded_list.append(rup_ensemble_003)\n",
    "uap_loaded_list.append(rup_ensemble_005)\n",
    "uap_loaded_list.append(rup_ensemble_010)\n",
    "uap_loaded_list.append(rupw_010)\n",
    "uap_loaded_list.append(rupw_005)\n",
    "uap_loaded_list.append(rupw_003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ce0ab4",
   "metadata": {},
   "source": [
    "## ablation experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0077846",
   "metadata": {},
   "source": [
    "### MLP without physical constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34557eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackDetectionDataset(Dataset):\n",
    "    def __init__(self, data_loader, uap_list, scaler=None, max_samples=None):\n",
    "        self.normal_samples = []\n",
    "        self.attack_samples = []\n",
    "        self.scaler = scaler\n",
    "\n",
    "        print(\"Building dataset: collecting normal and attacked samples...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            count = 0\n",
    "            for _, _, weather_future, _ in data_loader:\n",
    "                B, T, F = weather_future.shape  # B, 24, 8\n",
    "                weather_np = weather_future.cpu().numpy()\n",
    "                self.normal_samples.append(weather_np)\n",
    "                for uap_tensor in uap_list:\n",
    "                    uap = uap_tensor.cpu().numpy()  # (24, 8)\n",
    "                    attacked_batch = np.clip(weather_np + uap, 0, 1)  \n",
    "                    self.attack_samples.append(attacked_batch)\n",
    "                count += B\n",
    "                if max_samples and count >= max_samples:\n",
    "                    break\n",
    "\n",
    "        self.normal_samples = np.concatenate(self.normal_samples, axis=0)\n",
    "        self.attack_samples = np.concatenate(self.attack_samples, axis=0)\n",
    "        n_normal = len(self.normal_samples)\n",
    "        n_attack = len(self.attack_samples)\n",
    "        min_len = min(n_normal, n_attack)\n",
    "        self.normal_samples = self.normal_samples[:min_len]\n",
    "        self.attack_samples = self.attack_samples[:min_len]\n",
    "\n",
    "        print(f\"Final dataset: {min_len} normal + {min_len} attacked = {2 * min_len} samples\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.normal_samples) + len(self.attack_samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.normal_samples):\n",
    "            x = self.normal_samples[idx]\n",
    "            y = 0  # normal\n",
    "        else:\n",
    "            x = self.attack_samples[idx - len(self.normal_samples)]\n",
    "            y = 1  # attacked\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65511715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim=24*8, hidden_dim=64, num_classes=2, dropout=0.3):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 24, 8) -> reshape to (B, 192)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_detector():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    dataset = AttackDetectionDataset(\n",
    "        data_loader=train_loader,  \n",
    "        uap_list=uap_loaded_list,\n",
    "        max_samples=None\n",
    "    )\n",
    "\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(0.8 * total_size)\n",
    "    val_size = total_size - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader_cls = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader_cls = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = SimpleMLP().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    num_epochs = 20\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        y_true_train, y_pred_train = [], []\n",
    "\n",
    "        for x, y in train_loader_cls:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            pred = logits.argmax(dim=1)\n",
    "            y_true_train.extend(y.cpu().numpy())\n",
    "            y_pred_train.extend(pred.cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(y_true_train, y_pred_train)\n",
    "        train_f1 = f1_score(y_true_train, y_pred_train)\n",
    "\n",
    "        model.eval()\n",
    "        y_true_val, y_pred_val, y_probs_val = [], [], []\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader_cls:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                probs = torch.softmax(logits, dim=1)[:, 1] \n",
    "                pred = logits.argmax(dim=1)\n",
    "\n",
    "                y_true_val.extend(y.cpu().numpy())\n",
    "                y_pred_val.extend(pred.cpu().numpy())\n",
    "                y_probs_val.extend(probs.cpu().numpy())\n",
    "\n",
    "        val_acc = accuracy_score(y_true_val, y_pred_val)\n",
    "        val_f1 = f1_score(y_true_val, y_pred_val)\n",
    "        val_auc = roc_auc_score(y_true_val, y_probs_val)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {train_loss/len(train_loader_cls):.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f} | \"\n",
    "              f\"Val Loss: {val_loss/len(val_loader_cls):.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_mlp_detector_caiso.pth\")\n",
    "\n",
    "    print(\"\\n Final Validation Results:\")\n",
    "    print(classification_report(y_true_val, y_pred_val, target_names=['Normal', 'Attacked']))\n",
    "    print(f\"AUC Score: {val_auc:.4f}\")\n",
    "\n",
    "    return model, val_auc, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b61d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model, auc, acc, f1 = train_mlp_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mlp_detector_on_test(\n",
    "    wind_power_model_new,  \n",
    "    test_loader,\n",
    "    uap_loaded_list,\n",
    "    device,\n",
    "    model_path=\"best_mlp_detector_caiso.pth\"\n",
    "):\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = SimpleMLP().to(device)\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(\"Loaded trained MLP detector weights.\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Model weights not found: {model_path}\") \n",
    "    model.eval()\n",
    "\n",
    "    wind_power_model_new = wind_power_model_new.to(device)\n",
    "    wind_power_model_new.eval() \n",
    "\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    y_probs_all = []\n",
    "    attack_types = [] \n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0.0\n",
    "\n",
    "    print(\"Starting comprehensive evaluation on multiple attack types...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (history_weather, wind_power_history, future_weather, future_wind_power) in enumerate(test_loader):\n",
    "            B = future_weather.size(0)\n",
    "\n",
    "            history_weather = history_weather.to(device)\n",
    "            wind_power_history = wind_power_history.to(device)\n",
    "            future_weather = future_weather.to(device)\n",
    "            future_wind_power = future_wind_power.to(device)\n",
    "\n",
    "            x_normal = future_weather\n",
    "            logits_normal = model(x_normal.view(B, -1))\n",
    "            loss = criterion(logits_normal, torch.zeros(B, dtype=torch.long).to(device))\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            probs_normal = torch.softmax(logits_normal, dim=1)[:, 1].detach().cpu().numpy()\n",
    "            pred_normal = logits_normal.argmax(dim=1).detach().cpu().numpy()\n",
    "\n",
    "            y_true_all.extend([0] * B)\n",
    "            y_pred_all.extend(pred_normal)\n",
    "            y_probs_all.extend(probs_normal)\n",
    "            attack_types.extend(['normal'] * B)\n",
    "\n",
    "            for uap_tensor in uap_loaded_list:\n",
    "                uap = uap_tensor.to(device)  # (24, 8)\n",
    "                adv_weather_uap = torch.clamp(future_weather + uap.unsqueeze(0), 0, 1)\n",
    "\n",
    "                logits_uap = model(adv_weather_uap.view(B, -1))\n",
    "                probs_uap = torch.softmax(logits_uap, dim=1)[:, 1].detach().cpu().numpy()\n",
    "                pred_uap = logits_uap.argmax(dim=1).detach().cpu().numpy()\n",
    "\n",
    "                y_true_all.extend([1] * B)\n",
    "                y_pred_all.extend(pred_uap)\n",
    "                y_probs_all.extend(probs_uap)\n",
    "                attack_types.extend(['uap'] * B)\n",
    "\n",
    "            with torch.enable_grad():\n",
    "                wind_power_model_new.train()\n",
    "                future_weather_adv = future_weather.clone().detach().requires_grad_(True)\n",
    "                pred_power = wind_power_model_new(wind_power_history, future_weather_adv)\n",
    "                loss_attack = torch.nn.MSELoss()(pred_power.squeeze(), future_wind_power)\n",
    "\n",
    "                if future_weather_adv.grad is not None:\n",
    "                    future_weather_adv.grad.zero_()\n",
    "                loss_attack.backward()\n",
    "\n",
    "                epsilon = 0.03\n",
    "                grad_sign = future_weather_adv.grad.data.sign()\n",
    "                adv_weather_fgsm = torch.clamp(future_weather + epsilon * grad_sign, 0, 1)\n",
    "                wind_power_model_new.eval()\n",
    "\n",
    "                logits_fgsm = model(adv_weather_fgsm.view(B, -1))\n",
    "                probs_fgsm = torch.softmax(logits_fgsm, dim=1)[:, 1].detach().cpu().numpy()\n",
    "                pred_fgsm = logits_fgsm.argmax(dim=1).detach().cpu().numpy()\n",
    "\n",
    "                y_true_all.extend([1] * B)\n",
    "                y_pred_all.extend(pred_fgsm)\n",
    "                y_probs_all.extend(probs_fgsm)\n",
    "                attack_types.extend(['fgsm_new_model'] * B)\n",
    "\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_acc = accuracy_score(y_true_all, y_pred_all)\n",
    "    test_f1 = f1_score(y_true_all, y_pred_all)\n",
    "    test_auc = roc_auc_score(y_true_all, y_probs_all)\n",
    "\n",
    "    def calc_metrics_for_type(types_to_include):\n",
    "        idx = [i for i, atk in enumerate(attack_types) if atk in types_to_include]\n",
    "        if len(idx) == 0:\n",
    "            return {'acc': 0, 'f1': 0, 'auc': float('nan')}\n",
    "        \n",
    "        y_true = [y_true_all[i] for i in idx]\n",
    "        y_pred = [y_pred_all[i] for i in idx]\n",
    "        y_prob = [y_probs_all[i] for i in idx]\n",
    "\n",
    "        if len(np.unique(y_true)) < 2:\n",
    "            auc_score = float('nan')\n",
    "        else:\n",
    "            auc_score = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "        return {\n",
    "            'acc': accuracy_score(y_true, y_pred),\n",
    "            'f1': f1_score(y_true, y_pred),\n",
    "            'auc': auc_score\n",
    "        }\n",
    "\n",
    "    results_by_type = {\n",
    "        'overall': {'acc': test_acc, 'f1': test_f1, 'auc': test_auc},\n",
    "        'normal_vs_uap': calc_metrics_for_type(['normal', 'uap']),\n",
    "        'normal_vs_fgsm_new_model': calc_metrics_for_type(['normal', 'fgsm_new_model']),\n",
    "    }\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPREHENSIVE EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Overall Accuracy:  {test_acc:.4f}\")\n",
    "    print(f\"Overall F1-Score:  {test_f1:.4f}\")\n",
    "    print(f\"Overall AUC:       {test_auc:.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"PERFORMANCE BY ATTACK TYPE\")\n",
    "    print(\"-\"*50)\n",
    "    for atk_type, metrics in results_by_type.items():\n",
    "        if atk_type == 'overall':\n",
    "            continue\n",
    "        print(f\"{atk_type.upper():15} | Acc={metrics['acc']:6.4f} | F1={metrics['f1']:6.4f} | AUC={metrics['auc']:6.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"Classification Report (Overall)\")\n",
    "    print(\"-\"*50)\n",
    "    print(classification_report(y_true_all, y_pred_all, target_names=['Normal (0)', 'Attacked (1)']))\n",
    "\n",
    "    return {\n",
    "        'overall': {\n",
    "            'loss': test_loss,\n",
    "            'accuracy': test_acc,\n",
    "            'f1': test_f1,\n",
    "            'auc': test_auc,\n",
    "            'y_true': y_true_all,\n",
    "            'y_scores': y_probs_all\n",
    "        },\n",
    "        'by_attack_type': results_by_type\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalConvNet_V2(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=3, dropout=0.2):\n",
    "        super(TemporalConvNet_V2, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "\n",
    "            padding = (kernel_size - 1) * dilation_size\n",
    "\n",
    "            conv = nn.Conv1d(\n",
    "                in_channels, out_channels, kernel_size,\n",
    "                stride=1, padding=padding, dilation=dilation_size  \n",
    "            )\n",
    "            relu = nn.ReLU()\n",
    "            drop = nn.Dropout(dropout)\n",
    "\n",
    "            if in_channels != out_channels:\n",
    "                res_conv = nn.Conv1d(in_channels, out_channels, 1)\n",
    "            else:\n",
    "                res_conv = None\n",
    "\n",
    "            layers.append(nn.ModuleDict({\n",
    "                'conv': conv,\n",
    "                'relu': relu,\n",
    "                'dropout': drop,\n",
    "                'res_conv': res_conv\n",
    "            }))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, in_channels, seq_len)\n",
    "        for layer in self.layers:\n",
    "            residual = x  \n",
    "\n",
    "            x = layer['conv'](x)  \n",
    "            x = layer['relu'](x)\n",
    "            x = layer['dropout'](x)\n",
    "            x = x[:, :, :residual.size(2)]  \n",
    "\n",
    "            if layer['res_conv'] is not None:\n",
    "                residual = layer['res_conv'](residual)\n",
    "            x = x + residual\n",
    "            x = layer['relu'](x)  \n",
    "        return x\n",
    "\n",
    "\n",
    "class WindPowerPredictorTCN_V2(nn.Module):\n",
    "    def __init__(self, d_model=64, dropout=0.2, fusion_mode='concat'):\n",
    "        super(WindPowerPredictorTCN_V2, self).__init__()\n",
    "        self.fusion_mode = fusion_mode  # 'concat' or 'add'\n",
    "        self.tcn_wind = TemporalConvNet_V2(\n",
    "            num_inputs=1,\n",
    "            num_channels=[d_model, d_model*2, d_model, d_model],  \n",
    "            kernel_size=3,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.tcn_weather = TemporalConvNet_V2(\n",
    "            num_inputs=8,\n",
    "            num_channels=[d_model, d_model*2, d_model, d_model],\n",
    "            kernel_size=3,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        if fusion_mode == 'concat':\n",
    "            fc_input_dim = d_model * 2\n",
    "        elif fusion_mode == 'add':\n",
    "            fc_input_dim = d_model\n",
    "        else:\n",
    "            raise ValueError(\"fusion_mode must be 'concat' or 'add'\")\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(fc_input_dim, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, wind_history, weather_future):\n",
    "        # wind_history: (batch_size, 288)\n",
    "        # weather_future: (batch_size, 24, 8)\n",
    "\n",
    "        x_wind = wind_history.unsqueeze(1)  # (B, 1, 288)\n",
    "        x_wind = self.tcn_wind(x_wind)     # (B, D, 288)\n",
    "        x_wind = x_wind[:, :, -1]          \n",
    "\n",
    "        x_weather = weather_future.transpose(1, 2)  # (B, 8, 24)\n",
    "        x_weather = self.tcn_weather(x_weather)     # (B, D, 24)\n",
    "        x_weather = x_weather[:, :, -1]             # -> (B, D)\n",
    "\n",
    "        if self.fusion_mode == 'concat':\n",
    "            combined = torch.cat((x_wind, x_weather), dim=1)  # (B, 2D)\n",
    "        elif self.fusion_mode == 'add':\n",
    "            combined = x_wind + x_weather  \n",
    "\n",
    "        output = self.fc(combined)         # (B, 1)\n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ce955",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_model=WindPowerPredictorTCN_V2().to(device)\n",
    "attack_model.load_state_dict(torch.load('wind_tcn_caiso_sigmoid_v2.pth', map_location=device))\n",
    "\n",
    "results = evaluate_mlp_detector_on_test(\n",
    "    wind_power_model_new=attack_model,\n",
    "    test_loader=test_loader,\n",
    "    uap_loaded_list=uap_loaded_list,\n",
    "    device=device,\n",
    "    model_path=\"best_mlp_detector_caiso.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5356d319",
   "metadata": {},
   "source": [
    "## Ablation experiments targeting various physical constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_constraints(weather_future, weather_scaler, constraint_types=['c1', 'c2', 'c3']):\n",
    "    B, T, F = weather_future.shape\n",
    "\n",
    "    x_flat = weather_future.view(-1, F)\n",
    "    x_unscaled_np = weather_scaler.inverse_transform(x_flat.cpu().numpy())\n",
    "    x_unscaled = torch.tensor(x_unscaled_np, dtype=torch.float32, device=weather_future.device).view(B, T, F)\n",
    "\n",
    "    DNI = x_unscaled[:, :, 1]           # Direct Normal Irradiance\n",
    "    SZA = x_unscaled[:, :, 4]           # Solar Zenith Angle\n",
    "    DHI = x_unscaled[:, :, 0]           # Diffuse Horizontal Irradiance\n",
    "    GHI = x_unscaled[:, :, 2]           # Global Horizontal Irradiance\n",
    "    Dew_Point = x_unscaled[:, :, 3]\n",
    "    Temperature = x_unscaled[:, :, 7]\n",
    "    RH = x_unscaled[:, :, 6]            # Relative Humidity\n",
    "\n",
    "    constraints = []\n",
    "\n",
    "    for c in constraint_types:\n",
    "        if c == 'c1':\n",
    "            cos_sza = torch.cos(SZA * torch.pi / 180)\n",
    "            c1 = torch.abs((DNI * cos_sza + DHI) - GHI)\n",
    "            constraints.append(c1.unsqueeze(-1))  # [B, T, 1]\n",
    "        elif c == 'c2':\n",
    "            c2 = torch.relu(Dew_Point - Temperature)\n",
    "            constraints.append(c2.unsqueeze(-1))\n",
    "        elif c == 'c3':\n",
    "            a, b = 17.625, 243.04\n",
    "            exp_dew = (a * Dew_Point) / (b + Dew_Point.clamp(min=1e-6))\n",
    "            exp_t = (a * Temperature) / (b + Temperature.clamp(min=1e-6))\n",
    "            RH_calculated = 100.0 * torch.exp(exp_dew - exp_t)\n",
    "            c3 = torch.abs(RH - RH_calculated)\n",
    "            constraints.append(c3.unsqueeze(-1))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown constraint: {c}\")\n",
    "\n",
    "    if len(constraints) == 0:\n",
    "        raise ValueError(\"At least one constraint must be specified\")\n",
    "    \n",
    "    constraints = torch.cat(constraints, dim=-1)  # [B, T, N]\n",
    "    return constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4de2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.lstm_wind = nn.LSTM(input_size=1, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm_weather = nn.LSTM(input_size=8, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(256, 1)\n",
    "        self.relu=nn.ReLU()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = wind_history.unsqueeze(-1)\n",
    "        _, (hn_wind, _) = self.lstm_wind(wind_history)\n",
    "        _, (hn_weather, _) = self.lstm_weather(weather_future)\n",
    "        hn_wind = hn_wind[-1, :, :]\n",
    "        hn_weather = hn_weather[-1, :, :]\n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.relu(output)\n",
    "        return output\n",
    "    \n",
    "def load_model(model_path, device='cpu'):\n",
    "    model = WindPowerPredictor().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wind_power_model_path = 'wind_caiso_lstm_sigmoid_version2.pth'\n",
    "wind_power_model = load_model(wind_power_model_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstraintDetector(nn.Module):\n",
    "    def __init__(self, num_constraints, hidden_dim=64):\n",
    "        super(ConstraintDetector, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_constraints * 24, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)  # x: [B, 24 * num_constraints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_detector(\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    weather_scaler,\n",
    "    constraint_types,\n",
    "    device='cuda',\n",
    "    num_epochs=20,\n",
    "    lr=1e-4,\n",
    "    save_path=None\n",
    "):\n",
    "   \n",
    "    print(f\"============================================================\")\n",
    "    print(f\"STARTING TRAINING: {''.join(constraint_types).upper()}\")\n",
    "    print(f\"============================================================\")\n",
    "    print(f\"Training Detector for constraints: {constraint_types}\")\n",
    "\n",
    "    model = ConstraintDetector(num_constraints=len(constraint_types)).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_threshold = 0.5\n",
    "    patience = 0\n",
    "    max_patience = 5  \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            history_weather, wind_power_history, future_weather, future_wind_power = batch\n",
    "            future_weather = future_weather.to(device)\n",
    "            B = future_weather.size(0)\n",
    "            labels = torch.zeros(B, device=device)\n",
    "            uap_perturb = torch.rand_like(future_weather) * 0.01\n",
    "            adv_weather = torch.clamp(future_weather + uap_perturb, 0, 1)\n",
    "            adv_labels = torch.ones(B, device=device)\n",
    "            mixed_weather = torch.cat([future_weather, adv_weather], dim=0)  # [2B, ...]\n",
    "            mixed_labels = torch.cat([labels, adv_labels], dim=0)            # [2B]\n",
    "\n",
    "            constraints = compute_constraints(mixed_weather.cpu(), weather_scaler, constraint_types)\n",
    "            constraints_flat = constraints.view(constraints.size(0), -1).to(device)  # [2B, 24*C]\n",
    "\n",
    "            logits = model(constraints_flat).squeeze()  # [2B]\n",
    "            loss = criterion(logits, mixed_labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_probs = []\n",
    "        val_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                history_weather, wind_power_history, future_weather, future_wind_power = batch\n",
    "                B = future_weather.size(0)\n",
    "                future_weather = future_weather.to(device)\n",
    "\n",
    "                constraints_normal = compute_constraints(future_weather.cpu(), weather_scaler, constraint_types)\n",
    "                constraints_flat_normal = constraints_normal.view(B, -1).to(device)\n",
    "                logits_normal = model(constraints_flat_normal).squeeze()\n",
    "                prob_normal = torch.sigmoid(logits_normal).detach().cpu().numpy()  \n",
    "                val_probs.append(prob_normal)\n",
    "                val_true.append(np.zeros(B))\n",
    "\n",
    "                uap_perturb = torch.rand_like(future_weather) * 0.01\n",
    "                adv_weather = torch.clamp(future_weather + uap_perturb, 0, 1)\n",
    "                constraints_adv = compute_constraints(adv_weather.cpu(), weather_scaler, constraint_types)\n",
    "                constraints_flat_adv = constraints_adv.view(B, -1).to(device)\n",
    "                logits_adv = model(constraints_flat_adv).squeeze()\n",
    "                prob_adv = torch.sigmoid(logits_adv).detach().cpu().numpy()\n",
    "                val_probs.append(prob_adv)\n",
    "                val_true.append(np.ones(B))\n",
    "\n",
    "        val_probs = np.concatenate(val_probs)\n",
    "        val_true = np.concatenate(val_true)\n",
    "\n",
    "        print(f\"\\n Debug Info at Epoch {epoch}:\")\n",
    "        print(f\"  Total samples: {len(val_true)} (Normal: {len(val_true) - val_true.sum()}, Adv: {val_true.sum()})\")\n",
    "        print(f\"  Mean normal prob: {np.mean(val_probs[val_true == 0]):.4f} ± {np.std(val_probs[val_true == 0]):.4f}\")\n",
    "        print(f\"  Mean adv prob:    {np.mean(val_probs[val_true == 1]):.4f} ± {np.std(val_probs[val_true == 1]):.4f}\")\n",
    "        print(f\"  Prob range: [{val_probs.min():.4f}, {val_probs.max():.4f}]\")\n",
    "\n",
    "        best_acc = 0.0\n",
    "        best_thresh = 0.5\n",
    "        thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "\n",
    "        for thresh in thresholds:\n",
    "            pred_labels = (val_probs >= thresh).astype(int)\n",
    "            acc = (pred_labels == val_true).sum() / len(val_true)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_thresh = thresh\n",
    "\n",
    "        val_acc = best_acc\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_threshold = best_thresh  \n",
    "            if save_path:\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'best_threshold': best_threshold,\n",
    "                    'val_accuracy': best_val_acc,\n",
    "                    'constraint_types': constraint_types\n",
    "                }, save_path)\n",
    "                print(f\"Model saved to {save_path} \"\n",
    "                      f\"(Accuracy = {best_val_acc:.4f}, Best Thresh = {best_threshold:.3f})\")\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        if epoch % 3 == 0:\n",
    "            print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}, Val Acc: {val_acc:.4f}, Thresh: {best_thresh:.3f}\")\n",
    "\n",
    "        if patience >= max_patience:\n",
    "            print(f\" Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    print(f\" Training finished. Best Val Accuracy: {best_val_acc:.4f} @ Thresh={best_threshold:.3f}\")\n",
    "    return model, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc7867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_detector(\n",
    "    model,\n",
    "    test_loader,\n",
    "    uap_loaded_list,\n",
    "    weather_scaler,\n",
    "    wind_power_model,\n",
    "    constraint_types,\n",
    "    device='cuda',\n",
    "    model_path=None  \n",
    "):\n",
    "\n",
    "    if model_path is not None:\n",
    "        print(f\"Loading model from {model_path}\")\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_threshold = checkpoint.get('best_threshold', 0.5)  \n",
    "        print(f\"Loaded best_threshold = {best_threshold:.4f}\")\n",
    "    else:\n",
    "        best_threshold = 0.5\n",
    "        print(f\"No model_path provided. Using default threshold = {best_threshold:.3f}\")\n",
    "\n",
    "    model.eval()\n",
    "    wind_power_model.to(device)\n",
    "    wind_power_model.eval()\n",
    "\n",
    "    all_pred_proba = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            history_weather, wind_power_history, future_weather, future_wind_power = batch\n",
    "            B = future_weather.size(0)\n",
    "\n",
    "            history_weather = history_weather.to(device)\n",
    "            wind_power_history = wind_power_history.to(device)\n",
    "            future_weather = future_weather.to(device)\n",
    "            future_wind_power = future_wind_power.to(device)\n",
    "\n",
    "            constraints_normal = compute_constraints(future_weather.cpu(), weather_scaler, constraint_types)\n",
    "            constraints_flat_normal = constraints_normal.view(B, -1).to(device)\n",
    "            logits_normal = model(constraints_flat_normal).squeeze()\n",
    "            prob_normal = torch.sigmoid(logits_normal).detach().cpu().numpy()\n",
    "            all_pred_proba.append(prob_normal)\n",
    "            all_true_labels.append(np.zeros(B))\n",
    "\n",
    "            for uap in uap_loaded_list:\n",
    "                adv_weather = torch.clamp(future_weather + uap.to(device), 0, 1)\n",
    "                constraints_adv = compute_constraints(adv_weather.cpu(), weather_scaler, constraint_types)\n",
    "                constraints_flat_adv = constraints_adv.view(B, -1).to(device)\n",
    "                logits_adv = model(constraints_flat_adv).squeeze()\n",
    "                prob_adv = torch.sigmoid(logits_adv).detach().cpu().numpy()\n",
    "                all_pred_proba.append(prob_adv)\n",
    "                all_true_labels.append(np.ones(B))\n",
    "\n",
    "            with torch.enable_grad():\n",
    "                wind_power_model.train()\n",
    "                future_weather_for_adv = future_weather.clone().detach().requires_grad_(True)\n",
    "                pred_power = wind_power_model(wind_power_history, future_weather_for_adv)\n",
    "                loss = torch.nn.MSELoss()(pred_power.squeeze(), future_wind_power)\n",
    "\n",
    "                if future_weather_for_adv.grad is not None:\n",
    "                    future_weather_for_adv.grad.zero_()\n",
    "                loss.backward()\n",
    "\n",
    "                grad_sign = future_weather_for_adv.grad.data.sign()\n",
    "                epsilon = 0.03\n",
    "                adv_weather_grad = torch.clamp(future_weather + epsilon * grad_sign, 0, 1)\n",
    "                wind_power_model.eval()\n",
    "\n",
    "                constraints_grad = compute_constraints(adv_weather_grad.cpu(), weather_scaler, constraint_types)\n",
    "                constraints_flat_grad = constraints_grad.view(B, -1).to(device)\n",
    "                logits_grad = model(constraints_flat_grad).squeeze()\n",
    "                prob_grad = torch.sigmoid(logits_grad).detach().cpu().numpy()\n",
    "                all_pred_proba.append(prob_grad)\n",
    "                all_true_labels.append(np.ones(B))\n",
    "\n",
    "    y_pred_proba = np.concatenate(all_pred_proba)\n",
    "    y_true = np.concatenate(all_true_labels)\n",
    "\n",
    "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "    correct = (y_pred == y_true).sum()\n",
    "    total = len(y_true)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    TP = ((y_pred == 1) & (y_true == 1)).sum()\n",
    "    FP = ((y_pred == 1) & (y_true == 0)).sum()\n",
    "    FN = ((y_pred == 0) & (y_true == 1)).sum()\n",
    "    TN = ((y_pred == 0) & (y_true == 0)).sum()\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    def compute_auc_manual(y_true, y_score):\n",
    "        indices = np.argsort(y_score)[::-1]\n",
    "        y_true_sorted = y_true[indices]\n",
    "        n_pos = y_true.sum()\n",
    "        n_neg = len(y_true) - n_pos\n",
    "        if n_pos == 0 or n_neg == 0:\n",
    "            return 0.5\n",
    "        tp = fp = auc = 0\n",
    "        for label in y_true_sorted:\n",
    "            if label == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                auc += tp\n",
    "                fp += 1\n",
    "        return auc / (n_pos * n_neg)\n",
    "\n",
    "    auc = compute_auc_manual(y_true, y_pred_proba)\n",
    "\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"EVALUATION: Constraints = {constraint_types}\")\n",
    "    print(f\"{'Metric':<12} {'Score':<10}\")\n",
    "    print(f\"{'-'*20}\")\n",
    "    print(f\"{'Accuracy':<12} {accuracy:.4f}\")\n",
    "    print(f\"{'Precision':<12} {precision:.4f}\")\n",
    "    print(f\"{'Recall':<12} {recall:.4f}\")\n",
    "    print(f\"{'F1-Score':<12} {f1:.4f}\")\n",
    "    print(f\"{'-'*20}\")\n",
    "    print(f\"Total samples: {total} (Normal: {int(TN+FP)}, Adv: {int(TP+FN)})\")\n",
    "    print(f\"Predictions: Predicted 0: {int(TN+FN)}, Predicted 1: {int(TP+FP)}\")\n",
    "    print(f\"Confusion: TP={TP}, FP={FP}, FN={FN}, TN={TN}\")\n",
    "    print(f\"Prob stats: [min={y_pred_proba.min():.4f}, max={y_pred_proba.max():.4f}, \"\n",
    "          f\"mean={y_pred_proba.mean():.4f}]\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'y_true': y_true,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'y_pred': y_pred,\n",
    "        'confusion': {'TP': int(TP), 'FP': int(FP), 'FN': int(FN), 'TN': int(TN)}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = [\n",
    "    ['c1'],\n",
    "    ['c2'],\n",
    "    ['c3'],\n",
    "    ['c1', 'c2'],\n",
    "    ['c1', 'c3'],\n",
    "    ['c2', 'c3']\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for combo in combinations:\n",
    "    name = \"_\".join(combo)\n",
    "    save_path = f\"{name}_detector_caiso.pth\"\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"STARTING TRAINING: {name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    trained_model, best_thresh = train_detector(  \n",
    "        train_loader=train_loader,\n",
    "        val_loader=test_loader,\n",
    "        weather_scaler=weather_scaler,\n",
    "        constraint_types=combo,\n",
    "        device=device,\n",
    "        save_path=save_path,\n",
    "        lr=1e-4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eec1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictorV2(nn.Module):\n",
    "    def __init__(self, d_model=64, nhead=4, num_layers=3, dim_feedforward=128, dropout=0.1, max_seq_len=300):\n",
    "        super(WindPowerPredictorV2, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.embedding_wind = nn.Linear(1, d_model)\n",
    "        self.embedding_weather = nn.Linear(8, d_model)\n",
    "\n",
    "        self.pos_encoder_wind = nn.Parameter(torch.zeros(max_seq_len, 1, d_model))\n",
    "        self.pos_encoder_weather = nn.Parameter(torch.zeros(max_seq_len, 1, d_model))\n",
    "\n",
    "\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=False\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "\n",
    "        self.fc_combine = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, wind_history, weather_future):\n",
    "        # wind_history: (batch_size, T1)        e.g., (32, 288)\n",
    "        # weather_future: (batch_size, T2, 8)    e.g., (32, 24, 8)\n",
    "\n",
    "        batch_size, seq_len_wind = wind_history.shape\n",
    "        _, seq_len_weather, _ = weather_future.shape\n",
    "\n",
    "        if seq_len_wind > self.pos_encoder_wind.size(0):\n",
    "            raise ValueError(f\"Wind sequence length {seq_len_wind} exceeds max supported length {self.pos_encoder_wind.size(0)}\")\n",
    "        if seq_len_weather > self.pos_encoder_weather.size(0):\n",
    "            raise ValueError(f\"Weather sequence length {seq_len_weather} exceeds max supported length {self.pos_encoder_weather.size(0)}\")\n",
    "\n",
    "        wind_emb = self.embedding_wind(wind_history.unsqueeze(-1))           # (B, T1, D)\n",
    "        weather_emb = self.embedding_weather(weather_future)                 # (B, T2, D)\n",
    "\n",
    "        wind_emb = wind_emb.permute(1, 0, 2)  # (T1, B, D)\n",
    "        weather_emb = weather_emb.permute(1, 0, 2)  # (T2, B, D)\n",
    "\n",
    "        wind_emb = wind_emb + self.pos_encoder_wind[:seq_len_wind]      # (T1, B, D)\n",
    "        weather_emb = weather_emb + self.pos_encoder_weather[:seq_len_weather]  # (T2, B, D)\n",
    "\n",
    "        wind_features = self.transformer_encoder(wind_emb)              # (T1, B, D)\n",
    "        weather_features = self.transformer_encoder(weather_emb)        # (T2, B, D)\n",
    "\n",
    "        wind_last = wind_features[-1, :, :]       \n",
    "        weather_last = weather_features[-1, :, :]  \n",
    "\n",
    "        combined = torch.cat((wind_last, weather_last), dim=1)  # (B, 2D)\n",
    "\n",
    "        output = self.fc_combine(combined)  # (B, 1)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "    \n",
    "model_path = 'wind_caiso_transformer_sigmoid_version2.pth'\n",
    "wind_power_model = WindPowerPredictorV2().to(device)\n",
    "wind_power_model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda4fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_power_model.eval()  \n",
    "combinations = [['c1'], ['c2'], ['c3'], ['c1', 'c2'], ['c1', 'c3']]\n",
    "\n",
    "results = {}\n",
    "print(\"Starting evaluation for all constraint combinations...\")\n",
    "\n",
    "for combo in combinations:\n",
    "    name = \"_\".join(combo)\n",
    "    save_path = f\"{name}_detector_caiso.pth\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EVALUATING: {name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Loading detector from: {save_path}\")\n",
    "\n",
    "    detector = ConstraintDetector(num_constraints=len(combo)).to(device)\n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(save_path, map_location=device)\n",
    "\n",
    "        detector.load_state_dict(checkpoint['model_state_dict'])\n",
    "        detector.eval()\n",
    "\n",
    "        best_threshold = checkpoint.get('best_threshold', 0.5)\n",
    "        print(f\"Detector loaded. Best threshold = {best_threshold:.4f}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Model file not found: {save_path}\")\n",
    "        results[name] = None\n",
    "        continue\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing key in checkpoint {save_path}: {e}\")\n",
    "        print(\"Hint: Make sure you're using the updated training code that saves 'best_threshold'.\")\n",
    "        results[name] = None\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {save_path}: {e}\")\n",
    "        results[name] = None\n",
    "        continue\n",
    "\n",
    "    metrics = evaluate_detector(\n",
    "        model=detector, \n",
    "        test_loader=test_loader,\n",
    "        uap_loaded_list=uap_loaded_list,\n",
    "        weather_scaler=weather_scaler,\n",
    "        wind_power_model=wind_power_model,      \n",
    "        constraint_types=combo,\n",
    "        device=device,\n",
    "        model_path=save_path  \n",
    "    )\n",
    "    results[name] = metrics\n",
    "    print(f\"Metrics for {name}: Accuracy={metrics['accuracy']:.4f}, AUC={metrics['auc']:.4f}\")\n",
    "\n",
    "print(\"\\n All evaluations completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee83f2",
   "metadata": {},
   "source": [
    "## If there is noise in the experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.lstm_wind = nn.LSTM(input_size=1, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm_weather = nn.LSTM(input_size=8, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(256, 1)\n",
    "        self.relu=nn.ReLU()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = wind_history.unsqueeze(-1)\n",
    "        _, (hn_wind, _) = self.lstm_wind(wind_history)\n",
    "        _, (hn_weather, _) = self.lstm_weather(weather_future)\n",
    "        hn_wind = hn_wind[-1, :, :]\n",
    "        hn_weather = hn_weather[-1, :, :]\n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.relu(output)\n",
    "        return output\n",
    "    \n",
    "def load_model(model_path, device='cpu'):\n",
    "    model = WindPowerPredictor().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "model_path = 'wind_caiso_lstm_sigmoid_version2.pth'\n",
    "model = load_model(model_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_constraints(weather_future, weather_scaler):\n",
    "    batch_size, seq_len, feature_dim = weather_future.shape\n",
    "    weather_future_reshaped = weather_future.view(-1, feature_dim)\n",
    "    weather_future_unscaled = weather_scaler.inverse_transform(weather_future_reshaped.detach().cpu().numpy())\n",
    "    weather_future_unscaled = torch.tensor(weather_future_unscaled, dtype=weather_future.dtype, device=weather_future.device)\n",
    "    weather_future_unscaled = weather_future_unscaled.view(batch_size, seq_len, feature_dim)\n",
    "    DNI = weather_future_unscaled[:, :, 1]\n",
    "    Solar_Zenith_Angle = weather_future_unscaled[:, :, 4]\n",
    "    DHI = weather_future_unscaled[:, :, 0]\n",
    "    GHI = weather_future_unscaled[:, :, 2]\n",
    "    Dew_Point = weather_future_unscaled[:, :, 3]\n",
    "    Temperature = weather_future_unscaled[:, :, 7]\n",
    "    Relative_Humidity = weather_future_unscaled[:, :, 6]\n",
    "    cos_sza = torch.cos(Solar_Zenith_Angle * np.pi / 180.0)\n",
    "    constraint_1 = torch.abs((DNI * cos_sza + DHI) - GHI)  # GHI = DNI*cos + DHI\n",
    "    constraint_2 = torch.relu(Dew_Point - Temperature)     # Dew point <= Temperature\n",
    "    constraint_3 = torch.abs(\n",
    "        100 * torch.exp(17.625 * Dew_Point / (243.04 + Dew_Point)) /\n",
    "        torch.exp(17.625 * Temperature / (243.04 + Temperature)) - Relative_Humidity\n",
    "    )\n",
    "\n",
    "    return torch.stack([constraint_1, constraint_2, constraint_3], dim=-1)\n",
    "\n",
    "class ConstraintClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=72):\n",
    "        super(ConstraintClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b96341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_constraint_classifier(test_loader, uap_loaded_list, classifier_model, wind_power_model, weather_scaler, device='cuda', sensor_noise_std=0.0):\n",
    "    wind_power_model.train()  \n",
    "    classifier_model.eval()   \n",
    "\n",
    "    all_uap_labels = []\n",
    "    all_uap_preds = []\n",
    "    all_bp_labels = []\n",
    "    all_bp_preds = []\n",
    "\n",
    "    epsilons = [0.03, 0.05, 0.10]\n",
    "\n",
    "    add_noise = sensor_noise_std > 0\n",
    "    noise_desc = f\" (with sensor noise σ={sensor_noise_std})\" if add_noise else \"\"\n",
    "\n",
    "    print(f\"Testing attack detection{noise_desc}\")\n",
    "\n",
    "    for history_weather, wind_history, weather_future, future_wind_power in test_loader:\n",
    "        B = weather_future.size(0)\n",
    "        wind_history = wind_history.to(device)\n",
    "        weather_future = weather_future.to(device)\n",
    "        future_wind_power = future_wind_power.to(device)\n",
    "\n",
    "        if add_noise:\n",
    "            noise = torch.randn_like(weather_future) * sensor_noise_std\n",
    "            weather_future_noisy = torch.clamp(weather_future + noise, 0, 1)\n",
    "        else:\n",
    "            weather_future_noisy = weather_future\n",
    "\n",
    "        normal_constraints = compute_constraints(weather_future_noisy.cpu(), weather_scaler).to(device)\n",
    "        normal_constraints = normal_constraints.view(B, -1)\n",
    "\n",
    "        all_attacked_constraints = []\n",
    "        for uap_loaded in uap_loaded_list:\n",
    "            attacked_weather = torch.clamp(weather_future_noisy + uap_loaded.to(device), 0, 1)\n",
    "            attacked_constraints = compute_constraints(attacked_weather.cpu(), weather_scaler).to(device)\n",
    "            attacked_constraints = attacked_constraints.view(B, -1)\n",
    "            all_attacked_constraints.append(attacked_constraints)\n",
    "\n",
    "        if all_attacked_constraints:\n",
    "            attacked_constraints_cat = torch.cat(all_attacked_constraints, dim=0)\n",
    "            constraints_uap = torch.cat([normal_constraints, attacked_constraints_cat], dim=0)\n",
    "            labels_uap = torch.cat([\n",
    "                torch.ones(B, device=device),  \n",
    "                torch.zeros(attacked_constraints_cat.size(0), device=device)  \n",
    "            ])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = classifier_model(constraints_uap).squeeze()\n",
    "                preds = (outputs > 0.5).float()\n",
    "\n",
    "            all_uap_labels.append(labels_uap.cpu().numpy())\n",
    "            all_uap_preds.append(preds.cpu().numpy())\n",
    "\n",
    "        wind_power_model.train()\n",
    "        for param in wind_power_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        weather_input_for_grad = weather_future_noisy.clone().detach().requires_grad_(True)\n",
    "        pred_power = wind_power_model(wind_history, weather_input_for_grad)\n",
    "\n",
    "        if pred_power.dim() == 1:\n",
    "            pred_power = pred_power.unsqueeze(1)\n",
    "        if future_wind_power.dim() == 1:\n",
    "            future_wind_power = future_wind_power.unsqueeze(1)\n",
    "\n",
    "        loss_power = nn.MSELoss()(pred_power.squeeze(), future_wind_power.squeeze())\n",
    "\n",
    "        if loss_power.grad_fn is None:\n",
    "            raise RuntimeError(\"loss_power has no grad_fn! Check if gradients are disabled.\")\n",
    "\n",
    "        wind_power_model.zero_grad()\n",
    "        loss_power.backward()\n",
    "\n",
    "        grad_sign = weather_input_for_grad.grad.data.sign()\n",
    "\n",
    "        all_attacked_constraints_bp = []\n",
    "        for eps in epsilons:\n",
    "            adv_weather = torch.clamp(weather_input_for_grad + eps * grad_sign, 0, 1)\n",
    "            attacked_constraints = compute_constraints(adv_weather.cpu(), weather_scaler).to(device)\n",
    "            attacked_constraints = attacked_constraints.view(B, -1)\n",
    "            all_attacked_constraints_bp.append(attacked_constraints)\n",
    "\n",
    "        if all_attacked_constraints_bp:\n",
    "            attacked_constraints_bp_cat = torch.cat(all_attacked_constraints_bp, dim=0)\n",
    "\n",
    "            constraints_bp = torch.cat([normal_constraints, attacked_constraints_bp_cat], dim=0)\n",
    "            labels_bp = torch.cat([\n",
    "                torch.ones(B, device=device),\n",
    "                torch.zeros(attacked_constraints_bp_cat.size(0), device=device)\n",
    "            ])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = classifier_model(constraints_bp).squeeze()\n",
    "                preds = (outputs > 0.5).float()\n",
    "\n",
    "            all_bp_labels.append(labels_bp.cpu().numpy())\n",
    "            all_bp_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    def compute_metrics(true_labels, preds):\n",
    "        true_labels = np.concatenate(true_labels)\n",
    "        preds = np.concatenate(preds)\n",
    "\n",
    "        acc = (preds == true_labels).mean() * 100\n",
    "        precision = precision_score(true_labels, preds, average='weighted', zero_division=0) * 100\n",
    "        recall = recall_score(true_labels, preds, average='weighted', zero_division=0) * 100\n",
    "        f1 = f1_score(true_labels, preds, average='weighted', zero_division=0) * 100\n",
    "\n",
    "        return acc, precision, recall, f1\n",
    "\n",
    "    if all_uap_labels:\n",
    "        uap_acc, uap_prec, uap_rec, uap_f1 = compute_metrics(all_uap_labels, all_uap_preds)\n",
    "        print(f'UAP Attack Detection Results{noise_desc}:')\n",
    "        print(f'   Accuracy:  {uap_acc:.2f}%')\n",
    "        print(f'   Precision: {uap_prec:.2f}%')\n",
    "        print(f'   Recall:    {uap_rec:.2f}%')\n",
    "        print(f'   F1-Score:  {uap_f1:.2f}%')\n",
    "    else:\n",
    "        uap_acc = uap_prec = uap_rec = uap_f1 = 0\n",
    "        print('No UAP samples evaluated.')\n",
    "\n",
    "    if all_bp_labels:\n",
    "        bp_acc, bp_prec, bp_rec, bp_f1 = compute_metrics(all_bp_labels, all_bp_preds)\n",
    "        print(f'FGSM (Backpropagation) Attack Detection Results{noise_desc}:')\n",
    "        print(f'   Accuracy:  {bp_acc:.2f}%')\n",
    "        print(f'   Precision: {bp_prec:.2f}%')\n",
    "        print(f'   Recall:    {bp_rec:.2f}%')\n",
    "        print(f'   F1-Score:  {bp_f1:.2f}%')\n",
    "    else:\n",
    "        bp_acc = bp_prec = bp_rec = bp_f1 = 0\n",
    "        print('No BP (FGSM) samples evaluated.')\n",
    "\n",
    "    return uap_acc, uap_prec, uap_rec, uap_f1, bp_acc, bp_prec, bp_rec, bp_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self, d_model=50):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding_wind = nn.Linear(1, d_model)\n",
    "        self.embedding_weather = nn.Linear(8, d_model)\n",
    "        self.transformer_wind = nn.Transformer(\n",
    "            d_model=d_model, nhead=2, num_encoder_layers=2, num_decoder_layers=2, dim_feedforward=200, dropout=0.1\n",
    "        )\n",
    "        self.transformer_weather = nn.Transformer(\n",
    "            d_model=d_model, nhead=2, num_encoder_layers=2, num_decoder_layers=2, dim_feedforward=200, dropout=0.1\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = self.embedding_wind(wind_history.unsqueeze(-1))  # (batch_size, seq_len, d_model)\n",
    "        wind_history = wind_history.permute(1, 0, 2)  # (seq_len, batch_size, d_model)\n",
    "        weather_future = self.embedding_weather(weather_future)  # (batch_size, seq_len, d_model)\n",
    "        weather_future = weather_future.permute(1, 0, 2)  # (seq_len, batch_size, d_model)\n",
    "\n",
    "        transformer_output_wind = self.transformer_wind(wind_history, wind_history)\n",
    "        transformer_output_weather = self.transformer_weather(weather_future, weather_future)\n",
    "        \n",
    "        combined = torch.cat((transformer_output_wind[-1, :, :], transformer_output_weather[-1, :, :]), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.sigmoid(output)  \n",
    "        return output\n",
    "    \n",
    "#wind_caiso_transformer_sigmoid.pth\n",
    "model_path = 'wind_caiso_transformer_sigmoid.pth'\n",
    "wind_power_model= load_model(model_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9238efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = ConstraintClassifier(input_dim=72)\n",
    "classifier_model.load_state_dict(torch.load('CAISO_zone_1_PALM.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_stds = [0.001, 0.002, 0.003, 0.005]\n",
    "results = []\n",
    "\n",
    "for noise_std in noise_stds:\n",
    "    print(f\"\\nRunning test with sensor_noise_std = {noise_std}\")\n",
    "    metrics = test_constraint_classifier(\n",
    "        test_loader=test_loader,\n",
    "        uap_loaded_list=uap_loaded_list,\n",
    "        classifier_model=classifier_model,\n",
    "        wind_power_model=wind_power_model,\n",
    "        weather_scaler=weather_scaler,\n",
    "        device='cuda',\n",
    "        sensor_noise_std=noise_std\n",
    "    )\n",
    "    results.append((noise_std, metrics))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
