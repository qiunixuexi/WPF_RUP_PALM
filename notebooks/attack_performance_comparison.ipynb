{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58223092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error,r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484365a",
   "metadata": {},
   "source": [
    "## 0. Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "name='CAISO_zone_1_.csv'\n",
    "surrogate_model_path = 'transformer_wind_power_model2_CAISO_zone_1_.pth'\n",
    "with open('weather_scaler.pkl', 'rb') as f:\n",
    "    weather_scaler = pickle.load(f)\n",
    "\n",
    "class WindPowerDataset(Dataset):\n",
    "    def __init__(self, csv_file, wind_power_scaler=None, weather_scaler=None, save_scalers=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.data = self.data.iloc[::5, :].reset_index(drop=True)\n",
    "\n",
    "        self.original_wind_power_std = self.data.iloc[:, 2].std()\n",
    "        self.original_weather_std = self.data.iloc[:, 4:12].std()\n",
    "\n",
    "        if wind_power_scaler is None or weather_scaler is None:\n",
    "            self.wind_power_scaler = MinMaxScaler()\n",
    "            self.weather_scaler = MinMaxScaler()\n",
    "\n",
    "            self.data.iloc[:, 2] = self.wind_power_scaler.fit_transform(self.data.iloc[:, 2].values.reshape(-1, 1)).squeeze()\n",
    "\n",
    "            self.data.iloc[:, 4:12] = self.weather_scaler.fit_transform(self.data.iloc[:, 4:12])\n",
    "            \n",
    "            if save_scalers:\n",
    "                with open('wind_power_scaler.pkl', 'wb') as f:\n",
    "                    pickle.dump(self.wind_power_scaler, f)\n",
    "                with open('weather_scaler.pkl', 'wb') as f:\n",
    "                    pickle.dump(self.weather_scaler, f)\n",
    "        else:\n",
    "            self.wind_power_scaler = wind_power_scaler\n",
    "            self.weather_scaler = weather_scaler\n",
    "            self.data.iloc[:, 2] = self.wind_power_scaler.transform(self.data.iloc[:, 2].values.reshape(-1, 1)).squeeze()\n",
    "            self.data.iloc[:, 4:12] = self.weather_scaler.transform(self.data.iloc[:, 4:12])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - 312  # 288 (1440/5) + 24 (120/5)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        wind_power_history = self.data.iloc[idx:idx + 288, 2].values.astype(float)\n",
    "        future_weather = self.data.iloc[idx + 288:idx + 312, 4:12].values.astype(float)\n",
    "        future_wind_power = self.data.iloc[idx + 312, 2]\n",
    "        return torch.tensor(wind_power_history, dtype=torch.float32), \\\n",
    "               torch.tensor(future_weather, dtype=torch.float32), \\\n",
    "               torch.tensor(future_wind_power, dtype=torch.float32)\n",
    "    \n",
    "    def get_original_stds(self):\n",
    "        return {\n",
    "            'original_wind_power_std': self.original_wind_power_std,\n",
    "            'original_weather_std': self.original_weather_std.to_dict()\n",
    "        }\n",
    "\n",
    "dataset = WindPowerDataset(name, save_scalers=True)\n",
    "weather_stds = dataset.get_original_stds()\n",
    "weather_stds_array = np.array(list(weather_stds['original_weather_std'].values()))  \n",
    "weather_data = pd.read_csv(name)\n",
    "weather_data = weather_data.iloc[::5, :].reset_index(drop=True)\n",
    "weather_mean = weather_data.iloc[:, 4:12].mean()\n",
    "wind_power_scaler=dataset.wind_power_scaler\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size=32\n",
    "test_split=0.2\n",
    "test_size = int(len(dataset) * test_split)\n",
    "train_size = len(dataset) - test_size\n",
    "train_dataset = Subset(dataset, list(range(train_size)))\n",
    "test_dataset = Subset(dataset, list(range(train_size, len(dataset))))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867dbba",
   "metadata": {},
   "source": [
    "## 1. Load surrogate model and target model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5708d336",
   "metadata": {},
   "source": [
    "### traget model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad65881",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.lstm_wind = nn.LSTM(input_size=1, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm_weather = nn.LSTM(input_size=8, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(256, 1)\n",
    "        self.relu=nn.ReLU()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = wind_history.unsqueeze(-1)\n",
    "        _, (hn_wind, _) = self.lstm_wind(wind_history)\n",
    "        _, (hn_weather, _) = self.lstm_weather(weather_future)\n",
    "        hn_wind = hn_wind[-1, :, :]\n",
    "        hn_weather = hn_weather[-1, :, :]\n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.relu(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd17837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, device='cpu'):\n",
    "    model = WindPowerPredictor().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = 'wind_caiso_lstm_sigmoid_version2.pth'\n",
    "model = load_model(model_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bcf972",
   "metadata": {},
   "source": [
    "### surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5881a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(WindPowerPredictor, self).__init__()  \n",
    "        self.gru_wind = nn.GRU(input_size=1, hidden_size=50, num_layers=2, batch_first=True)  \n",
    "        self.gru_weather = nn.GRU(input_size=8, hidden_size=50, num_layers=2, batch_first=True)  \n",
    "        self.fc = nn.Linear(100, 1)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "      \n",
    "    def forward(self, wind_history, weather_future):  \n",
    "        wind_history = wind_history.unsqueeze(-1)  \n",
    "        _, hn_wind = self.gru_wind(wind_history)  \n",
    "        _, hn_weather = self.gru_weather(weather_future)  \n",
    "        hn_wind = hn_wind[-1, :, :]  \n",
    "        hn_weather = hn_weather[-1, :, :]  \n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)  \n",
    "        output = self.fc(combined)  \n",
    "        output = self.sigmoid(output)\n",
    "        return output  \n",
    "    \n",
    "model_path1 = 'wind_gru_caiso_sigmoid.pth'\n",
    "model1 = load_model(model_path1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75e8ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self, d_model=50):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding_wind = nn.Linear(1, d_model)\n",
    "        self.embedding_weather = nn.Linear(8, d_model)\n",
    "        self.transformer_wind = nn.Transformer(\n",
    "            d_model=d_model, nhead=2, num_encoder_layers=2, num_decoder_layers=2, dim_feedforward=200, dropout=0.1\n",
    "        )\n",
    "        self.transformer_weather = nn.Transformer(\n",
    "            d_model=d_model, nhead=2, num_encoder_layers=2, num_decoder_layers=2, dim_feedforward=200, dropout=0.1\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = self.embedding_wind(wind_history.unsqueeze(-1))  # (batch_size, seq_len, d_model)\n",
    "        wind_history = wind_history.permute(1, 0, 2)  # (seq_len, batch_size, d_model)\n",
    "        weather_future = self.embedding_weather(weather_future)  # (batch_size, seq_len, d_model)\n",
    "        weather_future = weather_future.permute(1, 0, 2)  # (seq_len, batch_size, d_model)\n",
    "\n",
    "        transformer_output_wind = self.transformer_wind(wind_history, wind_history)\n",
    "        transformer_output_weather = self.transformer_weather(weather_future, weather_future)\n",
    "        \n",
    "        combined = torch.cat((transformer_output_wind[-1, :, :], transformer_output_weather[-1, :, :]), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.sigmoid(output)  \n",
    "        return output\n",
    "    \n",
    "model_path2 = 'wind_caiso_transformer_sigmoid.pth'\n",
    "model2 = load_model(model_path2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0158db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=(kernel_size-1) * dilation_size, dilation=dilation_size),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Dropout(dropout)]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class WindPowerPredictorTCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WindPowerPredictorTCN, self).__init__()\n",
    "        self.tcn_wind = TemporalConvNet(num_inputs=1, num_channels=[50]*3, kernel_size=3, dropout=0.2)\n",
    "        self.tcn_weather = TemporalConvNet(num_inputs=8, num_channels=[50]*3, kernel_size=3, dropout=0.2)\n",
    "        self.fc = nn.Linear(50 * 2, 1)  # Combined output size of TCNs\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = wind_history.unsqueeze(1)  # (batch_size, 1, seq_len)\n",
    "        tcn_output_wind = self.tcn_wind(wind_history).transpose(1, 2)[:, -1, :]\n",
    "        \n",
    "        weather_future = weather_future.transpose(1, 2)  # (batch_size, 8, seq_len)\n",
    "        tcn_output_weather = self.tcn_weather(weather_future).transpose(1, 2)[:, -1, :]\n",
    "        \n",
    "        combined = torch.cat((tcn_output_wind, tcn_output_weather), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "    \n",
    "model3 = WindPowerPredictorTCN()\n",
    "model_path3 = 'wind_tcn_caiso_sigmoid.pth'\n",
    "model3.load_state_dict(torch.load(model_path3)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86442103",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.lstm_wind = nn.LSTM(input_size=1, hidden_size=50, num_layers=2, batch_first=True)\n",
    "        self.lstm_weather = nn.LSTM(input_size=8, hidden_size=50, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(100, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = wind_history.unsqueeze(-1)\n",
    "        _, (hn_wind, _) = self.lstm_wind(wind_history)\n",
    "        _, (hn_weather, _) = self.lstm_weather(weather_future)\n",
    "        hn_wind = hn_wind[-1, :, :]\n",
    "        hn_weather = hn_weather[-1, :, :]\n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.sigmoid(output)  \n",
    "        return output\n",
    "    \n",
    "model_path4 = 'wind_caiso_lstm_sigmoid.pth'\n",
    "model4 = WindPowerPredictor()\n",
    "model4.load_state_dict(torch.load(model_path4)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c5597",
   "metadata": {},
   "source": [
    "## Attack peroformance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e64218",
   "metadata": {},
   "source": [
    "### RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b28648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_attack_RA(model, data_loader, epsilon=0.01, device='cpu'):\n",
    "    model.eval()  \n",
    "    all_preds = []\n",
    "    all_adversarial_preds = []\n",
    "    all_targets = []\n",
    "    all_original_weather = []\n",
    "    all_adversarial_weather = []\n",
    "    \n",
    "    for parameters in model.parameters():\n",
    "        parameters.requires_grad = False\n",
    "    \n",
    "    for wind_history, weather_future, future_wind_power in data_loader:\n",
    "        wind_history = wind_history.to(device)\n",
    "        weather_future = weather_future.to(device)\n",
    "        future_wind_power = future_wind_power.to(device)\n",
    "        original_output = model(wind_history, weather_future)\n",
    "        uap=torch.empty_like(weather_future).uniform_(-epsilon, epsilon)\n",
    "        adversarial_weather = weather_future +uap\n",
    "        adversarial_weather = torch.clamp(adversarial_weather, 0, 1)  \n",
    "        adversarial_output = model(wind_history, adversarial_weather.detach())  \n",
    "        all_preds.append(original_output.detach().cpu().numpy())\n",
    "        all_adversarial_preds.append(adversarial_output.detach().cpu().numpy())\n",
    "        all_targets.append(future_wind_power.cpu().numpy())\n",
    "        all_original_weather.append(weather_future.detach().cpu().numpy())\n",
    "        all_adversarial_weather.append(adversarial_weather.detach().cpu().numpy())\n",
    "\n",
    "    model.eval()  \n",
    "\n",
    "    return all_preds, all_adversarial_preds, all_targets, all_original_weather, all_adversarial_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c167e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_list=[0.03,0.05,0.1]\n",
    "for epsilon in epsilon_list:\n",
    "    original_preds, adversarial_preds, targets, original_weathers, adversarial_weathers = adversarial_attack_RA(model, test_loader, epsilon=epsilon, device=device)\n",
    "    all_targets = np.concatenate(targets).flatten()\n",
    "    all_adversarial_preds=np.concatenate(adversarial_preds).flatten()\n",
    "    all_targets_inv=wind_power_scaler.inverse_transform(np.array(all_targets).reshape(-1, 1)).squeeze()\n",
    "    all_preds_inv=wind_power_scaler.inverse_transform(np.array(all_adversarial_preds).reshape(-1, 1)).squeeze()\n",
    "    rmse = mean_squared_error(all_targets_inv, all_preds_inv, squared=False)\n",
    "    mse = mean_squared_error(all_targets_inv, all_preds_inv)\n",
    "    print(f'RMSE_inv: {rmse:.10f}')\n",
    "    print(f'MSE_inv: {mse:.10f}')\n",
    "    mae = mean_absolute_error(all_targets_inv, all_preds_inv)\n",
    "    print(f'MAE_inv: {mae:.10f}')\n",
    "    print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd453a",
   "metadata": {},
   "source": [
    "### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_attack_FGSM(sur_model, model, data_loader, epsilon=0.01, device='cpu'):\n",
    "    sur_model.train()  \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_adversarial_preds = []\n",
    "    all_targets = []\n",
    "    all_original_weather = []\n",
    "    all_adversarial_weather = []\n",
    "\n",
    "    for parameters in sur_model.parameters():\n",
    "        parameters.requires_grad = False\n",
    "    \n",
    "    for wind_history, weather_future, future_wind_power in data_loader:\n",
    "        wind_history = wind_history.to(device)\n",
    "        weather_future = weather_future.to(device)\n",
    "        future_wind_power = future_wind_power.to(device)\n",
    "        weather_future.requires_grad = True\n",
    "        original_output = model(wind_history, weather_future)\n",
    "        sur_original_output = sur_model(wind_history, weather_future)\n",
    "        original_loss = torch.sum(sur_original_output.squeeze()- future_wind_power)\n",
    "        sur_model.zero_grad()\n",
    "        original_loss.backward()  \n",
    "\n",
    "        # adversarial perturbation\n",
    "        weather_future_grad = weather_future.grad.data\n",
    "        adversarial_weather = weather_future + epsilon * weather_future_grad.sign()\n",
    "        adversarial_weather = torch.clamp(adversarial_weather, 0, 1)  # ensure the data is within a reasonable range\n",
    "        adversarial_output = model(wind_history, adversarial_weather.detach())  \n",
    "\n",
    "        all_preds.append(original_output.detach().cpu().numpy())\n",
    "        all_adversarial_preds.append(adversarial_output.detach().cpu().numpy())\n",
    "        all_targets.append(future_wind_power.cpu().numpy())\n",
    "        all_original_weather.append(weather_future.detach().cpu().numpy())\n",
    "        all_adversarial_weather.append(adversarial_weather.detach().cpu().numpy())\n",
    "\n",
    "    model.eval()  \n",
    "\n",
    "    return all_preds, all_adversarial_preds, all_targets, all_original_weather, all_adversarial_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c07383",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_list=[0.03,0.05,0.1]\n",
    "sur_model_list=[model1,model2,model3,model4]\n",
    "for sur_model in sur_model_list:\n",
    "    for epsilon in epsilon_list:\n",
    "        original_preds, adversarial_preds, targets, original_weathers, adversarial_weathers = adversarial_attack_FGSM(sur_model, model, test_loader, epsilon=epsilon, device=device)\n",
    "        all_targets = np.concatenate(targets).flatten()\n",
    "        all_adversarial_preds=np.concatenate(adversarial_preds).flatten()\n",
    "        all_targets_inv=wind_power_scaler.inverse_transform(np.array(all_targets).reshape(-1, 1)).squeeze()\n",
    "        all_preds_inv=wind_power_scaler.inverse_transform(np.array(all_adversarial_preds).reshape(-1, 1)).squeeze()\n",
    "        rmse = mean_squared_error(all_targets_inv, all_preds_inv, squared=False)\n",
    "        mse = mean_squared_error(all_targets_inv, all_preds_inv)\n",
    "        print(f'RMSE_inv: {rmse:.10f}')\n",
    "        print(f'MSE_inv: {mse:.10f}')\n",
    "        mae = mean_absolute_error(all_targets_inv, all_preds_inv)\n",
    "        print(f'MAE_inv: {mae:.10f}')\n",
    "        print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf7456",
   "metadata": {},
   "source": [
    "### PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb8ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_attack_PGD(sur_model, model, data_loader, epsilon=0.01, alpha=0.003, num_iterations=80, device='cpu'):\n",
    "    sur_model.train()  \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_adversarial_preds = []\n",
    "    all_targets = []\n",
    "    all_original_weather = []\n",
    "    all_adversarial_weather = []\n",
    "\n",
    "    for parameters in sur_model.parameters():\n",
    "        parameters.requires_grad = False\n",
    "\n",
    "    for wind_history, weather_future, future_wind_power in data_loader:\n",
    "        wind_history = wind_history.to(device)\n",
    "        weather_future = weather_future.to(device)\n",
    "        future_wind_power = future_wind_power.to(device)\n",
    "        adversarial_weather = weather_future.clone().detach()\n",
    "        adversarial_weather.requires_grad = True\n",
    "        original_output = model(wind_history, weather_future)\n",
    "\n",
    "        sur_original_output = sur_model(wind_history, weather_future)\n",
    "        for i in range(num_iterations):\n",
    "            original_output = model(wind_history, adversarial_weather)\n",
    "            \n",
    "            sur_original_output = sur_model(wind_history, adversarial_weather)\n",
    "            original_loss = torch.sum(sur_original_output.squeeze()- future_wind_power)\n",
    "            sur_model.zero_grad()\n",
    "            original_loss.backward()  \n",
    "            with torch.no_grad():\n",
    "                weather_future_grad = adversarial_weather.grad.data\n",
    "                adversarial_weather += alpha * weather_future_grad.sign()\n",
    "                adversarial_weather = torch.max(torch.min(adversarial_weather, weather_future + epsilon),\n",
    "                                                weather_future - epsilon)\n",
    "                adversarial_weather = torch.clamp(adversarial_weather, 0,1)\n",
    "                adversarial_weather = adversarial_weather.detach().requires_grad_(True)\n",
    "     \n",
    "        adversarial_output = model(wind_history, adversarial_weather)\n",
    "        original_output = model(wind_history, weather_future)\n",
    "\n",
    "        all_preds.append(original_output.detach().cpu().numpy())\n",
    "        all_adversarial_preds.append(adversarial_output.detach().cpu().numpy())\n",
    "        all_targets.append(future_wind_power.cpu().numpy())\n",
    "        all_original_weather.append(weather_future.detach().cpu().numpy())\n",
    "        all_adversarial_weather.append(adversarial_weather.detach().cpu().numpy())\n",
    "    sur_model.eval()  \n",
    "    \n",
    "    return all_preds, all_adversarial_preds, all_targets, all_original_weather, all_adversarial_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_list=[0.03,0.05,0.1]\n",
    "sur_model_list=[model1,model2,model3,model4]\n",
    "for sur_model in sur_model_list:\n",
    "    for epsilon in epsilon_list:\n",
    "        original_preds, adversarial_preds, targets, original_weathers, adversarial_weathers = adversarial_attack_PGD(sur_model, model, test_loader, epsilon=epsilon, device=device)\n",
    "        all_targets = np.concatenate(targets).flatten()\n",
    "        all_adversarial_preds=np.concatenate(adversarial_preds).flatten()\n",
    "        all_targets_inv=wind_power_scaler.inverse_transform(np.array(all_targets).reshape(-1, 1)).squeeze()\n",
    "        all_preds_inv=wind_power_scaler.inverse_transform(np.array(all_adversarial_preds).reshape(-1, 1)).squeeze()\n",
    "        rmse = mean_squared_error(all_targets_inv, all_preds_inv, squared=False)\n",
    "        mse = mean_squared_error(all_targets_inv, all_preds_inv)\n",
    "        print(f'RMSE_inv: {rmse:.10f}')\n",
    "        print(f'MSE_inv: {mse:.10f}')\n",
    "        mae = mean_absolute_error(all_targets_inv, all_preds_inv)\n",
    "        print(f'MAE_inv: {mae:.10f}')\n",
    "        print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2497766c",
   "metadata": {},
   "source": [
    "### AoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b263800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "import torch.optim as optim\n",
    "\n",
    "def compute_attention(model, wind_history, weather_input, baseline_type='zero'):\n",
    "    was_training = model.training\n",
    "    try:\n",
    "        model.train()\n",
    "        if not weather_input.requires_grad:\n",
    "            weather_input.requires_grad_(True)\n",
    "\n",
    "        with torch.backends.cudnn.flags(enabled=False):\n",
    "            output = model(wind_history, weather_input)\n",
    "\n",
    "        grad_outputs = torch.ones_like(output)\n",
    "        \n",
    "        grads = torch.autograd.grad(\n",
    "            outputs=output,\n",
    "            inputs=weather_input,\n",
    "            grad_outputs=grad_outputs,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        attention = torch.abs(grads * weather_input)\n",
    "        return attention.contiguous()\n",
    "\n",
    "    finally:\n",
    "        if not was_training:\n",
    "            model.eval()\n",
    "\n",
    "def generate_universal_adversarial_samples(\n",
    "    surrogate_models,\n",
    "    test_loader,\n",
    "    device,\n",
    "    lambda_aoa=1.0,\n",
    "    lambda_reg=10.0,\n",
    "    epsilon=0.1,  \n",
    "    num_steps=10,\n",
    "    learning_rate=0.01,\n",
    "    target_bias=0.1, \n",
    "    save_path=\"universal_adversarial_samples.pkl\"\n",
    "):\n",
    "   \n",
    "    for model in surrogate_models:\n",
    "        model.train() \n",
    "\n",
    "    adversarial_samples = []\n",
    "\n",
    "    for batch_idx, (wind_history, future_weather, true_power) in enumerate(test_loader):\n",
    "        wind_history = wind_history.to(device)\n",
    "        future_weather = future_weather.to(device)\n",
    "        true_power = true_power.to(device)\n",
    "\n",
    "        A_ori_list = []\n",
    "        for model in surrogate_models:\n",
    "            A_ori = compute_attention(model, wind_history, future_weather, baseline_type='original')\n",
    "            A_ori_list.append(A_ori.detach())\n",
    "\n",
    "        future_weather_adv = future_weather.detach().clone().requires_grad_(True)\n",
    "        optimizer = optim.Adam([future_weather_adv], lr=learning_rate)\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            optimizer.zero_grad()\n",
    "            total_loss = 0.0\n",
    "\n",
    "            for i, model in enumerate(surrogate_models):\n",
    "                A_adv = compute_attention(model, wind_history, future_weather_adv, baseline_type='original')\n",
    "                A_ori_flat = A_ori_list[i].reshape(A_ori_list[i].size(0), -1)  \n",
    "                A_adv_flat = A_adv.reshape(A_adv.size(0), -1)\n",
    "                cos_sim = nn.functional.cosine_similarity(A_ori_flat, A_adv_flat, dim=1)\n",
    "                L_aoa = -cos_sim.mean()\n",
    "\n",
    "                pred_adv = model(wind_history, future_weather_adv).squeeze()\n",
    "                pred_ori = model(wind_history, future_weather).squeeze().detach()\n",
    "                L_reg = -pred_adv.mean()\n",
    "\n",
    "                loss = lambda_aoa * L_aoa + lambda_reg * L_reg\n",
    "                total_loss += loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                future_weather_adv.data = torch.clamp(\n",
    "                    future_weather_adv,\n",
    "                    min=future_weather - epsilon,\n",
    "                    max=future_weather + epsilon\n",
    "                )\n",
    "\n",
    "        adversarial_samples.append({\n",
    "            'index': batch_idx,\n",
    "            'wind_history': wind_history.cpu().detach().numpy(),\n",
    "            'future_weather_original': future_weather.cpu().detach().numpy(),\n",
    "            'future_weather_adversarial': future_weather_adv.cpu().detach().numpy(),\n",
    "            'true_power': true_power.cpu().detach().numpy()\n",
    "        })\n",
    "\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Batch {batch_idx}, Loss: {total_loss.item():.4f}\")\n",
    "    return adversarial_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4077fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack_with_mae(surrogate_models, adversarial_samples, device, wind_power_scaler=None):\n",
    "    results = []\n",
    "    for model_idx, model in enumerate(surrogate_models):\n",
    "        model.eval()\n",
    "        total_bias = 0.0\n",
    "        total_mae_ori = 0.0\n",
    "        total_mae_adv = 0.0\n",
    "        count = 0\n",
    "        \n",
    "        for sample in adversarial_samples:\n",
    "            wind_history = torch.tensor(sample['wind_history'], dtype=torch.float32).to(device)\n",
    "            future_weather_ori = torch.tensor(sample['future_weather_original'], dtype=torch.float32).to(device)\n",
    "            future_weather_adv = torch.tensor(sample['future_weather_adversarial'], dtype=torch.float32).to(device)\n",
    "            true_power = torch.tensor(sample['true_power'], dtype=torch.float32).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred_ori = model(wind_history, future_weather_ori).squeeze()\n",
    "                pred_adv = model(wind_history, future_weather_adv).squeeze()\n",
    "                \n",
    "                bias = (pred_adv - pred_ori).mean().item()\n",
    "                total_bias += bias\n",
    "                \n",
    "                mae_ori = torch.abs(pred_ori - true_power).mean().item()\n",
    "                mae_adv = torch.abs(pred_adv - true_power).mean().item()\n",
    "                total_mae_ori += mae_ori\n",
    "                total_mae_adv += mae_adv\n",
    "                \n",
    "                count += 1\n",
    "        \n",
    "        avg_bias = total_bias / count\n",
    "        avg_mae_ori = total_mae_ori / count\n",
    "        avg_mae_adv = total_mae_adv / count\n",
    "        mae_increase = avg_mae_adv - avg_mae_ori\n",
    "        \n",
    "        result = {\n",
    "            'model_idx': model_idx,\n",
    "            'avg_prediction_bias': avg_bias,\n",
    "            'avg_mae_original': avg_mae_ori,\n",
    "            'avg_mae_adversarial': avg_mae_adv,\n",
    "            'mae_increase': mae_increase\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"Model {model_idx}:\")\n",
    "        print(f\"adversarial MAE = {avg_mae_adv:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f7390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_aoa_attack_and_save(\n",
    "    surrogate_models,\n",
    "    test_loader,\n",
    "    device,\n",
    "    wind_power_scaler,\n",
    "    epsilon=0.1,\n",
    "    num_steps=20,\n",
    "    learning_rate=0.01,\n",
    "    lambda_aoa=1.0,\n",
    "    lambda_reg=10.0,\n",
    "    model_idx_to_use=0,  \n",
    "    save_csv_name=\"buchong_AoA.csv\"\n",
    "):\n",
    "\n",
    "    print(f\"\\n AoA attack (epsilon={epsilon})...\")\n",
    "\n",
    "    adversarial_samples = generate_universal_adversarial_samples(\n",
    "        surrogate_models=surrogate_models,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        lambda_aoa=lambda_aoa,\n",
    "        lambda_reg=lambda_reg,\n",
    "        epsilon=epsilon,\n",
    "        num_steps=num_steps,\n",
    "        learning_rate=learning_rate,\n",
    "        target_bias=0.0,  \n",
    "        save_path=f\"adversarial_samples_epsilon_{epsilon}.pkl\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n evaluate attack performance (epsilon={epsilon})...\")\n",
    "    attack_results = evaluate_attack_with_mae(\n",
    "        surrogate_models,\n",
    "        adversarial_samples,\n",
    "        device,\n",
    "        wind_power_scaler=wind_power_scaler\n",
    "    )\n",
    "\n",
    "\n",
    "    model = surrogate_models[model_idx_to_use]\n",
    "    model.eval()\n",
    "\n",
    "    all_targets = []      \n",
    "    all_preds_adv = []    \n",
    "\n",
    "    for sample in adversarial_samples:\n",
    "        wind_history = torch.tensor(sample['wind_history'], dtype=torch.float32).to(device)\n",
    "        future_weather_adv = torch.tensor(sample['future_weather_adversarial'], dtype=torch.float32).to(device)\n",
    "        true_power = torch.tensor(sample['true_power'], dtype=torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_adv = model(wind_history, future_weather_adv).squeeze()\n",
    "\n",
    "        all_targets.append(true_power.cpu().numpy())\n",
    "        all_preds_adv.append(pred_adv.cpu().numpy())\n",
    "\n",
    "    all_targets = np.concatenate(all_targets).flatten()\n",
    "    all_preds_adv = np.concatenate(all_preds_adv).flatten()\n",
    "\n",
    "    r2_adv = r2_score(all_targets, all_preds_adv)\n",
    "    rmse_adv = mean_squared_error(all_targets, all_preds_adv, squared=False)\n",
    "    mse_adv = mean_squared_error(all_targets, all_preds_adv)\n",
    "    print(f'RÂ²: {r2_adv:.10f}')\n",
    "    print(f'RMSE: {rmse_adv:.10f}')\n",
    "    print(f'MSE: {mse_adv:.10f}')\n",
    "\n",
    "    return attack_results, r2_adv, rmse_adv, mse_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97538526",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0.1, 0.05, 0.03]\n",
    "csv_names = ['buchong_AoA_010.csv', 'buchong_AoA_005.csv', 'buchong_AoA_003.csv']\n",
    "\n",
    "for eps, csv_name in zip(epsilons, csv_names):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\" AoA attack, epsilon={eps}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    attack_results, r2, rmse, mse = run_aoa_attack_and_save(\n",
    "        surrogate_models=sur_model_list,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        wind_power_scaler=wind_power_scaler,\n",
    "        epsilon=eps,\n",
    "        num_steps=80,        \n",
    "        learning_rate=0.003,  \n",
    "        lambda_aoa=1.0,\n",
    "        lambda_reg=10.0,\n",
    "        model_idx_to_use=0,  \n",
    "        save_csv_name=csv_name\n",
    "    )\n",
    "\n",
    "    for res in attack_results:\n",
    "        if res['model_idx'] == 0:\n",
    "            print(f\" Model 0 - MAE Increase: {res['mae_increase']:.6f}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355603e5",
   "metadata": {},
   "source": [
    "## UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e92fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_attack_inde(uap_loaded, model, data_loader, device='cpu'):\n",
    "    model.eval()  \n",
    "    all_preds = []\n",
    "    all_adversarial_preds = []\n",
    "    all_targets = []\n",
    "    all_original_weather = []\n",
    "    all_adversarial_weather = []\n",
    "    for wind_history, weather_future, future_wind_power in data_loader:\n",
    "        wind_history = wind_history.to(device)\n",
    "        weather_future = weather_future.to(device)\n",
    "        future_wind_power = future_wind_power.to(device)\n",
    "        original_output = model(wind_history, weather_future)\n",
    "        adversarial_weather = weather_future + uap_loaded\n",
    "        adversarial_weather = torch.clamp(adversarial_weather, 0, 1)  \n",
    "        adversarial_output = model(wind_history, adversarial_weather.detach())  \n",
    "        all_preds.append(original_output.detach().cpu().numpy())\n",
    "        all_adversarial_preds.append(adversarial_output.detach().cpu().numpy())\n",
    "        all_targets.append(future_wind_power.cpu().numpy())\n",
    "        all_original_weather.append(weather_future.detach().cpu().numpy())\n",
    "        all_adversarial_weather.append(adversarial_weather.detach().cpu().numpy())\n",
    "    model.eval()  \n",
    "    return all_preds, all_adversarial_preds, all_targets, all_original_weather, all_adversarial_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0048e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('uap_list010_caiso.pkl', 'rb') as f:\n",
    "    uap_list010 = pickle.load(f)\n",
    "\n",
    "with open('uap_list005_caiso.pkl', 'rb') as f:\n",
    "    uap_list005 = pickle.load(f)\n",
    "\n",
    "with open('uap_list003_caiso.pkl', 'rb') as f:\n",
    "    uap_list003 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for uap_loaded in uap_list010:\n",
    "    original_preds, adversarial_preds, targets, original_weathers, adversarial_weathers = adversarial_attack_inde(uap_loaded, model, test_loader, device=device)\n",
    "    adversarial_preds_uni = np.concatenate(adversarial_preds).flatten()\n",
    "    targets= np.concatenate(targets).flatten()\n",
    "    all_targets_inv=wind_power_scaler.inverse_transform(np.array(targets).reshape(-1, 1)).squeeze()\n",
    "    all_preds_inv=wind_power_scaler.inverse_transform(np.array(adversarial_preds_uni).reshape(-1, 1)).squeeze()\n",
    "    mae = mean_absolute_error(all_targets_inv, all_preds_inv)\n",
    "    r2= r2_score(all_targets_inv, all_preds_inv)\n",
    "    rmse=mean_squared_error(all_targets_inv, all_preds_inv, squared=False)\n",
    "    print('r2=',r2)\n",
    "    print('rmse=',rmse)\n",
    "    print('mae=',mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4953c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for uap_loaded in uap_list005:\n",
    "    original_preds, adversarial_preds, targets, original_weathers, adversarial_weathers = adversarial_attack_inde(uap_loaded, model, test_loader, device=device)\n",
    "    adversarial_preds_uni = np.concatenate(adversarial_preds).flatten()\n",
    "    targets= np.concatenate(targets).flatten()\n",
    "    all_targets_inv=wind_power_scaler.inverse_transform(np.array(targets).reshape(-1, 1)).squeeze()\n",
    "    all_preds_inv=wind_power_scaler.inverse_transform(np.array(adversarial_preds_uni).reshape(-1, 1)).squeeze()\n",
    "    mae = mean_absolute_error(all_targets_inv, all_preds_inv)\n",
    "    r2= r2_score(all_targets_inv, all_preds_inv)\n",
    "    rmse=mean_squared_error(all_targets_inv, all_preds_inv, squared=False)\n",
    "    print('r2=',r2)\n",
    "    print('rmse=',rmse)\n",
    "    print('mae=',mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for uap_loaded in uap_list003:\n",
    "    original_preds, adversarial_preds, targets, original_weathers, adversarial_weathers = adversarial_attack_inde(uap_loaded, model, test_loader, device=device)\n",
    "    adversarial_preds_uni = np.concatenate(adversarial_preds).flatten()\n",
    "    targets= np.concatenate(targets).flatten()\n",
    "    all_targets_inv=wind_power_scaler.inverse_transform(np.array(targets).reshape(-1, 1)).squeeze()\n",
    "    all_preds_inv=wind_power_scaler.inverse_transform(np.array(adversarial_preds_uni).reshape(-1, 1)).squeeze()\n",
    "    mae = mean_absolute_error(all_targets_inv, all_preds_inv)\n",
    "    r2= r2_score(all_targets_inv, all_preds_inv)\n",
    "    rmse=mean_squared_error(all_targets_inv, all_preds_inv, squared=False)\n",
    "    print('r2=',r2)\n",
    "    print('rmse=',rmse)\n",
    "    print('mae=',mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf446d",
   "metadata": {},
   "source": [
    "## RUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df22560",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rup_ensemble_003_caiso.pkl', 'rb') as f:\n",
    "    rup_ensemble_003 = pickle.load(f)\n",
    "\n",
    "with open('rup_ensemble_005_caiso.pkl', 'rb') as f:\n",
    "    rup_ensemble_005 = pickle.load(f)\n",
    "\n",
    "with open('rup_ensemble_010_caiso.pkl', 'rb') as f:\n",
    "    rup_ensemble_010 = pickle.load(f)\n",
    "\n",
    "rup_list=[rup_ensemble_003,rup_ensemble_005,rup_ensemble_010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2dcfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for uap_loaded in rup_list:\n",
    "    original_preds, adversarial_preds, targets, original_weathers, adversarial_weathers = adversarial_attack_inde(uap_loaded, model, test_loader, device=device)\n",
    "    adversarial_preds_uni = np.concatenate(adversarial_preds).flatten()\n",
    "    targets= np.concatenate(targets).flatten()\n",
    "    all_targets_inv=wind_power_scaler.inverse_transform(np.array(targets).reshape(-1, 1)).squeeze()\n",
    "    all_preds_inv=wind_power_scaler.inverse_transform(np.array(adversarial_preds_uni).reshape(-1, 1)).squeeze()\n",
    "    mae = mean_absolute_error(all_targets_inv, all_preds_inv)\n",
    "    r2= r2_score(all_targets_inv, all_preds_inv)\n",
    "    rmse=mean_squared_error(all_targets_inv, all_preds_inv, squared=False)\n",
    "    print('r2=',r2)\n",
    "    print('rmse=',rmse)\n",
    "    print('mae=',mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add0175d",
   "metadata": {},
   "source": [
    "## RUPW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b9e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RUPW010_caiso.pkl', 'rb') as f:\n",
    "    rupw_010 = pickle.load(f)\n",
    "\n",
    "with open('RUPW005_caiso.pkl', 'rb') as f:\n",
    "    rupw_005 = pickle.load(f)\n",
    "\n",
    "with open('RUPW003_caiso.pkl', 'rb') as f:\n",
    "    rupw_003 = pickle.load(f)\n",
    "\n",
    "rupw_ensemble=[rupw_003,rupw_005,rupw_010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c143caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for uap_loaded in rupw_ensemble:\n",
    "    original_preds, adversarial_preds, targets, original_weathers, adversarial_weathers = adversarial_attack_inde(uap_loaded, model, test_loader, device=device)\n",
    "    adversarial_preds_uni = np.concatenate(adversarial_preds).flatten()\n",
    "    targets= np.concatenate(targets).flatten()\n",
    "    all_targets_inv=wind_power_scaler.inverse_transform(np.array(targets).reshape(-1, 1)).squeeze()\n",
    "    all_preds_inv=wind_power_scaler.inverse_transform(np.array(adversarial_preds_uni).reshape(-1, 1)).squeeze()\n",
    "    mae = mean_absolute_error(all_targets_inv, all_preds_inv)\n",
    "    r2= r2_score(all_targets_inv, all_preds_inv)\n",
    "    rmse=mean_squared_error(all_targets_inv, all_preds_inv, squared=False)\n",
    "    print('r2=',r2)\n",
    "    print('rmse=',rmse)\n",
    "    print('mae=',mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
