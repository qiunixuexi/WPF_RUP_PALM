{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3641e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09873507",
   "metadata": {},
   "source": [
    "## 0. Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b676daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerDataset(Dataset):\n",
    "    def __init__(self, csv_file, wind_power_scaler=None, weather_scaler=None, save_scalers=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.data = self.data.iloc[::5, :].reset_index(drop=True)\n",
    "\n",
    "        self.original_wind_power_std = self.data.iloc[:, 2].std()\n",
    "        self.original_weather_std = self.data.iloc[:, 4:12].std()\n",
    "\n",
    "        if wind_power_scaler is None or weather_scaler is None:\n",
    "            self.wind_power_scaler = MinMaxScaler()\n",
    "            self.weather_scaler = MinMaxScaler()\n",
    "\n",
    "            self.data.iloc[:, 2] = self.wind_power_scaler.fit_transform(self.data.iloc[:, 2].values.reshape(-1, 1)).squeeze()\n",
    "\n",
    "            self.data.iloc[:, 4:12] = self.weather_scaler.fit_transform(self.data.iloc[:, 4:12])\n",
    "            \n",
    "            if save_scalers:\n",
    "                with open('wind_power_scaler.pkl', 'wb') as f:\n",
    "                    pickle.dump(self.wind_power_scaler, f)\n",
    "                with open('weather_scaler.pkl', 'wb') as f:\n",
    "                    pickle.dump(self.weather_scaler, f)\n",
    "        else:\n",
    "            self.wind_power_scaler = wind_power_scaler\n",
    "            self.weather_scaler = weather_scaler\n",
    "            self.data.iloc[:, 2] = self.wind_power_scaler.transform(self.data.iloc[:, 2].values.reshape(-1, 1)).squeeze()\n",
    "            self.data.iloc[:, 4:12] = self.weather_scaler.transform(self.data.iloc[:, 4:12])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - 312  # 288 (1440/5) + 24 (120/5)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        history_weather = self.data.iloc[idx:idx + 288, 4:12].values.astype(float)  # [288, 8]\n",
    "        wind_power_history = self.data.iloc[idx:idx + 288, 2].values.astype(float)   # [288]\n",
    "        future_weather = self.data.iloc[idx + 288:idx + 312, 4:12].values.astype(float)  # [24, 8]\n",
    "        future_wind_power = self.data.iloc[idx + 312, 2]  # float\n",
    "\n",
    "        return (\n",
    "            #torch.tensor(history_weather, dtype=torch.float32),\n",
    "            torch.tensor(wind_power_history, dtype=torch.float32),\n",
    "            torch.tensor(future_weather, dtype=torch.float32),\n",
    "            torch.tensor(future_wind_power, dtype=torch.float32)\n",
    "        )\n",
    "    \n",
    "    def get_original_stds(self):\n",
    "        return {\n",
    "            'original_wind_power_std': self.original_wind_power_std,\n",
    "            'original_weather_std': self.original_weather_std.to_dict()\n",
    "        }\n",
    "    \n",
    "name='CAISO_zone_1_.csv'\n",
    "with open('weather_scaler.pkl', 'rb') as f:\n",
    "    weather_scaler = pickle.load(f)\n",
    "dataset = WindPowerDataset(name, save_scalers=True)\n",
    "wind_power_scaler=dataset.wind_power_scaler\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size=32\n",
    "test_split=0.2\n",
    "test_size = int(len(dataset) * test_split)\n",
    "train_size = len(dataset) - test_size\n",
    "train_dataset = Subset(dataset, list(range(train_size)))\n",
    "test_dataset = Subset(dataset, list(range(train_size, len(dataset))))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4cd865",
   "metadata": {},
   "source": [
    "## 1. preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c9d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the RUB/UP/RUPW data obtained by the defending party (wind farm) through training their own wind power prediction model. (based on target model, not surrogate model)\n",
    "uap_loaded_list = [\n",
    "    torch.load('RUP_caiso_003.pth').to('cpu'),\n",
    "    torch.load('RUP_caiso_005.pth').to('cpu'),\n",
    "    torch.load('RUP_caiso_010.pth').to('cpu'),\n",
    "    torch.load('UP_caiso_003.pth').to('cpu'),\n",
    "    torch.load('UP_caiso_005.pth').to('cpu'),\n",
    "    torch.load('UP_caiso_010.pth').to('cpu'),\n",
    "    torch.load('RUPW_caiso_003.pth').to('cpu'),\n",
    "    torch.load('RUPW_caiso_005.pth').to('cpu'),\n",
    "    torch.load('RUPW_caiso_010.pth').to('cpu')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca580bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.lstm_wind = nn.LSTM(input_size=1, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm_weather = nn.LSTM(input_size=8, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(256, 1)\n",
    "        self.relu=nn.ReLU()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = wind_history.unsqueeze(-1)\n",
    "        _, (hn_wind, _) = self.lstm_wind(wind_history)\n",
    "        _, (hn_weather, _) = self.lstm_weather(weather_future)\n",
    "        hn_wind = hn_wind[-1, :, :]\n",
    "        hn_weather = hn_weather[-1, :, :]\n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.relu(output)\n",
    "        return output\n",
    "def load_model(model_path, device='cpu'):\n",
    "    model =WindPowerPredictor().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "model_path = 'wind_caiso_lstm_sigmoid_version2.pth' \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = load_model(model_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bfe0e8",
   "metadata": {},
   "source": [
    "## 2. PALM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_constraints(weather_future, weather_scaler):\n",
    "    \n",
    "    batch_size, seq_len, feature_dim = weather_future.shape\n",
    "\n",
    "    # Denormalization\n",
    "    weather_future_reshaped = weather_future.view(-1, feature_dim)\n",
    "    weather_future_unscaled = weather_scaler.inverse_transform(weather_future_reshaped.detach().cpu().numpy())\n",
    "    weather_future_unscaled = torch.tensor(weather_future_unscaled, dtype=weather_future.dtype, device=weather_future.device)\n",
    "    weather_future_unscaled = weather_future_unscaled.view(batch_size, seq_len, feature_dim)\n",
    "\n",
    "    # extract variables\n",
    "    DNI = weather_future_unscaled[:, :, 1]\n",
    "    Solar_Zenith_Angle = weather_future_unscaled[:, :, 4]\n",
    "    DHI = weather_future_unscaled[:, :, 0]\n",
    "    GHI = weather_future_unscaled[:, :, 2]\n",
    "    Dew_Point = weather_future_unscaled[:, :, 3]\n",
    "    Temperature = weather_future_unscaled[:, :, 7]\n",
    "    Relative_Humidity = weather_future_unscaled[:, :, 6]\n",
    "\n",
    "    # Physical constraints\n",
    "    cos_sza = torch.cos(Solar_Zenith_Angle * np.pi / 180.0)\n",
    "    constraint_1 = torch.abs((DNI * cos_sza + DHI) - GHI)  # GHI = DNI*cos + DHI\n",
    "    constraint_2 = torch.relu(Dew_Point - Temperature)     # Dew point <= Temperature\n",
    "    constraint_3 = torch.abs(\n",
    "        100 * torch.exp(17.625 * Dew_Point / (243.04 + Dew_Point)) /\n",
    "        torch.exp(17.625 * Temperature / (243.04 + Temperature)) - Relative_Humidity\n",
    "    )\n",
    "\n",
    "    return torch.stack([constraint_1, constraint_2, constraint_3], dim=-1)\n",
    "\n",
    "\n",
    "# define the classifier network (Normal=1, Adversarial=0)\n",
    "class ConstraintClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=72):\n",
    "        super(ConstraintClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# Train Classifier\n",
    "def train_constraint_classifier_with_loader(\n",
    "    train_loader,\n",
    "    uap_loaded_list,\n",
    "    classifier_model,\n",
    "    wind_power_model,\n",
    "    weather_scaler,\n",
    "    device='cuda',\n",
    "    epochs=10,\n",
    "    learning_rate=1e-5\n",
    "):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(classifier_model.parameters(), lr=learning_rate)\n",
    "    classifier_model.to(device)\n",
    "    wind_power_model.to(device)\n",
    "\n",
    "    # Freeze power prediction model parameters\n",
    "    wind_power_model.eval()\n",
    "    for param in wind_power_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    best_loss_value = float('inf')\n",
    "    epsilons = [0.03, 0.05, 0.10]  # different perturbation strengths\n",
    "\n",
    "    print(f\" Training with epsilon values: {epsilons}\")\n",
    "    print(\" Label: Normal = 1, Adversarial = 0\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        total_steps = 0\n",
    "        classifier_model.train()\n",
    "\n",
    "        for batch_idx, (wind_history, weather_future, future_wind_power) in enumerate(train_loader):\n",
    "            B = weather_future.size(0)\n",
    "            weather_future = weather_future.to(device)\n",
    "            wind_history = wind_history.to(device)\n",
    "            future_wind_power = future_wind_power.to(device)\n",
    "\n",
    "            # Store constraints and labels for all samples\n",
    "            all_constraints = []\n",
    "            all_labels = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                normal_constraints = compute_constraints(weather_future.cpu(), weather_scaler).to(device)\n",
    "                normal_constraints = normal_constraints.view(B, -1)\n",
    "                all_constraints.append(normal_constraints)\n",
    "                all_labels.append(torch.ones(B, device=device))  # normal = 1\n",
    "\n",
    "            for uap in uap_loaded_list:\n",
    "                adv_weather = torch.clamp(weather_future + uap.to(device), 0, 1)\n",
    "                attacked_constraints = compute_constraints(adv_weather.cpu(), weather_scaler).to(device)\n",
    "                attacked_constraints = attacked_constraints.view(B, -1)\n",
    "                all_constraints.append(attacked_constraints)\n",
    "                all_labels.append(torch.zeros(B, device=device))  # abnormal = 0\n",
    "\n",
    "            wind_power_model.train()  # must be in train() mode\n",
    "\n",
    "            # Ensure wind_power_model parameters are not updated\n",
    "            for param in wind_power_model.parameters():\n",
    "                param.requires_grad = False  # freeze parameters\n",
    "\n",
    "            weather_future_for_grad = weather_future.clone().detach().requires_grad_(True)\n",
    "            pred_power = wind_power_model(wind_history, weather_future_for_grad)\n",
    "            loss_power = nn.MSELoss()(pred_power.squeeze(), future_wind_power)\n",
    "\n",
    "            # backward\n",
    "            wind_power_model.zero_grad()\n",
    "            loss_power.backward()  # now can backward\n",
    "\n",
    "            # gain the gradient\n",
    "            grad_sign = weather_future_for_grad.grad.data.sign()\n",
    "\n",
    "            # Generate adversarial samples with multiple epsilons\n",
    "            for eps in epsilons:\n",
    "                adv_weather = torch.clamp(weather_future + eps * grad_sign, 0, 1)\n",
    "                attacked_constraints = compute_constraints(adv_weather.cpu(), weather_scaler).to(device)\n",
    "                attacked_constraints = attacked_constraints.view(B, -1)\n",
    "                all_constraints.append(attacked_constraints)\n",
    "                all_labels.append(torch.zeros(B, device=device))  # abnormal = 0\n",
    "\n",
    "            # Restore eval() (optional)\n",
    "            wind_power_model.eval()\n",
    "\n",
    "            # Concatenate all samples\n",
    "            combined_constraints = torch.cat(all_constraints, dim=0)\n",
    "            combined_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = classifier_model(combined_constraints).squeeze()\n",
    "            loss = criterion(outputs, combined_labels)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_steps += 1\n",
    "\n",
    "        avg_loss = total_loss / total_steps\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.6f}\")\n",
    "\n",
    "        # save best model\n",
    "        if avg_loss < best_loss_value:\n",
    "            best_loss_value = avg_loss\n",
    "            best_classifier_model = copy.deepcopy(classifier_model)\n",
    "            print(f\"âœ… Best model updated with loss: {best_loss_value:.6f}\")\n",
    "\n",
    "    print(f\"ðŸŽ‰ Training completed. Best loss: {best_loss_value:.6f}\")\n",
    "    return best_classifier_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6fcdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "classifier_model = ConstraintClassifier(input_dim=72)\n",
    "\n",
    "# start training\n",
    "trained_classifier = train_constraint_classifier_with_loader(\n",
    "    train_loader=train_loader,\n",
    "    uap_loaded_list=uap_loaded_list,\n",
    "    classifier_model=classifier_model,\n",
    "    wind_power_model=model,\n",
    "    weather_scaler=weather_scaler,\n",
    "    device='cuda',\n",
    "    epochs=30,\n",
    "    learning_rate=1e-5\n",
    ")\n",
    "\n",
    "torch.save(trained_classifier,'CAISO_zone_1_PALM.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3094504a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed6079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb70996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
