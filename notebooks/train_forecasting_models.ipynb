{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a70a70",
   "metadata": {},
   "source": [
    "## 0. Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b359d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,r2_score, mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim  \n",
    "import copy\n",
    "from metrics import predict_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dbe655",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WindPowerDataset(Dataset):\n",
    "    def __init__(self, csv_file, wind_power_scaler=None, weather_scaler=None, save_scalers=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # sample every 5 rows\n",
    "        self.data = self.data.iloc[::5, :].reset_index(drop=True)\n",
    "\n",
    "        # calculate original std\n",
    "        self.original_wind_power_std = self.data.iloc[:, 2].std()\n",
    "        self.original_weather_std = self.data.iloc[:, 4:12].std()\n",
    "        \n",
    "        # initialize scalers\n",
    "        if wind_power_scaler is None or weather_scaler is None:\n",
    "            self.wind_power_scaler = MinMaxScaler()\n",
    "            self.weather_scaler = MinMaxScaler()\n",
    "\n",
    "            # Normalize the wind power data\n",
    "            self.data.iloc[:, 2] = self.wind_power_scaler.fit_transform(self.data.iloc[:, 2].values.reshape(-1, 1)).squeeze()\n",
    "\n",
    "            # Normalize the weather data\n",
    "            self.data.iloc[:, 4:12] = self.weather_scaler.fit_transform(self.data.iloc[:, 4:12])\n",
    "            \n",
    "            if save_scalers:\n",
    "                with open('wind_power_scaler.pkl', 'wb') as f:\n",
    "                    pickle.dump(self.wind_power_scaler, f)\n",
    "                with open('weather_scaler.pkl', 'wb') as f:\n",
    "                    pickle.dump(self.weather_scaler, f)\n",
    "        else:\n",
    "            self.wind_power_scaler = wind_power_scaler\n",
    "            self.weather_scaler = weather_scaler\n",
    "            self.data.iloc[:, 2] = self.wind_power_scaler.transform(self.data.iloc[:, 2].values.reshape(-1, 1)).squeeze()\n",
    "            self.data.iloc[:, 4:12] = self.weather_scaler.transform(self.data.iloc[:, 4:12])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - 312  # 288 (1440/5) + 24 (120/5), 288=1day history, 24=forecast 2 hour ahead\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        wind_power_history = self.data.iloc[idx:idx + 288, 2].values.astype(float)\n",
    "        future_weather = self.data.iloc[idx + 288:idx + 312, 4:12].values.astype(float)\n",
    "        future_wind_power = self.data.iloc[idx + 312, 2]\n",
    "        return torch.tensor(wind_power_history, dtype=torch.float32), \\\n",
    "               torch.tensor(future_weather, dtype=torch.float32), \\\n",
    "               torch.tensor(future_wind_power, dtype=torch.float32)\n",
    "    \n",
    "    def get_original_stds(self):\n",
    "        return {\n",
    "            'original_wind_power_std': self.original_wind_power_std,\n",
    "            'original_weather_std': self.original_weather_std.to_dict()\n",
    "        }\n",
    "\n",
    "\n",
    "dataset = WindPowerDataset('CAISO_zone_1_.csv', save_scalers=True)\n",
    "weather_stds = dataset.get_original_stds()\n",
    "#print(\"weather_stds: \", weather_stds)\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)  \n",
    "test_size = total_size - train_size  \n",
    "\n",
    "\n",
    "train_idx = list(range(train_size))\n",
    "test_idx = list(range(train_size, total_size))\n",
    "\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "test_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)  \n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)   \n",
    "\n",
    "wind_power_scaler=dataset.wind_power_scaler\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a4c7b5",
   "metadata": {},
   "source": [
    "## 1. Train surrogate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fdfa35",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a072bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(WindPowerPredictor, self).__init__()  \n",
    "        self.gru_wind = nn.GRU(input_size=1, hidden_size=50, num_layers=2, batch_first=True)  \n",
    "        self.gru_weather = nn.GRU(input_size=8, hidden_size=50, num_layers=2, batch_first=True)  \n",
    "        self.fc = nn.Linear(100, 1)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "      \n",
    "    def forward(self, wind_history, weather_future):  \n",
    "        wind_history = wind_history.unsqueeze(-1)  \n",
    "        _, hn_wind = self.gru_wind(wind_history)  \n",
    "        _, hn_weather = self.gru_weather(weather_future)  \n",
    "        hn_wind = hn_wind[-1, :, :]  \n",
    "        hn_weather = hn_weather[-1, :, :]  \n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)  \n",
    "        output = self.fc(combined)  \n",
    "        output = self.sigmoid(output)\n",
    "        return output  \n",
    "  \n",
    "def train_model(csv_file, epochs=10, batch_size=32, learning_rate=0.001, test_split=0.2, device='cpu'):  \n",
    "    dataset = WindPowerDataset(csv_file, save_scalers=True)  \n",
    "    test_size = int(len(dataset) * test_split)  \n",
    "    train_size = len(dataset) - test_size  \n",
    "    train_dataset = Subset(dataset, list(range(train_size)))  \n",
    "    test_dataset = Subset(dataset, list(range(train_size, len(dataset))))  \n",
    "      \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)  \n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  \n",
    "      \n",
    "    model = WindPowerPredictor().to(device)  \n",
    "    criterion = nn.MSELoss()  \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "      \n",
    "    best_test_loss = float('inf')  \n",
    "    best_model_state = None  \n",
    "  \n",
    "    for epoch in range(epochs):  \n",
    "        model.train()  \n",
    "        for wind_history, weather_future, future_wind_power in train_loader:  \n",
    "            wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)  \n",
    "            optimizer.zero_grad()  \n",
    "            output = model(wind_history, weather_future)  \n",
    "            loss = criterion(output.squeeze(), future_wind_power)  \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "  \n",
    "        # validation\n",
    "        model.eval()  \n",
    "        test_predictions = []  \n",
    "        test_targets = []  \n",
    "        test_loss = 0.0  \n",
    "        with torch.no_grad():  \n",
    "            for wind_history, weather_future, future_wind_power in test_loader:  \n",
    "                wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)  \n",
    "                output = model(wind_history, weather_future)  \n",
    "                loss = criterion(output.squeeze(), future_wind_power)  \n",
    "                test_loss += loss.item()  \n",
    "                test_predictions.extend(output.squeeze().cpu().numpy())  \n",
    "                test_targets.extend(future_wind_power.cpu().numpy())  \n",
    "  \n",
    "        test_loss /= len(test_loader)  \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Test Loss: {test_loss}')  \n",
    "  \n",
    "        # update and save the best model\n",
    "        if test_loss < best_test_loss:  \n",
    "            best_model_state = copy.deepcopy(model.state_dict())  \n",
    "            best_test_loss=test_loss\n",
    "  \n",
    "    # save the best model  \n",
    "    torch.save(best_model_state, 'wind_gru_caiso_sigmoid.pth')  \n",
    "    print(f'Best model saved with test loss: {best_test_loss}')    \n",
    "    return best_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db0fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "csv_file = 'CAISO_zone_1_.csv'\n",
    "model = train_model(csv_file, device=device,learning_rate=0.0001, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a51ce14",
   "metadata": {},
   "source": [
    "### transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791dd463",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self, d_model=50):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding_wind = nn.Linear(1, d_model)\n",
    "        self.embedding_weather = nn.Linear(8, d_model)\n",
    "        self.transformer_wind = nn.Transformer(\n",
    "            d_model=d_model, nhead=2, num_encoder_layers=2, num_decoder_layers=2, dim_feedforward=200, dropout=0.1\n",
    "        )\n",
    "        self.transformer_weather = nn.Transformer(\n",
    "            d_model=d_model, nhead=2, num_encoder_layers=2, num_decoder_layers=2, dim_feedforward=200, dropout=0.1\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = self.embedding_wind(wind_history.unsqueeze(-1))  # (batch_size, seq_len, d_model)\n",
    "        wind_history = wind_history.permute(1, 0, 2)  # (seq_len, batch_size, d_model)\n",
    "        weather_future = self.embedding_weather(weather_future)  # (batch_size, seq_len, d_model)\n",
    "        weather_future = weather_future.permute(1, 0, 2)  # (seq_len, batch_size, d_model)\n",
    "\n",
    "        transformer_output_wind = self.transformer_wind(wind_history, wind_history)\n",
    "        transformer_output_weather = self.transformer_weather(weather_future, weather_future)\n",
    "        \n",
    "        combined = torch.cat((transformer_output_wind[-1, :, :], transformer_output_weather[-1, :, :]), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.sigmoid(output)  \n",
    "        return output\n",
    "\n",
    "def train_model(csv_file, epochs=10, batch_size=32, learning_rate=0.001, test_split=0.2, device='cpu'):\n",
    "    dataset = WindPowerDataset(csv_file, save_scalers=True)\n",
    "    test_size = int(len(dataset) * test_split)\n",
    "    train_size = len(dataset) - test_size\n",
    "    train_dataset = Subset(dataset, list(range(train_size)))\n",
    "    test_dataset = Subset(dataset, list(range(train_size, len(dataset))))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = WindPowerPredictor().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_test_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for wind_history, weather_future, future_wind_power in train_loader:\n",
    "            wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(wind_history, weather_future)\n",
    "            loss = criterion(output.squeeze(), future_wind_power)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for wind_history, weather_future, future_wind_power in test_loader:\n",
    "                wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)\n",
    "                output = model(wind_history, weather_future)\n",
    "                loss = criterion(output.squeeze(), future_wind_power)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Test Loss: {test_loss}')\n",
    "\n",
    "        # update and save the best model\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_model_state = model.state_dict().copy()  \n",
    "\n",
    "    # save the best model\n",
    "    torch.save(best_model_state, 'wind_caiso_transformer_sigmoid.pth')\n",
    "    print(f'Best model saved with test loss: {best_test_loss}')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf62b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(csv_file, device=device, epochs=20, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653bd09b",
   "metadata": {},
   "source": [
    "### TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c40bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=(kernel_size-1) * dilation_size, dilation=dilation_size),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Dropout(dropout)]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class WindPowerPredictorTCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WindPowerPredictorTCN, self).__init__()\n",
    "        self.tcn_wind = TemporalConvNet(num_inputs=1, num_channels=[50]*3, kernel_size=3, dropout=0.2)\n",
    "        self.tcn_weather = TemporalConvNet(num_inputs=8, num_channels=[50]*3, kernel_size=3, dropout=0.2)\n",
    "        self.fc = nn.Linear(50 * 2, 1)  # Combined output size of TCNs\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = wind_history.unsqueeze(1)  # (batch_size, 1, seq_len)\n",
    "        tcn_output_wind = self.tcn_wind(wind_history).transpose(1, 2)[:, -1, :]\n",
    "        \n",
    "        weather_future = weather_future.transpose(1, 2)  # (batch_size, 8, seq_len)\n",
    "        tcn_output_weather = self.tcn_weather(weather_future).transpose(1, 2)[:, -1, :]\n",
    "        \n",
    "        combined = torch.cat((tcn_output_wind, tcn_output_weather), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbadb7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_lambda(total_epochs):\n",
    "    def lr_lambda(epoch):\n",
    "        return 1 - (epoch / total_epochs)\n",
    "    return lr_lambda\n",
    "\n",
    "def train_model_tcn(csv_file, epochs=40, batch_size=32, learning_rate=0.001, test_split=0.2, device='cpu'):\n",
    "    dataset = WindPowerDataset(csv_file, save_scalers=True)\n",
    "    test_size = int(len(dataset) * test_split)\n",
    "    train_size = len(dataset) - test_size\n",
    "    train_dataset = Subset(dataset, list(range(train_size)))\n",
    "    test_dataset = Subset(dataset, list(range(train_size, len(dataset))))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = WindPowerPredictorTCN().to(device)\n",
    "    criterion = torch.nn.MSELoss()  \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "    lr_lambda = get_lr_lambda(epochs)\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for wind_history, weather_future, future_wind_power in train_loader:\n",
    "            wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(wind_history, weather_future)\n",
    "            loss = criterion(output.squeeze(), future_wind_power)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for wind_history, weather_future, future_wind_power in test_loader:\n",
    "                wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)\n",
    "                output = model(wind_history, weather_future)\n",
    "                loss = criterion(output.squeeze(), future_wind_power)\n",
    "                test_loss += loss.item()\n",
    "     \n",
    "        \n",
    "        test_loss /= len(test_loader)  \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Test Loss: {test_loss}')  \n",
    "  \n",
    "        # 更新并保存最佳模型  \n",
    "        if test_loss < best_loss:  \n",
    "            best_model_state = copy.deepcopy(model.state_dict())  \n",
    "            best_loss = test_loss\n",
    "    torch.save(best_model_state, 'wind_tcn_caiso_sigmoid.pth')\n",
    "    return best_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model_tcn(csv_file, device=device, epochs=100, learning_rate=0.00001)    #Training time is longer compared to other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7232410",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f384a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.lstm_wind = nn.LSTM(input_size=1, hidden_size=50, num_layers=2, batch_first=True)\n",
    "        self.lstm_weather = nn.LSTM(input_size=8, hidden_size=50, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(100, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = wind_history.unsqueeze(-1)\n",
    "        _, (hn_wind, _) = self.lstm_wind(wind_history)\n",
    "        _, (hn_weather, _) = self.lstm_weather(weather_future)\n",
    "        hn_wind = hn_wind[-1, :, :]\n",
    "        hn_weather = hn_weather[-1, :, :]\n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.sigmoid(output)  \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_lstm(csv_file, epochs=10, batch_size=32, learning_rate=0.001, test_split=0.2, device='cpu'):\n",
    "    dataset = WindPowerDataset(csv_file, save_scalers=True)\n",
    "    test_size = int(len(dataset) * test_split)\n",
    "    train_size = len(dataset) - test_size\n",
    "    train_dataset = Subset(dataset, list(range(train_size)))\n",
    "    test_dataset = Subset(dataset, list(range(train_size, len(dataset))))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = WindPowerPredictor().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_test_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for wind_history, weather_future, future_wind_power in train_loader:\n",
    "            wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(wind_history, weather_future)\n",
    "            loss = criterion(output.squeeze(), future_wind_power)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for wind_history, weather_future, future_wind_power in test_loader:\n",
    "                wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)\n",
    "                output = model(wind_history, weather_future)\n",
    "                loss = criterion(output.squeeze(), future_wind_power)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Test Loss: {test_loss}')\n",
    "\n",
    "        \n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_model_state = model.state_dict().copy() \n",
    "\n",
    "    torch.save(best_model_state, 'wind_caiso_lstm_sigmoid.pth')\n",
    "    print(f'Best model saved with test loss: {best_test_loss}')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b616c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model_lstm(csv_file, device=device, epochs=20, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a764a3",
   "metadata": {},
   "source": [
    "## 2. Train target model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c38d388",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f50353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim  \n",
    "import copy\n",
    "\n",
    "class WindPowerPredictor(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(WindPowerPredictor, self).__init__()  \n",
    "        self.gru_wind = nn.GRU(input_size=1, hidden_size=128, num_layers=1, batch_first=True)  \n",
    "        self.gru_weather = nn.GRU(input_size=8, hidden_size=128, num_layers=1, batch_first=True)  \n",
    "        self.fc = nn.Linear(256, 1)  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "      \n",
    "    def forward(self, wind_history, weather_future):  \n",
    "        wind_history = wind_history.unsqueeze(-1)  \n",
    "        _, hn_wind = self.gru_wind(wind_history)  \n",
    "        _, hn_weather = self.gru_weather(weather_future)  \n",
    "        hn_wind = hn_wind[-1, :, :]  \n",
    "        hn_weather = hn_weather[-1, :, :]  \n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)  \n",
    "        output = self.fc(combined)  \n",
    "        output = self.sigmoid(output)\n",
    "        return output  \n",
    "  \n",
    "def train_model(csv_file, epochs=10, batch_size=32, learning_rate=0.001, test_split=0.2, device='cpu'):  \n",
    "    dataset = WindPowerDataset(csv_file, save_scalers=True)  \n",
    "    test_size = int(len(dataset) * test_split)  \n",
    "    train_size = len(dataset) - test_size  \n",
    "    train_dataset = Subset(dataset, list(range(train_size)))  \n",
    "    test_dataset = Subset(dataset, list(range(train_size, len(dataset))))  \n",
    "      \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)  \n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  \n",
    "      \n",
    "    model = WindPowerPredictor().to(device)  \n",
    "    criterion = nn.MSELoss()  \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "      \n",
    "    best_test_loss = float('inf')  \n",
    "    best_model_state = None  \n",
    "  \n",
    "    for epoch in range(epochs):  \n",
    "        model.train()  \n",
    "        for wind_history, weather_future, future_wind_power in train_loader:  \n",
    "            wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)  \n",
    "            optimizer.zero_grad()  \n",
    "            output = model(wind_history, weather_future)  \n",
    "            loss = criterion(output.squeeze(), future_wind_power)  \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "  \n",
    "        # 验证阶段  \n",
    "        model.eval()  \n",
    "        test_predictions = []  \n",
    "        test_targets = []  \n",
    "        test_loss = 0.0  \n",
    "        with torch.no_grad():  \n",
    "            for wind_history, weather_future, future_wind_power in test_loader:  \n",
    "                wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)  \n",
    "                output = model(wind_history, weather_future)  \n",
    "                loss = criterion(output.squeeze(), future_wind_power)  \n",
    "                test_loss += loss.item()  \n",
    "                test_predictions.extend(output.squeeze().cpu().numpy())  \n",
    "                test_targets.extend(future_wind_power.cpu().numpy())  \n",
    "  \n",
    "        test_loss /= len(test_loader)  \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Test Loss: {test_loss}')  \n",
    "  \n",
    "      \n",
    "        if test_loss < best_test_loss:  \n",
    "            #best_test_mape = test_mape  \n",
    "            best_model_state = copy.deepcopy(model.state_dict())  \n",
    "            best_test_loss=test_loss\n",
    "  \n",
    "    torch.save(best_model_state, 'wind_gru_caiso_sigmoid_version2.pth')  \n",
    "    print(f'Best model saved with test loss: {best_test_loss}')  \n",
    "    return best_model_state\n",
    "\n",
    "csv_file = 'CAISO_zone_1_.csv'\n",
    "model = train_model(csv_file, device=device,learning_rate=0.00003, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1285ebc0",
   "metadata": {},
   "source": [
    "### transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictorV2(nn.Module):\n",
    "    def __init__(self, d_model=64, nhead=4, num_layers=3, dim_feedforward=128, dropout=0.1, max_seq_len=300):\n",
    "        super(WindPowerPredictorV2, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.embedding_wind = nn.Linear(1, d_model)\n",
    "        self.embedding_weather = nn.Linear(8, d_model)\n",
    "\n",
    "        self.pos_encoder_wind = nn.Parameter(torch.zeros(max_seq_len, 1, d_model))\n",
    "        self.pos_encoder_weather = nn.Parameter(torch.zeros(max_seq_len, 1, d_model))\n",
    "\n",
    "\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=False\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "\n",
    "        self.fc_combine = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, wind_history, weather_future):\n",
    "        # wind_history: (batch_size, T1)        e.g., (32, 288)\n",
    "        # weather_future: (batch_size, T2, 8)    e.g., (32, 24, 8)\n",
    "\n",
    "        batch_size, seq_len_wind = wind_history.shape\n",
    "        _, seq_len_weather, _ = weather_future.shape\n",
    "\n",
    "        if seq_len_wind > self.pos_encoder_wind.size(0):\n",
    "            raise ValueError(f\"Wind sequence length {seq_len_wind} exceeds max supported length {self.pos_encoder_wind.size(0)}\")\n",
    "        if seq_len_weather > self.pos_encoder_weather.size(0):\n",
    "            raise ValueError(f\"Weather sequence length {seq_len_weather} exceeds max supported length {self.pos_encoder_weather.size(0)}\")\n",
    "\n",
    "        wind_emb = self.embedding_wind(wind_history.unsqueeze(-1))           # (B, T1, D)\n",
    "        weather_emb = self.embedding_weather(weather_future)                 # (B, T2, D)\n",
    "\n",
    "        wind_emb = wind_emb.permute(1, 0, 2)  # (T1, B, D)\n",
    "        weather_emb = weather_emb.permute(1, 0, 2)  # (T2, B, D)\n",
    "\n",
    "        wind_emb = wind_emb + self.pos_encoder_wind[:seq_len_wind]      # (T1, B, D)\n",
    "        weather_emb = weather_emb + self.pos_encoder_weather[:seq_len_weather]  # (T2, B, D)\n",
    "\n",
    "        wind_features = self.transformer_encoder(wind_emb)              # (T1, B, D)\n",
    "        weather_features = self.transformer_encoder(weather_emb)        # (T2, B, D)\n",
    "\n",
    "        wind_last = wind_features[-1, :, :]        \n",
    "        weather_last = weather_features[-1, :, :]  \n",
    "\n",
    "        combined = torch.cat((wind_last, weather_last), dim=1)  # (B, 2D)\n",
    "\n",
    "        output = self.fc_combine(combined)  # (B, 1)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "def train_model(csv_file, epochs=10, batch_size=32, learning_rate=0.001, test_split=0.2, device='cpu'):\n",
    "    dataset = WindPowerDataset(csv_file, save_scalers=True)\n",
    "    test_size = int(len(dataset) * test_split)\n",
    "    train_size = len(dataset) - test_size\n",
    "    train_dataset = Subset(dataset, list(range(train_size)))\n",
    "    test_dataset = Subset(dataset, list(range(train_size, len(dataset))))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = WindPowerPredictorV2().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_test_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for wind_history, weather_future, future_wind_power in train_loader:\n",
    "            wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(wind_history, weather_future)\n",
    "            loss = criterion(output.squeeze(), future_wind_power)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for wind_history, weather_future, future_wind_power in test_loader:\n",
    "                wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)\n",
    "                output = model(wind_history, weather_future)\n",
    "                loss = criterion(output.squeeze(), future_wind_power)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Test Loss: {test_loss}')\n",
    "\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_model_state = model.state_dict().copy()  \n",
    "\n",
    "    torch.save(best_model_state, 'wind_caiso_transformer_sigmoid_version2.pth')\n",
    "    print(f'Best model saved with test loss: {best_test_loss}')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(csv_file, device=device,learning_rate=0.00003, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d12cc2",
   "metadata": {},
   "source": [
    "### tcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8739438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalConvNet_V2(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=3, dropout=0.2):\n",
    "        super(TemporalConvNet_V2, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "\n",
    "            padding = (kernel_size - 1) * dilation_size\n",
    "\n",
    "            conv = nn.Conv1d(\n",
    "                in_channels, out_channels, kernel_size,\n",
    "                stride=1, padding=padding, dilation=dilation_size  \n",
    "            )\n",
    "            relu = nn.ReLU()\n",
    "            drop = nn.Dropout(dropout)\n",
    "\n",
    "            if in_channels != out_channels:\n",
    "                res_conv = nn.Conv1d(in_channels, out_channels, 1)\n",
    "            else:\n",
    "                res_conv = None\n",
    "\n",
    "            layers.append(nn.ModuleDict({\n",
    "                'conv': conv,\n",
    "                'relu': relu,\n",
    "                'dropout': drop,\n",
    "                'res_conv': res_conv\n",
    "            }))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, in_channels, seq_len)\n",
    "        for layer in self.layers:\n",
    "            residual = x  \n",
    "\n",
    "            x = layer['conv'](x)  \n",
    "            x = layer['relu'](x)\n",
    "            x = layer['dropout'](x)\n",
    "            x = x[:, :, :residual.size(2)]  \n",
    "\n",
    "            # 残差连接\n",
    "            if layer['res_conv'] is not None:\n",
    "                residual = layer['res_conv'](residual)\n",
    "            x = x + residual\n",
    "            x = layer['relu'](x)  \n",
    "        return x\n",
    "\n",
    "\n",
    "class WindPowerPredictorTCN_V2(nn.Module):\n",
    "    def __init__(self, d_model=64, dropout=0.2, fusion_mode='concat'):\n",
    "        super(WindPowerPredictorTCN_V2, self).__init__()\n",
    "        self.fusion_mode = fusion_mode  # 'concat' or 'add'\n",
    "        self.tcn_wind = TemporalConvNet_V2(\n",
    "            num_inputs=1,\n",
    "            num_channels=[d_model, d_model*2, d_model, d_model],  \n",
    "            kernel_size=3,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.tcn_weather = TemporalConvNet_V2(\n",
    "            num_inputs=8,\n",
    "            num_channels=[d_model, d_model*2, d_model, d_model],\n",
    "            kernel_size=3,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        if fusion_mode == 'concat':\n",
    "            fc_input_dim = d_model * 2\n",
    "        elif fusion_mode == 'add':\n",
    "            fc_input_dim = d_model\n",
    "        else:\n",
    "            raise ValueError(\"fusion_mode must be 'concat' or 'add'\")\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(fc_input_dim, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, wind_history, weather_future):\n",
    "        # wind_history: (batch_size, 288)\n",
    "        # weather_future: (batch_size, 24, 8)\n",
    "\n",
    "        x_wind = wind_history.unsqueeze(1)  # (B, 1, 288)\n",
    "        x_wind = self.tcn_wind(x_wind)     # (B, D, 288)\n",
    "        x_wind = x_wind[:, :, -1]          \n",
    "\n",
    "        x_weather = weather_future.transpose(1, 2)  # (B, 8, 24)\n",
    "        x_weather = self.tcn_weather(x_weather)     # (B, D, 24)\n",
    "        x_weather = x_weather[:, :, -1]             # -> (B, D)\n",
    "\n",
    "        if self.fusion_mode == 'concat':\n",
    "            combined = torch.cat((x_wind, x_weather), dim=1)  # (B, 2D)\n",
    "        elif self.fusion_mode == 'add':\n",
    "            combined = x_wind + x_weather  \n",
    "\n",
    "        output = self.fc(combined)         # (B, 1)\n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19920038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, device='cpu'):\n",
    "    model = WindPowerPredictorTCN_V2().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()  \n",
    "    return model\n",
    "\n",
    "def get_lr_lambda(total_epochs):\n",
    "    def lr_lambda(epoch):\n",
    "        return 1 - (epoch / total_epochs)\n",
    "    return lr_lambda\n",
    "\n",
    "def train_model_tcn(csv_file, epochs=40, batch_size=32, learning_rate=0.001, test_split=0.2, device='cpu'):\n",
    "    dataset = WindPowerDataset(csv_file, save_scalers=True)\n",
    "    test_size = int(len(dataset) * test_split)\n",
    "    train_size = len(dataset) - test_size\n",
    "    train_dataset = Subset(dataset, list(range(train_size)))\n",
    "    test_dataset = Subset(dataset, list(range(train_size, len(dataset))))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = WindPowerPredictorTCN_V2(d_model=64, dropout=0.2, fusion_mode='concat').to(device)\n",
    "    criterion = torch.nn.MSELoss()  \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    lr_lambda = get_lr_lambda(epochs)\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for wind_history, weather_future, future_wind_power in train_loader:\n",
    "            wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(wind_history, weather_future)\n",
    "            loss = criterion(output.squeeze(), future_wind_power)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for wind_history, weather_future, future_wind_power in test_loader:\n",
    "                wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)\n",
    "                output = model(wind_history, weather_future)\n",
    "                loss = criterion(output.squeeze(), future_wind_power)\n",
    "                test_loss += loss.item()\n",
    "     \n",
    "        \n",
    "        test_loss /= len(test_loader)  \n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Test Loss: {test_loss}')  \n",
    "\n",
    "        if test_loss < best_loss:  \n",
    "            best_model_state = copy.deepcopy(model.state_dict())  \n",
    "    torch.save(best_model_state, 'wind_tcn_caiso_sigmoid_v2.pth')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f322d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_tcn(csv_file, epochs=20, batch_size=32, learning_rate=0.00003, test_split=0.2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49044205",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=WindPowerPredictorTCN_V2().to(device)\n",
    "model.load_state_dict(torch.load('wind_tcn_caiso_sigmoid_v2.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a82b6a",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindPowerPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WindPowerPredictor, self).__init__()\n",
    "        self.lstm_wind = nn.LSTM(input_size=1, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm_weather = nn.LSTM(input_size=8, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(256, 1)\n",
    "        self.relu=nn.ReLU()\n",
    "    \n",
    "    def forward(self, wind_history, weather_future):\n",
    "        wind_history = wind_history.unsqueeze(-1)\n",
    "        _, (hn_wind, _) = self.lstm_wind(wind_history)\n",
    "        _, (hn_weather, _) = self.lstm_weather(weather_future)\n",
    "        hn_wind = hn_wind[-1, :, :]\n",
    "        hn_weather = hn_weather[-1, :, :]\n",
    "        combined = torch.cat((hn_wind, hn_weather), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        output = self.relu(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a471899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(csv_file, epochs=10, batch_size=32, learning_rate=0.001, test_split=0.2, device='cpu'):\n",
    "    dataset = WindPowerDataset(csv_file, save_scalers=True)\n",
    "    test_size = int(len(dataset) * test_split)\n",
    "    train_size = len(dataset) - test_size\n",
    "    train_dataset = Subset(dataset, list(range(train_size)))\n",
    "    test_dataset = Subset(dataset, list(range(train_size, len(dataset))))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = WindPowerPredictor().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_test_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for wind_history, weather_future, future_wind_power in train_loader:\n",
    "            wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(wind_history, weather_future)\n",
    "            loss = criterion(output.squeeze(), future_wind_power)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for wind_history, weather_future, future_wind_power in test_loader:\n",
    "                wind_history, weather_future, future_wind_power = wind_history.to(device), weather_future.to(device), future_wind_power.to(device)\n",
    "                output = model(wind_history, weather_future)\n",
    "                loss = criterion(output.squeeze(), future_wind_power)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Test Loss: {test_loss}')\n",
    "\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_model_state = model.state_dict().copy()  \n",
    "\n",
    "    torch.save(best_model_state, 'wind_caiso_lstm_sigmoid_version2.pth')\n",
    "    print(f'Best model saved with test loss: {best_test_loss}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087072ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(csv_file, device=device, epochs=20, learning_rate=0.0001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
